{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepfake-detection-model-project/Deepfake-Detection-Project/blob/jiwon-dev/notebooks/01_preprocessing/FF%2B%2B_download_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install insightface onnxruntime-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQsp_PSHRXlf",
        "outputId": "74e8b235-4f77-4cbd-fa05-3b2c15a198eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/439.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m430.1/439.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from insightface) (2.0.2)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from insightface) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from insightface) (2.32.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from insightface) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from insightface) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from insightface) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from insightface) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from insightface) (0.25.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (from insightface) (3.0.12)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (from insightface) (2.0.8)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (from insightface) (3.17.0)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (25.12.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (1.14.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (6.0.3)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (2.12.3)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations->insightface) (4.6.0)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations->insightface) (6.5.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (2.9.0.post0)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx->insightface) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx->insightface) (0.5.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable->insightface) (0.2.14)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (2026.1.4)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (3.6.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (2026.1.14)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->insightface) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->insightface) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.17.0)\n",
            "Downloading onnxruntime_gpu-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (300.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m300.5/300.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp312-cp312-linux_x86_64.whl size=1071489 sha256=0df0a04305c61a12ddc0221fbdd6168700c430b50911045b51655894415f08b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/3c/e2/6d4815e8a8b33a2006554d65ce0d1f973e768f4c7a222fa675\n",
            "Successfully built insightface\n",
            "Installing collected packages: humanfriendly, onnx, coloredlogs, onnxruntime-gpu, insightface\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 insightface-0.7.3 onnx-1.20.1 onnxruntime-gpu-1.23.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "import urllib.request\n",
        "import tempfile\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from insightface.app import FaceAnalysis\n",
        "\n",
        "import shutil\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "n5gEePfQTquz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smlzFBDvSadc",
        "outputId": "5e006176-bc28-475a-c57b-e314a002d3af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ì„¤ì • ìˆ˜ì • ---\n",
        "LOCAL_BASE_PATH = \"/content/FF_frames_local\"  # ì½”ë© ë¡œì»¬ ê²½ë¡œì—ì„œ ì‘ì—…\n",
        "GDRIVE_SAVE_BASE = \"/content/drive/MyDrive/HECTO/Dataset/final_files\" # ê²°ê³¼ë¬¼ì´ ì €ì¥ë  êµ¬ë“œ í´ë”\n",
        "GDRIVE_ZIP_PATH = os.path.join(GDRIVE_SAVE_BASE, \"FF_frames.zip\")\n",
        "JSON_DB_PATH = os.path.join(GDRIVE_SAVE_BASE, \"ff_face_metadata.json\")\n",
        "VERIFY_SAVE_PATH = os.path.join(GDRIVE_SAVE_BASE, \"FF_Verification\")\n",
        "\n",
        "# êµ¬ë“œì— ì €\n",
        "FINAL_SAVE_PATH = \"/content/drive/MyDrive/HECTO/Dataset/FF_Frames_Final\"\n",
        "\n",
        "NUM_FRAMES = 15\n",
        "SERVER_URL = \"http://kaldir.vc.in.tum.de/faceforensics/v3/\"\n",
        "FILELIST_URL = SERVER_URL + \"misc/filelist.json\"\n",
        "MANIPULATIONS = ['Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures']\n",
        "COMPRESSION = 'c23'"
      ],
      "metadata": {
        "id": "IsqQRx8kbRTB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì•„ì´ë”” ëŒ€ì—­ë³„ë¡œ ì¡°ì‘ë°©ì‹ ì„¤ì •í•˜ë„ë¡ ìˆ˜ì •\n",
        "def get_id_matched_dataset():\n",
        "    # 1. Real: 000.mp4 ~ 999.mp4ê¹Œì§€ 1,000ê°œ ê°•ì œ ìƒì„±\n",
        "    real_list = [f\"{i:03d}.mp4\" for i in range(1000)]\n",
        "\n",
        "    # 2. Fake: ì„œë²„ì˜ 500ê°œ ìŒì„ ì •ë°©í–¥/ì—­ë°©í–¥ìœ¼ë¡œ í’€ì–´ 1,000ê°œ ìƒì„±\n",
        "    print(\"ì„œë²„ì—ì„œ Fake ë§¤ì¹­ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...\")\n",
        "    with urllib.request.urlopen(FILELIST_URL) as url:\n",
        "        file_pairs = json.loads(url.read().decode())\n",
        "\n",
        "    fake_dict = {m: [] for m in MANIPULATIONS}\n",
        "\n",
        "    for pair in file_pairs:\n",
        "        # pairëŠ” ['000', '003'] ê°™ì€ í˜•íƒœì„\n",
        "        id_a, id_b = pair[0], pair[1]\n",
        "\n",
        "        # ë°©í–¥ 1: id_aë¥¼ ë°°ê²½(Target)ìœ¼ë¡œ ì‚¬ìš© (id_a_id_b.mp4)\n",
        "        try:\n",
        "            int_a = int(id_a)\n",
        "            if int_a < 1000:\n",
        "                method = MANIPULATIONS[min(int_a // 250, 3)]\n",
        "                fake_dict[method].append(f\"{id_a}_{id_b}.mp4\")\n",
        "        except: pass\n",
        "\n",
        "        # ë°©í–¥ 2: id_bë¥¼ ë°°ê²½(Target)ìœ¼ë¡œ ì‚¬ìš© (id_b_id_a.mp4)\n",
        "        try:\n",
        "            int_b = int(id_b)\n",
        "            if int_b < 1000:\n",
        "                method = MANIPULATIONS[min(int_b // 250, 3)]\n",
        "                fake_dict[method].append(f\"{id_b}_{id_a}.mp4\")\n",
        "        except: pass\n",
        "\n",
        "    # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì •ë ¬í•˜ì—¬ ìˆœì„œ ë³´ì¥\n",
        "    for m in MANIPULATIONS:\n",
        "        fake_dict[m].sort()\n",
        "\n",
        "    print(f\"âœ… ìµœì¢… ë¦¬ìŠ¤íŠ¸ í™•ì •: Real {len(real_list)}ê°œ / Fake ì´ {sum(len(v) for v in fake_dict.values())}ê°œ\")\n",
        "    return real_list, fake_dict"
      ],
      "metadata": {
        "id": "QIQlP0SabVKw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RetinaFace ì´ˆê¸°í™” (ëœë“œë§ˆí¬ ì¶”ì¶œì„ ìœ„í•´ landmark2d ì¶”ê°€)\n",
        "detector = FaceAnalysis(allowed_modules=['detection', 'landmark_2d'], providers=['CUDAExecutionProvider'])\n",
        "detector.prepare(ctx_id=0, det_size=(640, 640))\n",
        "\n",
        "# # providersë¥¼ ['CPUExecutionProvider']ë¡œ ë³€ê²½í•˜ê³  ctx_id=-1ë¡œ ì„¤ì •\n",
        "# detector = FaceAnalysis(allowed_modules=['detection', 'landmark_2d'], providers=['CPUExecutionProvider'])\n",
        "# detector.prepare(ctx_id=-1, det_size=(640, 640))\n",
        "\n",
        "def get_aligned_face(image, face_info, target_size=(256, 256)):\n",
        "    try:\n",
        "        h_img, w_img = image.shape[:2]\n",
        "        landmarks = getattr(face_info, 'kps', None)\n",
        "        bbox = getattr(face_info, 'bbox', None)\n",
        "        if bbox is None: return None\n",
        "\n",
        "        x1, y1, x2, y2 = bbox.astype(int)\n",
        "        center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "\n",
        "        # 1. ì •ë ¬ ì‹œë„ (ëˆˆ ìœ„ì¹˜ê°€ ìˆëŠ” ê²½ìš°)\n",
        "        if landmarks is not None and len(landmarks) >= 2:\n",
        "            left_eye, right_eye = landmarks[0], landmarks[1]\n",
        "            dy, dx = right_eye[1] - left_eye[1], right_eye[0] - left_eye[0]\n",
        "            angle = np.degrees(np.arctan2(dy, dx))\n",
        "\n",
        "            M = cv2.getRotationMatrix2D((float(center_x), float(center_y)), angle, 1.0)\n",
        "            image = cv2.warpAffine(image, M, (w_img, h_img), flags=cv2.INTER_CUBIC)\n",
        "\n",
        "        # 2. ì •ì‚¬ê° í¬ë¡­ ì˜ì—­ ê³„ì‚° (ì• ì´ˆì— ì •ì‚¬ê°ìœ¼ë¡œ ì¡ê¸°)\n",
        "        w_box, h_box = x2 - x1, y2 - y1\n",
        "        # ì–¼êµ´ì˜ ë” ê¸´ ìª½ì„ ê¸°ì¤€ìœ¼ë¡œ ë§ˆì§„(30%)ì„ í¬í•¨í•œ ì •ì‚¬ê° ë³€ ê¸¸ì´ ê²°ì •\n",
        "        side_length = int(max(w_box, h_box) * 1.3)\n",
        "\n",
        "        half_side = side_length // 2\n",
        "        nx1, ny1 = center_x - half_side, center_y - half_side\n",
        "        nx2, ny2 = center_x + half_side, center_y + half_side\n",
        "\n",
        "        # ì´ë¯¸ì§€ ê²½ê³„ë¥¼ ë²—ì–´ë‚˜ëŠ” ê²½ìš° íŒ¨ë”© ì²˜ë¦¬ (ê²€ì€ìƒ‰ìœ¼ë¡œ ì±„ì›€)\n",
        "        # ì´ë ‡ê²Œ í•´ì•¼ 'ì§œë¶€'ë˜ì§€ ì•Šê³  ì •ì‚¬ê° í˜•íƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
        "        pad_x1 = max(0, -nx1)\n",
        "        pad_y1 = max(0, -ny1)\n",
        "        pad_x2 = max(0, nx2 - w_img)\n",
        "        pad_y2 = max(0, ny2 - h_img)\n",
        "\n",
        "        nx1, ny1 = max(0, nx1), max(0, ny1)\n",
        "        nx2, ny2 = min(w_img, nx2), min(h_img, ny2)\n",
        "\n",
        "        face_crop = image[ny1:ny2, nx1:nx2]\n",
        "\n",
        "        # ë¶€ì¡±í•œ ë¶€ë¶„ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ ì±„ì›Œ ì •ì‚¬ê° ìœ ì§€\n",
        "        if pad_x1 > 0 or pad_y1 > 0 or pad_x2 > 0 or pad_y2 > 0:\n",
        "            face_crop = cv2.copyMakeBorder(face_crop, pad_y1, pad_y2, pad_x1, pad_x2,\n",
        "                                           cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "\n",
        "        return cv2.resize(face_crop, target_size)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def resize_with_letterbox(image, target_size=(256, 256)):\n",
        "    if image.size == 0: return np.zeros((target_size[1], target_size[0], 3), dtype=np.uint8)\n",
        "    h, w = image.shape[:2]\n",
        "    scale = min(target_size[0]/w, target_size[1]/h)\n",
        "    nw, nh = int(w * scale), int(h * scale)\n",
        "\n",
        "    img_resized = cv2.resize(image, (nw, nh))\n",
        "    canvas = np.zeros((target_size[1], target_size[0], 3), dtype=np.uint8)\n",
        "    dx, dy = (target_size[0]-nw)//2, (target_size[1]-nh)//2\n",
        "    canvas[dy:dy+nh, dx:dx+nw] = img_resized\n",
        "    return canvas"
      ],
      "metadata": {
        "id": "6XIt8uaPP611",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70698d3b-caef-4909-9272-55460354234b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download_path: /root/.insightface/models/buffalo_l\n",
            "Downloading /root/.insightface/models/buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281857/281857 [00:02<00:00, 102996.42KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/genderage.onnx genderage\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition\n",
            "set det-size: (640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_extract_combined(video_names, sub_path, category_name, label, detector, is_real=True):\n",
        "    # êµ¬ê¸€ ë“œë¼ì´ë¸Œ ìµœì¢… ì €ì¥ ê²½ë¡œ ì„¤ì •\n",
        "    save_dir = os.path.join(FINAL_SAVE_PATH, category_name)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # JSON DB ë¡œë“œ (ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì™€ì„œ ì´ì–´ì„œ ì‘ì—…)\n",
        "    metadata = {}\n",
        "    if os.path.exists(JSON_DB_PATH):\n",
        "        with open(JSON_DB_PATH, 'r') as f:\n",
        "            metadata = json.load(f)\n",
        "\n",
        "    for v_name in tqdm(video_names, desc=f\"Processing {category_name}\"):\n",
        "        video_id = v_name.split('.')[0]\n",
        "        video_folder = os.path.join(save_dir, video_id)\n",
        "\n",
        "        # ğŸ”¥ [ì´ì–´í•˜ê¸° ë¡œì§] ì´ë¯¸ í´ë”ê°€ ìˆê³  í”„ë ˆì„ì´ ë‹¤ ì°¨ìˆìœ¼ë©´ ìŠ¤í‚µ\n",
        "        if os.path.exists(video_folder) and len(os.listdir(video_folder)) >= NUM_FRAMES:\n",
        "            continue\n",
        "\n",
        "        os.makedirs(video_folder, exist_ok=True)\n",
        "        video_url = SERVER_URL + sub_path + v_name\n",
        "        target_id = video_id.split('_')[0] if not is_real else video_id\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(suffix='.mp4') as temp_v:\n",
        "            try:\n",
        "                urllib.request.urlretrieve(video_url, temp_v.name)\n",
        "                cap = cv2.VideoCapture(temp_v.name)\n",
        "                total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "                if total <= 0: continue\n",
        "                interval = max(1, total // NUM_FRAMES)\n",
        "\n",
        "                last_face_info = None\n",
        "                video_faces_found = False\n",
        "                frames_cache = []\n",
        "                face_crops_temp = []\n",
        "                current_video_metadata = [None] * NUM_FRAMES\n",
        "\n",
        "                for i in range(NUM_FRAMES):\n",
        "                    cap.set(cv2.CAP_PROP_POS_FRAMES, i * interval)\n",
        "                    ret, frame = cap.read()\n",
        "                    if not ret or frame is None:\n",
        "                        face_crops_temp.append(None)\n",
        "                        continue\n",
        "\n",
        "                    frames_cache.append(frame)\n",
        "                    face_to_save = None\n",
        "                    used_info = None\n",
        "\n",
        "                    if is_real:\n",
        "                        # [REAL] GPU ê°€ì† ì–¼êµ´ ê²€ì¶œ\n",
        "                        faces = detector.get(frame)\n",
        "                        if faces:\n",
        "                            used_info = sorted(faces, key=lambda x: (getattr(x, 'score', 0.0) or 0.0), reverse=True)[0]\n",
        "                            face_to_save = get_aligned_face(frame, used_info)\n",
        "\n",
        "                            if face_to_save is not None:\n",
        "                                # ì†Œê¸‰ ì ìš©\n",
        "                                if not video_faces_found and i > 0:\n",
        "                                    for prev_idx in range(len(face_crops_temp)):\n",
        "                                        if face_crops_temp[prev_idx] is None:\n",
        "                                            retro_crop = get_aligned_face(frames_cache[prev_idx], used_info)\n",
        "                                            face_crops_temp[prev_idx] = retro_crop\n",
        "                                            current_video_metadata[prev_idx] = {\n",
        "                                                \"bbox\": used_info.bbox.tolist(),\n",
        "                                                \"kps\": used_info.kps.tolist() if hasattr(used_info, 'kps') else None\n",
        "                                            }\n",
        "                                last_face_info = used_info\n",
        "                                video_faces_found = True\n",
        "\n",
        "                        if face_to_save is None and last_face_info is not None:\n",
        "                            face_to_save = get_aligned_face(frame, last_face_info)\n",
        "                            used_info = last_face_info\n",
        "                    else:\n",
        "                        # [FAKE] JSON ì¢Œí‘œ ì¬í™œìš© (êµ¬ë“œì—ì„œ ë¶ˆëŸ¬ì˜¨ metadata ì‚¬ìš©)\n",
        "                        if target_id in metadata and i < len(metadata[target_id]):\n",
        "                            info = metadata[target_id][i]\n",
        "                            if info:\n",
        "                                class FaceInfo: pass\n",
        "                                used_info = FaceInfo()\n",
        "                                used_info.bbox = np.array(info['bbox'])\n",
        "                                used_info.kps = np.array(info['kps']) if info['kps'] else None\n",
        "                                face_to_save = get_aligned_face(frame, used_info)\n",
        "                                video_faces_found = True\n",
        "\n",
        "                    face_crops_temp.append(face_to_save)\n",
        "                    if is_real and used_info and face_to_save is not None:\n",
        "                        current_video_metadata[i] = {\n",
        "                            \"bbox\": used_info.bbox.tolist(),\n",
        "                            \"kps\": used_info.kps.tolist() if hasattr(used_info, 'kps') else None\n",
        "                        }\n",
        "\n",
        "                # íŒŒì¼ ì €ì¥ (êµ¬ê¸€ ë“œë¼ì´ë¸Œë¡œ ì§ì ‘ ì“°ê¸°)\n",
        "                if video_faces_found:\n",
        "                    for idx, crop in enumerate(face_crops_temp):\n",
        "                        if crop is not None:\n",
        "                            cv2.imwrite(os.path.join(video_folder, f\"f{idx:03d}_{label}.jpg\"), crop)\n",
        "                else:\n",
        "                    for idx, frame in enumerate(frames_cache[:NUM_FRAMES]):\n",
        "                        full_resized = resize_with_letterbox(frame, (256, 256))\n",
        "                        cv2.imwrite(os.path.join(video_folder, f\"f{idx:03d}_{label}.jpg\"), full_resized)\n",
        "\n",
        "                # ğŸ”¥ [ì¤‘ìš”] ë§¤ ì˜ìƒ ì™„ë£Œ ì‹œë§ˆë‹¤ JSON ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸\n",
        "                if is_real:\n",
        "                    metadata[video_id] = current_video_metadata\n",
        "                    with open(JSON_DB_PATH, 'w') as f:\n",
        "                        json.dump(metadata, f)\n",
        "\n",
        "                cap.release()\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Error {v_name}: {e}\")"
      ],
      "metadata": {
        "id": "I5Gy9v-DQRSW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ìƒ˜í”Œ í™•ì¸ ì„¤ì • ---\n",
        "VERIFY_SAVE_PATH = \"/content/drive/MyDrive/HECTO/Dataset/FF_Verification\"\n",
        "\n",
        "def run_visual_verification(detector):\n",
        "    \"\"\"\n",
        "    ê° ì¡°ì‘ ë°©ì‹ë³„ë¡œ ì²« ë²ˆì§¸ Fake ì˜ìƒì„ ì„ ì •í•˜ê³ ,\n",
        "    ê·¸ì— ëŒ€ì‘í•˜ëŠ” Real ì˜ìƒì„ ìë™ìœ¼ë¡œ ì°¾ì•„ ê²€ì¦ ë¦¬ìŠ¤íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    print(\"ğŸ” ìƒ˜í”Œ ê²€ì¦ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "    if os.path.exists(VERIFY_SAVE_PATH):\n",
        "        shutil.rmtree(VERIFY_SAVE_PATH)\n",
        "    os.makedirs(VERIFY_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "    # 1. ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
        "    real_videos, fake_videos_dict = get_id_matched_dataset()\n",
        "    verify_list = []\n",
        "    temp_metadata = {}\n",
        "\n",
        "    # 2. ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ Fake ìƒ˜í”Œ í•˜ë‚˜ì”© ì„ ì •í•˜ê³ , ëŒ€ì‘í•˜ëŠ” Realë„ ì„¸íŠ¸ë¡œ ì¶”ê°€\n",
        "    # ì´ë ‡ê²Œ í•´ì•¼ Fake ì²˜ë¦¬ ì‹œ í•„ìš”í•œ Realì˜ JSON ì¢Œí‘œê°€ ë°˜ë“œì‹œ ì¡´ì¬í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
        "    for method in MANIPULATIONS:\n",
        "        v_list = fake_videos_dict.get(method, [])\n",
        "        if not v_list:\n",
        "            print(f\"âš ï¸ ê²½ê³ : {method} ì¹´í…Œê³ ë¦¬ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            continue\n",
        "\n",
        "        # ì²« ë²ˆì§¸ ê°€ì§œ ì˜ìƒ ì„ íƒ (ì˜ˆ: '751_752.mp4')\n",
        "        fake_v_name = v_list[0]\n",
        "        target_id = fake_v_name.split('_')[0] # '751' ì¶”ì¶œ\n",
        "\n",
        "        # í•´ë‹¹ ê°€ì§œ ì˜ìƒì˜ ì›ë³¸(Real) íŒŒì¼ëª… ìƒì„± (ì˜ˆ: '751.mp4')\n",
        "        real_v_name = target_id + \".mp4\"\n",
        "\n",
        "        if real_v_name in real_videos:\n",
        "            # Real ë¨¼ì € ì¶”ê°€ (ì¢Œí‘œ ìƒì„±ì„ ìœ„í•´)\n",
        "            verify_list.append((\"Real\", [real_v_name], f\"original_sequences/youtube/{COMPRESSION}/videos/\", 0, True))\n",
        "            # ê·¸ ë‹¤ìŒ Fake ì¶”ê°€ (ì¢Œí‘œ ì¬í™œìš©ì„ ìœ„í•´)\n",
        "            verify_list.append((f\"Fake/{method}\", [fake_v_name], f\"manipulated_sequences/{method}/{COMPRESSION}/videos/\", 1, False))\n",
        "        else:\n",
        "            print(f\"âš ï¸ ê²½ê³ : {method}ì˜ íƒ€ê²Ÿ ID {target_id}ì— í•´ë‹¹í•˜ëŠ” ì›ë³¸ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    # 3. ìœ„ì—ì„œ êµ¬ì„±ëœ ë¦¬ìŠ¤íŠ¸ ìˆœì°¨ ì²˜ë¦¬\n",
        "    for category, v_names, sub_path, label, is_real in verify_list:\n",
        "        v_name = v_names[0]\n",
        "        video_id = v_name.split('.')[0]\n",
        "        target_id = video_id.split('_')[0] if not is_real else video_id\n",
        "\n",
        "        # ì˜ìƒë³„ ê°œë³„ í´ë” ìƒì„±\n",
        "        video_folder = os.path.join(VERIFY_SAVE_PATH, category, video_id)\n",
        "        os.makedirs(video_folder, exist_ok=True)\n",
        "\n",
        "        print(f\"ğŸ“¸ {category} ì²˜ë¦¬ ì¤‘: {video_id}\")\n",
        "        video_url = SERVER_URL + sub_path + v_name\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(suffix='.mp4') as temp_v:\n",
        "            try:\n",
        "                urllib.request.urlretrieve(video_url, temp_v.name)\n",
        "                cap = cv2.VideoCapture(temp_v.name)\n",
        "                for i in range(5): # 5í”„ë ˆì„ì”© ê²€ì¦\n",
        "                    cap.set(cv2.CAP_PROP_POS_FRAMES, i * 10)\n",
        "                    ret, frame = cap.read()\n",
        "                    if not ret: break\n",
        "\n",
        "                    face_to_save = None\n",
        "                    if is_real:\n",
        "                        # [REAL] ì§ì ‘ ê²€ì¶œ ë° ì¢Œí‘œ ì €ì¥\n",
        "                        faces = detector.get(frame)\n",
        "                        if faces:\n",
        "                            # scoreê°€ Noneì¸ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ 0.0 ì²˜ë¦¬\n",
        "                            used_info = sorted(faces, key=lambda x: (getattr(x, 'score', 0.0) or 0.0), reverse=True)[0]\n",
        "                            face_to_save = get_aligned_face(frame, used_info)\n",
        "                            if target_id not in temp_metadata: temp_metadata[target_id] = []\n",
        "                            temp_metadata[target_id].append({\n",
        "                                \"bbox\": used_info.bbox.tolist(),\n",
        "                                \"kps\": used_info.kps.tolist() if hasattr(used_info, 'kps') else None\n",
        "                            })\n",
        "                    else:\n",
        "                        # [FAKE] ì €ì¥ëœ ì¢Œí‘œ ì¬í™œìš©\n",
        "                        if target_id in temp_metadata and i < len(temp_metadata[target_id]):\n",
        "                            class FaceInfo: pass\n",
        "                            info = temp_metadata[target_id][i]\n",
        "                            f_obj = FaceInfo()\n",
        "                            f_obj.bbox = np.array(info['bbox'])\n",
        "                            f_obj.kps = np.array(info['kps']) if info['kps'] else None\n",
        "                            face_to_save = get_aligned_face(frame, f_obj)\n",
        "\n",
        "                    if face_to_save is not None:\n",
        "                        cv2.imwrite(os.path.join(video_folder, f\"f{i:03d}_{label}.jpg\"), face_to_save)\n",
        "                cap.release()\n",
        "            except Exception as e:\n",
        "                print(f\"   -> âŒ {video_id} ì—ëŸ¬: {e}\")\n",
        "\n",
        "    print(f\"\\nâœ… ê²€ì¦ ì™„ë£Œ! êµ¬ê¸€ ë“œë¼ì´ë¸Œ í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”: {VERIFY_SAVE_PATH}\")"
      ],
      "metadata": {
        "id": "3lRljISdkN0Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- [ì£¼ì˜] FINAL_SAVE_PATHê°€ 4ë²ˆì§¸ ì…€ì—ì„œ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤ ---\n",
        "# FINAL_SAVE_PATH = \"/content/drive/MyDrive/HECTO/Dataset/FF_Frames_Final\"\n",
        "\n",
        "# 1. í™˜ê²½ ì¤€ë¹„ (í´ë” ì‚­ì œ ë¡œì§ ì œê±° - ì´ì–´í•˜ê¸°ë¥¼ ìœ„í•´)\n",
        "if not os.path.exists(FINAL_SAVE_PATH):\n",
        "    os.makedirs(FINAL_SAVE_PATH, exist_ok=True)\n",
        "    print(f\"âœ… ìƒˆ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±: {FINAL_SAVE_PATH}\")\n",
        "else:\n",
        "    print(f\"â„¹ï¸ ê¸°ì¡´ ë””ë ‰í† ë¦¬ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤. (ì´ì–´í•˜ê¸° ëª¨ë“œ)\")\n",
        "\n",
        "# 2. ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„\n",
        "real_videos, fake_videos_dict = get_id_matched_dataset()\n",
        "\n",
        "# 3. ë³¸ ì‘ì—… ì‹œì‘\n",
        "print(\"\\nğŸ¬ [1/2] Real ì˜ìƒ ì²˜ë¦¬ ë° JSON ì¢Œí‘œ DB êµ¬ì¶• ì‹œì‘...\")\n",
        "real_sub_path = f\"original_sequences/youtube/{COMPRESSION}/videos/\"\n",
        "process_and_extract_combined(real_videos, real_sub_path, \"Real\", 0, detector, is_real=True)\n",
        "\n",
        "print(\"\\nğŸ¬ [2/2] Fake ì˜ìƒ ID ë§¤ì¹­ ì²˜ë¦¬ ì‹œì‘ (ì¢Œí‘œ ì¬í™œìš©)...\")\n",
        "for method, v_list in fake_videos_dict.items():\n",
        "    fake_sub_path = f\"manipulated_sequences/{method}/{COMPRESSION}/videos/\"\n",
        "    process_and_extract_combined(v_list, fake_sub_path, f\"Fake/{method}\", 1, detector, is_real=False)\n",
        "\n",
        "print(\"\\nğŸ‰ ëª¨ë“  ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo0hhhIclGf_",
        "outputId": "ffd9aeb2-ab0a-45b7-a390-d5b61bd956d1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ìƒˆ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±: /content/drive/MyDrive/HECTO/Dataset/FF_Frames_Final\n",
            "ì„œë²„ì—ì„œ Fake ë§¤ì¹­ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...\n",
            "âœ… ìµœì¢… ë¦¬ìŠ¤íŠ¸ í™•ì •: Real 1000ê°œ / Fake ì´ 1000ê°œ\n",
            "\n",
            "ğŸ¬ [1/2] Real ì˜ìƒ ì²˜ë¦¬ ë° JSON ì¢Œí‘œ DB êµ¬ì¶• ì‹œì‘...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Real: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [2:13:13<00:00,  7.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ¬ [2/2] Fake ì˜ìƒ ID ë§¤ì¹­ ì²˜ë¦¬ ì‹œì‘ (ì¢Œí‘œ ì¬í™œìš©)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Fake/Deepfakes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [28:18<00:00,  6.80s/it]\n",
            "Processing Fake/Face2Face: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [29:55<00:00,  7.18s/it]\n",
            "Processing Fake/FaceSwap: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [33:00<00:00,  7.92s/it]\n",
            "Processing Fake/NeuralTextures: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [32:08<00:00,  7.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ‰ ëª¨ë“  ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ í™•ì¸í•˜ì„¸ìš”.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}