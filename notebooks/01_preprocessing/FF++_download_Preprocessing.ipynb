{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepfake-detection-model-project/Deepfake-Detection-Project/blob/jiwon-dev/notebooks/01_preprocessing/FF%2B%2B_download_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ê¸°ì¡´ ë¯¸ë””ì–´íŒŒì´í”„ ì„¤ì¹˜ ëŒ€ì‹  ì•„ë˜ ì‹¤í–‰\n",
        "!pip install insightface onnxruntime-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQsp_PSHRXlf",
        "outputId": "8ffd3272-aa90-48e7-fdc4-9f8b8dc8e094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/439.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from insightface) (2.0.2)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from insightface) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from insightface) (2.32.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from insightface) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from insightface) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from insightface) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from insightface) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from insightface) (0.25.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (from insightface) (3.0.12)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (from insightface) (2.0.8)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (from insightface) (3.17.0)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (25.12.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (1.14.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (6.0.3)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (2.12.3)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations->insightface) (4.6.0)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations->insightface) (6.5.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (2.9.0.post0)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx->insightface) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx->insightface) (0.5.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable->insightface) (0.2.14)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (2026.1.4)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (3.6.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (2025.12.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->insightface) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->insightface) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.17.0)\n",
            "Downloading onnxruntime_gpu-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (300.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m300.5/300.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp312-cp312-linux_x86_64.whl size=1071490 sha256=d4d3b3d202ca2c5a32e4e8128f61f23602855ddfb85b34dd6aeca70dcf80c3d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/3c/e2/6d4815e8a8b33a2006554d65ce0d1f973e768f4c7a222fa675\n",
            "Successfully built insightface\n",
            "Installing collected packages: humanfriendly, onnx, coloredlogs, onnxruntime-gpu, insightface\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 insightface-0.7.3 onnx-1.20.1 onnxruntime-gpu-1.23.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "import urllib.request\n",
        "import tempfile\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from insightface.app import FaceAnalysis"
      ],
      "metadata": {
        "id": "n5gEePfQTquz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smlzFBDvSadc",
        "outputId": "1e453b66-1532-438f-c142-bcb86b863864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ëœë¤ ì‹œë“œ ê³ ì •\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "\n",
        "# --- ì„¤ì • ---\n",
        "GDRIVE_BASE_PATH = \"/content/drive/MyDrive/HECTO/Dataset/FF_frames\"\n",
        "NUM_FRAMES = 15\n",
        "SERVER_URL = \"http://kaldir.vc.in.tum.de/faceforensics/v3/\"\n",
        "FILELIST_URL = SERVER_URL + \"misc/filelist.json\"\n",
        "\n",
        "# ì¡°ì‘ ë°©ì‹ ë¦¬ìŠ¤íŠ¸ (4ê°€ì§€ ì£¼ìš” ë°©ì‹)\n",
        "MANIPULATIONS = ['Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures']\n",
        "COMPRESSION = 'c23'"
      ],
      "metadata": {
        "id": "IsqQRx8kbRTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_balanced_dataset(sample_per_category=250, is_test=False):\n",
        "    print(\"ì„œë²„ì—ì„œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...\")\n",
        "    with urllib.request.urlopen(FILELIST_URL) as url:\n",
        "        file_pairs = json.loads(url.read().decode())\n",
        "\n",
        "    # í…ŒìŠ¤íŠ¸ ëª¨ë“œì¸ ê²½ìš° ì¹´í…Œê³ ë¦¬ë‹¹ 2ê°œë§Œ ì„ íƒ\n",
        "    if is_test:\n",
        "        sample_per_category = 2\n",
        "\n",
        "    # 1. Real ì˜ìƒ ë¦¬ìŠ¤íŠ¸ í™•ë³´ (ì „ì²´ì—ì„œ ìƒ˜í”Œë§)\n",
        "    # ê°€ì§œê°€ ì´ 4ì¢… * 250 = 1000ê°œì´ë¯€ë¡œ, ì§„ì§œë„ 1000ê°œ ì „ì²´ ì‚¬ìš©\n",
        "    # ìˆ˜ì •ëœ ë¦¬ìŠ¤íŠ¸ ìƒì„±ë¶€ (ì…€ 3 í™•ì¸)\n",
        "    real_list = []\n",
        "    for pair in file_pairs:\n",
        "        real_list.extend([pair[0] + '.mp4', pair[1] + '.mp4'])\n",
        "    # ì¤‘ë³µ ì œê±° (í˜¹ì‹œ ëª¨ë¥¼ ê²¹ì¹¨ ë°©ì§€)\n",
        "    real_list = sorted(list(set(real_list)))\n",
        "\n",
        "    if is_test:\n",
        "        real_list = random.sample(real_list, 2)\n",
        "    else:\n",
        "        # ê°€ì§œ ì´í•©ì— ë§ì¶° 1000ê°œ ìƒ˜í”Œë§ (FF++ ì›ë³¸ì€ ë”± 1000ê°œì´ë¯€ë¡œ ì…”í”Œë§Œ)\n",
        "        random.shuffle(real_list)\n",
        "\n",
        "    # 2. ê°€ì§œ ì˜ìƒ ë¦¬ìŠ¤íŠ¸ í™•ë³´ (ì¹´í…Œê³ ë¦¬ë³„ 250ê°œì”©)\n",
        "    fake_dict = {}\n",
        "    for method in MANIPULATIONS:\n",
        "        # ê° ì¡°ì‘ ë°©ì‹ë³„ë¡œ ëœë¤í•˜ê²Œ pair ì„ íƒ\n",
        "        sampled_pairs = random.sample(file_pairs, sample_per_category)\n",
        "        fake_dict[method] = ['_'.join(p) + '.mp4' for p in sampled_pairs]\n",
        "\n",
        "    return real_list, fake_dict\n"
      ],
      "metadata": {
        "id": "QIQlP0SabVKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RetinaFace ì´ˆê¸°í™” (ëœë“œë§ˆí¬ ì¶”ì¶œì„ ìœ„í•´ landmark2d ì¶”ê°€)\n",
        "detector = FaceAnalysis(allowed_modules=['detection', 'landmark_2d'], providers=['CUDAExecutionProvider'])\n",
        "detector.prepare(ctx_id=0, det_size=(640, 640))\n",
        "\n",
        "def get_aligned_face(image, face_info, target_size=(256, 256)):\n",
        "    try:\n",
        "        h_img, w_img = image.shape[:2]\n",
        "        landmarks = getattr(face_info, 'kps', None)\n",
        "        bbox = getattr(face_info, 'bbox', None)\n",
        "        if bbox is None: return None\n",
        "\n",
        "        x1, y1, x2, y2 = bbox.astype(int)\n",
        "        center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "\n",
        "        # 1. ì •ë ¬ ì‹œë„ (ëˆˆ ìœ„ì¹˜ê°€ ìˆëŠ” ê²½ìš°)\n",
        "        if landmarks is not None and len(landmarks) >= 2:\n",
        "            left_eye, right_eye = landmarks[0], landmarks[1]\n",
        "            dy, dx = right_eye[1] - left_eye[1], right_eye[0] - left_eye[0]\n",
        "            angle = np.degrees(np.arctan2(dy, dx))\n",
        "\n",
        "            M = cv2.getRotationMatrix2D((float(center_x), float(center_y)), angle, 1.0)\n",
        "            image = cv2.warpAffine(image, M, (w_img, h_img), flags=cv2.INTER_CUBIC)\n",
        "\n",
        "        # 2. ì •ì‚¬ê° í¬ë¡­ ì˜ì—­ ê³„ì‚° (ì• ì´ˆì— ì •ì‚¬ê°ìœ¼ë¡œ ì¡ê¸°)\n",
        "        w_box, h_box = x2 - x1, y2 - y1\n",
        "        # ì–¼êµ´ì˜ ë” ê¸´ ìª½ì„ ê¸°ì¤€ìœ¼ë¡œ ë§ˆì§„(30%)ì„ í¬í•¨í•œ ì •ì‚¬ê° ë³€ ê¸¸ì´ ê²°ì •\n",
        "        side_length = int(max(w_box, h_box) * 1.3)\n",
        "\n",
        "        half_side = side_length // 2\n",
        "        nx1, ny1 = center_x - half_side, center_y - half_side\n",
        "        nx2, ny2 = center_x + half_side, center_y + half_side\n",
        "\n",
        "        # ì´ë¯¸ì§€ ê²½ê³„ë¥¼ ë²—ì–´ë‚˜ëŠ” ê²½ìš° íŒ¨ë”© ì²˜ë¦¬ (ê²€ì€ìƒ‰ìœ¼ë¡œ ì±„ì›€)\n",
        "        # ì´ë ‡ê²Œ í•´ì•¼ 'ì§œë¶€'ë˜ì§€ ì•Šê³  ì •ì‚¬ê° í˜•íƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
        "        pad_x1 = max(0, -nx1)\n",
        "        pad_y1 = max(0, -ny1)\n",
        "        pad_x2 = max(0, nx2 - w_img)\n",
        "        pad_y2 = max(0, ny2 - h_img)\n",
        "\n",
        "        nx1, ny1 = max(0, nx1), max(0, ny1)\n",
        "        nx2, ny2 = min(w_img, nx2), min(h_img, ny2)\n",
        "\n",
        "        face_crop = image[ny1:ny2, nx1:nx2]\n",
        "\n",
        "        # ë¶€ì¡±í•œ ë¶€ë¶„ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ ì±„ì›Œ ì •ì‚¬ê° ìœ ì§€\n",
        "        if pad_x1 > 0 or pad_y1 > 0 or pad_x2 > 0 or pad_y2 > 0:\n",
        "            face_crop = cv2.copyMakeBorder(face_crop, pad_y1, pad_y2, pad_x1, pad_x2,\n",
        "                                           cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "\n",
        "        return cv2.resize(face_crop, target_size)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def resize_with_letterbox(image, target_size=(256, 256)):\n",
        "    if image.size == 0: return np.zeros((target_size[1], target_size[0], 3), dtype=np.uint8)\n",
        "    h, w = image.shape[:2]\n",
        "    scale = min(target_size[0]/w, target_size[1]/h)\n",
        "    nw, nh = int(w * scale), int(h * scale)\n",
        "\n",
        "    img_resized = cv2.resize(image, (nw, nh))\n",
        "    canvas = np.zeros((target_size[1], target_size[0], 3), dtype=np.uint8)\n",
        "    dx, dy = (target_size[0]-nw)//2, (target_size[1]-nh)//2\n",
        "    canvas[dy:dy+nh, dx:dx+nw] = img_resized\n",
        "    return canvas"
      ],
      "metadata": {
        "id": "6XIt8uaPP611",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ffb41d-1863-4bdb-8bef-88542b21b14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/genderage.onnx genderage\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition\n",
            "set det-size: (640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_extract(video_names, sub_path, category_name, label, detector):\n",
        "    \"\"\"\n",
        "    ì „ì²´ ë¹„ë””ì˜¤ ë¡œë“œ, ì²´í¬í¬ì¸íŠ¸, ì˜ˆì™¸ ì²˜ë¦¬ê°€ í†µí•©ëœ í’€ ë²„ì „\n",
        "    \"\"\"\n",
        "    save_dir = os.path.join(GDRIVE_BASE_PATH, category_name)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for v_name in tqdm(video_names, desc=f\"Processing {category_name}\"):\n",
        "        video_url = SERVER_URL + sub_path + v_name\n",
        "        video_id = v_name.split('.')[0]\n",
        "        video_folder = os.path.join(save_dir, video_id)\n",
        "\n",
        "        # [ì²´í¬í¬ì¸íŠ¸ ë¡œì§] ì´ë¯¸ 15í”„ë ˆì„ ì´ìƒ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ\n",
        "        if os.path.exists(video_folder) and len(os.listdir(video_folder)) >= NUM_FRAMES:\n",
        "            continue\n",
        "\n",
        "        os.makedirs(video_folder, exist_ok=True)\n",
        "\n",
        "        # ì„ì‹œ íŒŒì¼ì„ ìƒì„±í•˜ì—¬ ì„œë²„ì—ì„œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ\n",
        "        with tempfile.NamedTemporaryFile(suffix='.mp4') as temp_v:\n",
        "            try:\n",
        "                urllib.request.urlretrieve(video_url, temp_v.name)\n",
        "                cap = cv2.VideoCapture(temp_v.name)\n",
        "                total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "                if total <= 0:\n",
        "                    print(f\"âš ï¸ {v_name}: ì˜ìƒì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "                    continue\n",
        "\n",
        "                # 15í”„ë ˆì„ì„ ê³ ë¥´ê²Œ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ê°„ê²© ì„¤ì •\n",
        "                interval = max(1, total // NUM_FRAMES)\n",
        "\n",
        "                last_face_info = None\n",
        "                video_faces_found = False\n",
        "\n",
        "                for i in range(NUM_FRAMES):\n",
        "                    cap.set(cv2.CAP_PROP_POS_FRAMES, i * interval)\n",
        "                    ret, frame = cap.read()\n",
        "                    if not ret or frame is None:\n",
        "                        continue\n",
        "\n",
        "                    # 1. RetinaFace ê²€ì¶œ ì‹œë„\n",
        "                    faces = detector.get(frame)\n",
        "                    face_to_save = None\n",
        "\n",
        "                    if faces:\n",
        "                        # ì¸ì‹ ì„±ê³µ -> ì •ì‚¬ê° í¬ë¡­ (ì •ë ¬ í¬í•¨)\n",
        "                        # scoreê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ getattr ì‚¬ìš©\n",
        "                        face_info = sorted(faces, key=lambda x: getattr(x, 'score', 0.0) or 0.0, reverse=True)[0]\n",
        "                        face_to_save = get_aligned_face(frame, face_info)\n",
        "\n",
        "                        if face_to_save is not None:\n",
        "                            last_face_info = face_info\n",
        "                            video_faces_found = True\n",
        "\n",
        "                    # 2. ì¸ì‹ ì‹¤íŒ¨ ì‹œ -> ì´ì „ í”„ë ˆì„ ìœ„ì¹˜ ì •ë³´ í™œìš©\n",
        "                    if face_to_save is None and last_face_info is not None:\n",
        "                        face_to_save = get_aligned_face(frame, last_face_info)\n",
        "\n",
        "                    # ìµœì¢… ì´ë¯¸ì§€ ì €ì¥\n",
        "                    if face_to_save is not None:\n",
        "                        img_name = f\"f{i:03d}_{label}.jpg\"\n",
        "                        cv2.imwrite(os.path.join(video_folder, img_name), face_to_save)\n",
        "\n",
        "                # 3. [ìµœì¢… Fallback] ì˜ìƒ ë‚´ë‚´ ì–¼êµ´ì„ í•œ ë²ˆë„ ëª» ì°¾ì€ ê²½ìš°\n",
        "                if not video_faces_found:\n",
        "                    for i in range(NUM_FRAMES):\n",
        "                        cap.set(cv2.CAP_PROP_POS_FRAMES, i * interval)\n",
        "                        ret, frame = cap.read()\n",
        "                        if ret and frame is not None:\n",
        "                            # ì–¼êµ´ì´ ì—†ìœ¼ë¯€ë¡œ ì „ì²´ í”„ë ˆì„ì„ ì •ì‚¬ê° ë¦¬ì‚¬ì´ì¦ˆ(ì§œë¶€)í•˜ì—¬ ì €ì¥\n",
        "                            full_resized = cv2.resize(frame, (256, 256))\n",
        "                            img_name = f\"f{i:03d}_{label}.jpg\"\n",
        "                            cv2.imwrite(os.path.join(video_folder, img_name), full_resized)\n",
        "\n",
        "                cap.release()\n",
        "\n",
        "            except Exception as e:\n",
        "                # ì—ëŸ¬ ë°œìƒ ì‹œ í´ë”ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì‚­ì œ (ë‹¤ì‹œ ì‹œë„í•  ìˆ˜ ìˆë„ë¡)\n",
        "                if os.path.exists(video_folder) and not os.listdir(video_folder):\n",
        "                    os.rmdir(video_folder)\n",
        "                print(f\"âŒ Error {v_name}: {e}\")"
      ],
      "metadata": {
        "id": "I5Gy9v-DQRSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ì‹¤í–‰ ë¶€ë¶„ ---\n",
        "\n",
        "# 1. í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì„¤ì • (Trueì¼ ê²½ìš° ê° ì¹´í…Œê³ ë¦¬ë‹¹ 2ê°œì”©ë§Œ ìƒ˜í”Œë§)\n",
        "IS_TEST_MODE = False\n",
        "\n",
        "# ë°ì´í„°ì…‹ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
        "real_videos, fake_videos_dict = get_balanced_dataset(is_test=IS_TEST_MODE)\n",
        "print(f\"ğŸ“Š ì²˜ë¦¬ ì˜ˆì • Real ì˜ìƒ ê°œìˆ˜: {len(real_videos)}\")\n",
        "\n",
        "# 2. Real ì˜ìƒ ì²˜ë¦¬\n",
        "# detectorëŠ” ì´ì „ì— ì •ì˜í•œ RetinaFace ê°ì²´(app)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "real_sub_path = f\"original_sequences/youtube/{COMPRESSION}/videos/\"\n",
        "print(\"\\nğŸ¬ [1/2] Real ì˜ìƒ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "process_and_extract(real_videos, real_sub_path, \"Real\", 0, detector)\n",
        "\n",
        "# 3. Fake ì˜ìƒ ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬\n",
        "print(\"\\nğŸ¬ [2/2] Fake ì˜ìƒ ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
        "for method, v_list in fake_videos_dict.items():\n",
        "    fake_sub_path = f\"manipulated_sequences/{method}/{COMPRESSION}/videos/\"\n",
        "    category_name = f\"Fake/{method}\"\n",
        "\n",
        "    print(f\"\\nğŸ” {method} ì²˜ë¦¬ ì¤‘... (ì˜ìƒ ê°œìˆ˜: {len(v_list)})\")\n",
        "    # ì¹´í…Œê³ ë¦¬ ì´ë¦„ì— ë”°ë¼ í´ë” êµ¬ì¡°ê°€ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤ (ì˜ˆ: Fake/Deepfakes)\n",
        "    process_and_extract(v_list, fake_sub_path, category_name, 1, detector)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸ‰ ëª¨ë“  ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "print(f\"ğŸ“‚ ì €ì¥ ê²½ë¡œ: {GDRIVE_BASE_PATH}\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ffsLhLzbW_h",
        "outputId": "c79ff647-8427-4200-9e74-b87aae0140c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì„œë²„ì—ì„œ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...\n",
            "ğŸ“Š ì²˜ë¦¬ ì˜ˆì • Real ì˜ìƒ ê°œìˆ˜: 1000\n",
            "\n",
            "ğŸ¬ [1/2] Real ì˜ìƒ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Real: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [2:19:51<00:00,  8.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ¬ [2/2] Fake ì˜ìƒ ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n",
            "\n",
            "ğŸ” Deepfakes ì²˜ë¦¬ ì¤‘... (ì˜ìƒ ê°œìˆ˜: 250)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Fake/Deepfakes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [35:36<00:00,  8.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ” Face2Face ì²˜ë¦¬ ì¤‘... (ì˜ìƒ ê°œìˆ˜: 250)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Fake/Face2Face: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [34:57<00:00,  8.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ” FaceSwap ì²˜ë¦¬ ì¤‘... (ì˜ìƒ ê°œìˆ˜: 250)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Fake/FaceSwap: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [33:59<00:00,  8.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ” NeuralTextures ì²˜ë¦¬ ì¤‘... (ì˜ìƒ ê°œìˆ˜: 250)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Fake/NeuralTextures: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [34:17<00:00,  8.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "ğŸ‰ ëª¨ë“  ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
            "ğŸ“‚ ì €ì¥ ê²½ë¡œ: /content/drive/MyDrive/HECTO/Dataset/FF_frames\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}