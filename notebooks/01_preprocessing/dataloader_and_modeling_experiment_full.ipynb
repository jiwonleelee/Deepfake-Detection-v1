{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO48BLI24FGgrn7bQIsTYRi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepfake-detection-model-project/Deepfake-Detection-Project/blob/jiwon-dev/notebooks/01_preprocessing/dataloader_and_modeling_experiment_full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í• ì¼: ì••ì¶•íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° -> ë¡œì»¬ì—ì„œ ì••ì¶•í’€ê¸° -> ê²½ë¡œ ìˆ˜ì •í•˜ê¸°"
      ],
      "metadata": {
        "id": "apVNFOpYpJNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install timm # í˜„ì¬ ì½”ë©ì— ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì„œ ì£¼ì„ì²˜ë¦¬ í•¨"
      ],
      "metadata": {
        "id": "2gYXWlQZPfah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import gc"
      ],
      "metadata": {
        "id": "WH3tSGvTPZkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VPw09SGCs7oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¡œì»¬ì—ì„œ ì••ì¶• í•´ì œ (ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì—†ìŒ)\n",
        "!unzip -q /content/drive/MyDrive/HECTO/Dataset/images_data.zip -d /content/data_local"
      ],
      "metadata": {
        "id": "L2eAoSQr862o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ ì„¤ì • (ë³¸ì¸ì˜ ë“œë¼ì´ë¸Œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • ê°€ëŠ¥)\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/HECTO/checkpoints/01_backbone_selection'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# 3. ë°ì´í„°ì…‹ ê²½ë¡œ\n",
        "CSV_PATH = '/content/drive/MyDrive/HECTO/Dataset/CSV/total_local_path.csv'\n",
        "\n",
        "print(f\"âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ: {CHECKPOINT_DIR}\")"
      ],
      "metadata": {
        "id": "lI5k7luTO2cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    # Python ê¸°ë°˜ ì‹œë“œ ê³ ì •\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    # PyTorch ì‹œë“œ ê³ ì •\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    # CuDNN ê²°ì •ë¡ ì  ì—°ì‚° ì„¤ì •\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# ì‹œë“œ ì„¤ì •\n",
        "EXPERIMENT_SEED = 42\n",
        "set_seed(EXPERIMENT_SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"âœ… ì‹œë“œ {EXPERIMENT_SEED} ê³ ì • ì™„ë£Œ ë° {device} ì¤€ë¹„\")"
      ],
      "metadata": {
        "id": "mieyyaqCO47W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepfakeDataset(Dataset):\n",
        "    def __init__(self, csv_path, split='train', transform=None):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        self.data = df[df['split'] == split].reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data.loc[idx, 'frame_path']\n",
        "        label = self.data.loc[idx, 'label']\n",
        "        video_id = self.data.loc[idx, 'video_id']\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.float32), video_id\n",
        "\n",
        "# ì›Œì»¤ ì‹œë“œ ê³ ì • í•¨ìˆ˜\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(EXPERIMENT_SEED)\n",
        "\n",
        "# ê¸°ë³¸ ì¦ê°• ì„¤ì •\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    # 1. ê¸°í•˜í•™ì  ë³€í™˜ (256x256 ì›ë³¸ í•´ìƒë„ì—ì„œ ìˆ˜í–‰)\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "\n",
        "    # 2. í™”ì§ˆ ë° ìƒ‰ìƒ ë³€í™˜\n",
        "    transforms.RandomApply([\n",
        "        transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
        "    ], p=0.3),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "\n",
        "    # 3. ì„¼í„° í¬ë¡­ (Resize ëŒ€ì‹  ì‚¬ìš©)\n",
        "    # 256x256 ì´ë¯¸ì§€ì˜ ì¤‘ì•™ì—ì„œ 224x224ë¥¼ ì˜ë¼ë‚´ì–´ í”½ì…€ ì™œê³¡ì„ ë°©ì§€í•©ë‹ˆë‹¤.\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "\n",
        "    # 4. í…ì„œí™” ë° ì •ê·œí™”\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "    # 5. ê°€ë ¤ì§ ëŒ€ë¹„ (ToTensor ì´í›„ ì ìš©)\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    # 1. ì„¼í„° í¬ë¡­\n",
        "    # í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ ì¤‘ì•™ ì˜ì—­ì„ 224x224ë¡œ ì˜ë¼ëƒ…ë‹ˆë‹¤.\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "\n",
        "    # 2. í…ì„œí™” ë° ì •ê·œí™”\n",
        "    # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ íŒŒë¼ë¯¸í„°ì™€ ì™„ë²½íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "gHgu-5mvO6X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_acc_max = 0\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_acc):\n",
        "        score = val_acc\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "\n",
        "# ì²´í¬í¬ì¸íŠ¸ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜\n",
        "def save_checkpoint(state, is_best, model_name):\n",
        "    # 1. ì¼ë°˜ ì²´í¬í¬ì¸íŠ¸ (í•™ìŠµ ì¬ê°œìš©)\n",
        "    filename = os.path.join(CHECKPOINT_DIR, f\"{model_name}_checkpoint.pth.tar\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "    # 2. ë² ìŠ¤íŠ¸ ëª¨ë¸ ë”°ë¡œ ì €ì¥ (ë‚˜ì¤‘ì— í…ŒìŠ¤íŠ¸/ë°°í¬ìš©)\n",
        "    if is_best:\n",
        "        best_filename = os.path.join(CHECKPOINT_DIR, f\"{model_name}_best.pth.tar\")\n",
        "        torch.save(state, best_filename)\n",
        "        print(f\"â­ ìµœê³  ì„±ëŠ¥ ê°±ì‹ ! ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {best_filename}\")\n",
        "\n",
        "def load_checkpoint(model_name, model, optimizer):\n",
        "    filename = os.path.join(CHECKPOINT_DIR, f\"{model_name}_checkpoint.pth.tar\")\n",
        "    if os.path.isfile(filename):\n",
        "        print(f\"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: {filename}\")\n",
        "        checkpoint = torch.load(filename)\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        best_acc = checkpoint['best_acc']\n",
        "        return start_epoch, best_acc\n",
        "    else:\n",
        "        print(\"ğŸ†• ì´ì „ ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ. ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
        "        return 0, 0"
      ],
      "metadata": {
        "id": "c-DtaIfzO9ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- [ì¶”ê°€] í•™ìŠµ í•¨ìˆ˜ ---\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels, _ in tqdm(dataloader, desc=\"  Training\", leave=False):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device).unsqueeze(1) # [Batch, 1] í˜•íƒœë¡œ ë³€í™˜\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # í”„ë ˆì„ ë‹¨ìœ„ ì •í™•ë„ (ì°¸ê³ ìš©)\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return running_loss / len(dataloader), correct / total\n",
        "\n",
        "# --- [ì¶”ê°€] ì˜ìƒ ë‹¨ìœ„ í‰ê·  ì ìˆ˜ ê²€ì¦ í•¨ìˆ˜ ---\n",
        "def validate_video_level(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # ì˜ìƒë³„ ì ìˆ˜ë¥¼ ëª¨ìœ¼ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬\n",
        "    video_scores = defaultdict(list)\n",
        "    video_labels = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, video_ids in tqdm(dataloader, desc=\"  Validating\", leave=False):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device).unsqueeze(1)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # ì‹œê·¸ëª¨ì´ë“œë¥¼ í†µê³¼ì‹œì¼œ 0~1 ì‚¬ì´ í™•ë¥ ê°’ ì¶”ì¶œ\n",
        "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "            labels_np = labels.cpu().numpy()\n",
        "\n",
        "            for i in range(len(video_ids)):\n",
        "                vid = video_ids[i]\n",
        "                video_scores[vid].append(probs[i])\n",
        "                video_labels[vid] = labels_np[i]\n",
        "\n",
        "    # ğŸ”¥ ì˜ìƒ ë‹¨ìœ„ í‰ê·  ì ìˆ˜ ê³„ì‚° (ì‚¬ìš©ìë‹˜ì´ ìš”ì²­í•˜ì‹  ë¡œì§)\n",
        "    correct = 0\n",
        "    for vid in video_scores:\n",
        "        avg_prob = np.mean(video_scores[vid]) # í”„ë ˆì„ ì ìˆ˜ í‰ê· \n",
        "        final_pred = 1 if avg_prob > 0.5 else 0\n",
        "        if final_pred == video_labels[vid]:\n",
        "            correct += 1\n",
        "\n",
        "    video_acc = correct / len(video_scores)\n",
        "    return running_loss / len(dataloader), video_acc"
      ],
      "metadata": {
        "id": "jtxXilo75YQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‹¤í—˜ ëŒ€ìƒ ëª¨ë¸\n",
        "model_names = ['resnet50', 'efficientnet_b0', 'vit_tiny_patch16_224', 'convnext_tiny']\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "MAX_EPOCHS = 20  # ì–¼ë¦¬ìŠ¤íƒ‘ì´ ìˆìœ¼ë¯€ë¡œ ë„‰ë„‰íˆ ì¡ìŠµë‹ˆë‹¤.\n",
        "BATCH_SIZE = 32\n",
        "LR = 1e-4\n",
        "\n",
        "# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "results_summary = []\n",
        "\n",
        "# ë°ì´í„° ë¡œë” ì¤€ë¹„\n",
        "train_dataset = DeepfakeDataset(CSV_PATH, split='train', transform=train_transform)\n",
        "val_dataset = DeepfakeDataset(CSV_PATH, split='val', transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=2, worker_init_fn=seed_worker, generator=g)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "JoNIZc-HPAL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m_name in model_names:\n",
        "    print(f\"\\n\" + \"=\"*50)\n",
        "    print(f\"ğŸš€ Experiment Start: {m_name}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 1. ëª¨ë¸ ì´ˆê¸°í™” (Binary Classificationì„ ìœ„í•´ num_classes=1 ì„¤ì •)\n",
        "    model = timm.create_model(m_name, pretrained=True, num_classes=1).to(device)\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
        "\n",
        "    # ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸° (ì¤‘ë‹¨ëœ ê²½ìš° ëŒ€ë¹„)\n",
        "    start_epoch, best_acc = load_checkpoint(m_name, model, optimizer)\n",
        "\n",
        "    for epoch in range(start_epoch, MAX_EPOCHS):\n",
        "        print(f\"\\n[Epoch {epoch+1}/{MAX_EPOCHS}]\")\n",
        "\n",
        "        # í•™ìŠµ\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "        # ê²€ì¦ (ì˜ìƒ ë‹¨ìœ„ í‰ê°€)\n",
        "        val_loss, video_acc = validate_video_level(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"  Val Loss:   {val_loss:.4f} | Video-level Val Acc: {video_acc:.4f}\")\n",
        "\n",
        "        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì—¬ë¶€ í™•ì¸\n",
        "        is_best = video_acc > best_acc\n",
        "        if is_best:\n",
        "            best_acc = video_acc\n",
        "\n",
        "        # ì²´í¬í¬ì¸íŠ¸ ë° ë² ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ì €ì¥\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'best_acc': best_acc,\n",
        "        }, is_best, m_name)\n",
        "\n",
        "        # ì–¼ë¦¬ìŠ¤íƒ‘ í™•ì¸\n",
        "        early_stopping(video_acc)\n",
        "        if early_stopping.early_stop:\n",
        "            print(f\"ğŸ›‘ {m_name} Early Stopping!\")\n",
        "            break\n",
        "\n",
        "    results_summary.append({'Model': m_name, 'Best Video Acc': best_acc})\n",
        "\n",
        "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    del model, optimizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
        "print(\"\\n\" + \"ğŸ† Final Comparison Report \" + \"ğŸ†\")\n",
        "df_res = pd.DataFrame(results_summary)\n",
        "print(df_res.sort_values(by='Best Video Acc', ascending=False))"
      ],
      "metadata": {
        "id": "2w8rQFAu5ipV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}