{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO48BLI24FGgrn7bQIsTYRi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8b411acfdb5247ee90a9c94a5bb83cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6889cc6c88f440009c796e42e3616581",
              "IPY_MODEL_02fb38262bd64d91b95f166fd0b2bc92",
              "IPY_MODEL_0c8819b10f484236ab7f2acda5d781e6"
            ],
            "layout": "IPY_MODEL_efda58ba0e1843689272cb0aabe96203"
          }
        },
        "6889cc6c88f440009c796e42e3616581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dcf7ce2bd9e41c7bdaa9a2273c02785",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d45824721d314feea45c21520527e14e",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "02fb38262bd64d91b95f166fd0b2bc92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59fd11e4c59e4e3e98c7bc4760c45001",
            "max": 102469840,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a14e8b5b30244da9b5b13af701b4b60",
            "value": 102469840
          }
        },
        "0c8819b10f484236ab7f2acda5d781e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f908ef798cf424e839fb020a55178ac",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d37021cd661b44e3b6d57dcdb7412f14",
            "value": "‚Äá102M/102M‚Äá[00:01&lt;00:00,‚Äá134MB/s]"
          }
        },
        "efda58ba0e1843689272cb0aabe96203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dcf7ce2bd9e41c7bdaa9a2273c02785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d45824721d314feea45c21520527e14e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59fd11e4c59e4e3e98c7bc4760c45001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a14e8b5b30244da9b5b13af701b4b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f908ef798cf424e839fb020a55178ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d37021cd661b44e3b6d57dcdb7412f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepfake-detection-model-project/Deepfake-Detection-Project/blob/jiwon-dev/notebooks/01_preprocessing/dataloader_and_modeling_experiment_full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ìï†Ïùº: ÏïïÏ∂ïÌååÏùº Î∂àÎü¨Ïò§Í∏∞ -> Î°úÏª¨ÏóêÏÑú ÏïïÏ∂ïÌíÄÍ∏∞ -> Í≤ΩÎ°ú ÏàòÏ†ïÌïòÍ∏∞"
      ],
      "metadata": {
        "id": "apVNFOpYpJNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install timm # ÌòÑÏû¨ ÏΩîÎû©Ïóê Ïù¥ÎØ∏ ÏÑ§ÏπòÎêòÏñ¥ ÏûàÏñ¥ÏÑú Ï£ºÏÑùÏ≤òÎ¶¨ Ìï®"
      ],
      "metadata": {
        "id": "2gYXWlQZPfah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import gc"
      ],
      "metadata": {
        "id": "WH3tSGvTPZkd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏å ÎßàÏö¥Ìä∏\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPw09SGCs7oB",
        "outputId": "a3fb086a-a761-4096-805b-1e3c8ad248d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Î°úÏª¨ÏóêÏÑú ÏïïÏ∂ï Ìï¥Ï†ú (ÎÑ§Ìä∏ÏõåÌÅ¨ ÏßÄÏó∞ ÏóÜÏùå)\n",
        "!unzip -q /content/drive/MyDrive/HECTO/Dataset/images_data.zip -d /content/data_local"
      ],
      "metadata": {
        "id": "L2eAoSQr862o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû• Í≤ΩÎ°ú ÏÑ§Ï†ï (Î≥∏Ïù∏Ïùò ÎìúÎùºÏù¥Î∏å Í≤ΩÎ°úÏóê ÎßûÍ≤å ÏàòÏ†ï Í∞ÄÎä•)\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/HECTO/checkpoints/01_backbone_selection'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# 3. Îç∞Ïù¥ÌÑ∞ÏÖã Í≤ΩÎ°ú\n",
        "CSV_PATH = '/content/drive/MyDrive/HECTO/Dataset/CSV/total_local_path.csv'\n",
        "\n",
        "print(f\"‚úÖ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû• Í≤ΩÎ°ú: {CHECKPOINT_DIR}\")"
      ],
      "metadata": {
        "id": "lI5k7luTO2cn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c2f49f-0f7d-4850-8bbc-f90e32aa6744"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû• Í≤ΩÎ°ú: /content/drive/MyDrive/HECTO/checkpoints/01_backbone_selection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    # Python Í∏∞Î∞ò ÏãúÎìú Í≥†Ï†ï\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    # PyTorch ÏãúÎìú Í≥†Ï†ï\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    # CuDNN Í≤∞Ï†ïÎ°†Ï†Å Ïó∞ÏÇ∞ ÏÑ§Ï†ï\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# ÏãúÎìú ÏÑ§Ï†ï\n",
        "EXPERIMENT_SEED = 42\n",
        "set_seed(EXPERIMENT_SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"‚úÖ ÏãúÎìú {EXPERIMENT_SEED} Í≥†Ï†ï ÏôÑÎ£å Î∞è {device} Ï§ÄÎπÑ\")"
      ],
      "metadata": {
        "id": "mieyyaqCO47W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc734bc9-2a71-4878-c89b-b602f7b21bbd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ÏãúÎìú 42 Í≥†Ï†ï ÏôÑÎ£å Î∞è cuda Ï§ÄÎπÑ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepfakeDataset(Dataset):\n",
        "    def __init__(self, csv_path, split='train', transform=None):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        self.data = df[df['split'] == split].reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data.loc[idx, 'frame_path']\n",
        "        label = self.data.loc[idx, 'label']\n",
        "        video_id = self.data.loc[idx, 'video_id']\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.float32), video_id\n",
        "\n",
        "# ÏõåÏª§ ÏãúÎìú Í≥†Ï†ï Ìï®Ïàò\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(EXPERIMENT_SEED)\n",
        "\n",
        "# Í∏∞Î≥∏ Ï¶ùÍ∞ï ÏÑ§Ï†ï\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    # 1. Í∏∞ÌïòÌïôÏ†Å Î≥ÄÌôò (256x256 ÏõêÎ≥∏ Ìï¥ÏÉÅÎèÑÏóêÏÑú ÏàòÌñâ)\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "\n",
        "    # 2. ÌôîÏßà Î∞è ÏÉâÏÉÅ Î≥ÄÌôò\n",
        "    transforms.RandomApply([\n",
        "        transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
        "    ], p=0.3),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "\n",
        "    # 3. ÏÑºÌÑ∞ ÌÅ¨Î°≠ (Resize ÎåÄÏã† ÏÇ¨Ïö©)\n",
        "    # 256x256 Ïù¥ÎØ∏ÏßÄÏùò Ï§ëÏïôÏóêÏÑú 224x224Î•º ÏûòÎùºÎÇ¥Ïñ¥ ÌîΩÏÖÄ ÏôúÍ≥°ÏùÑ Î∞©ÏßÄÌï©ÎãàÎã§.\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "\n",
        "    # 4. ÌÖêÏÑúÌôî Î∞è Ï†ïÍ∑úÌôî\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "    # 5. Í∞ÄÎ†§Ïßê ÎåÄÎπÑ (ToTensor Ïù¥ÌõÑ Ï†ÅÏö©)\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    # 1. ÏÑºÌÑ∞ ÌÅ¨Î°≠\n",
        "    # ÌïôÏäµ ÏãúÏôÄ ÎèôÏùºÌïòÍ≤å Ï§ëÏïô ÏòÅÏó≠ÏùÑ 224x224Î°ú ÏûòÎùºÎÉÖÎãàÎã§.\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "\n",
        "    # 2. ÌÖêÏÑúÌôî Î∞è Ï†ïÍ∑úÌôî\n",
        "    # ÌïôÏäµ Ïãú ÏÇ¨Ïö©Ìïú ÌååÎùºÎØ∏ÌÑ∞ÏôÄ ÏôÑÎ≤ΩÌûà ÏùºÏπòÌï¥Ïïº Ìï©ÎãàÎã§.\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "gHgu-5mvO6X6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_acc_max = 0\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_acc):\n",
        "        score = val_acc\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "\n",
        "# Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû•/Î∂àÎü¨Ïò§Í∏∞ Ìï®Ïàò\n",
        "def save_checkpoint(state, is_best, model_name):\n",
        "    # 1. ÏùºÎ∞ò Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ (ÌïôÏäµ Ïû¨Í∞úÏö©)\n",
        "    filename = os.path.join(CHECKPOINT_DIR, f\"{model_name}_checkpoint.pth.tar\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "    # 2. Î≤†Ïä§Ìä∏ Î™®Îç∏ Îî∞Î°ú Ï†ÄÏû• (ÎÇòÏ§ëÏóê ÌÖåÏä§Ìä∏/Î∞∞Ìè¨Ïö©)\n",
        "    if is_best:\n",
        "        best_filename = os.path.join(CHECKPOINT_DIR, f\"{model_name}_best.pth.tar\")\n",
        "        torch.save(state, best_filename)\n",
        "        print(f\"‚≠ê ÏµúÍ≥† ÏÑ±Îä• Í∞±Ïã†! Î≤†Ïä§Ìä∏ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {best_filename}\")\n",
        "\n",
        "def load_checkpoint(model_name, model, optimizer):\n",
        "    filename = os.path.join(CHECKPOINT_DIR, f\"{model_name}_checkpoint.pth.tar\")\n",
        "    if os.path.isfile(filename):\n",
        "        print(f\"üîÑ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î∂àÎü¨Ïò§Îäî Ï§ë: {filename}\")\n",
        "        checkpoint = torch.load(filename)\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        best_acc = checkpoint['best_acc']\n",
        "        return start_epoch, best_acc\n",
        "    else:\n",
        "        print(\"üÜï Ïù¥Ï†Ñ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ ÏóÜÏùå. Ï≤òÏùåÎ∂ÄÌÑ∞ ÌïôÏäµÏùÑ ÏãúÏûëÌï©ÎãàÎã§.\")\n",
        "        return 0, 0"
      ],
      "metadata": {
        "id": "c-DtaIfzO9ge"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- [Ï∂îÍ∞Ä] ÌïôÏäµ Ìï®Ïàò ---\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels, _ in tqdm(dataloader, desc=\"  Training\", leave=False):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device).unsqueeze(1) # [Batch, 1] ÌòïÌÉúÎ°ú Î≥ÄÌôò\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # ÌîÑÎ†àÏûÑ Îã®ÏúÑ Ï†ïÌôïÎèÑ (Ï∞∏Í≥†Ïö©)\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return running_loss / len(dataloader), correct / total\n",
        "\n",
        "# --- [Ï∂îÍ∞Ä] ÏòÅÏÉÅ Îã®ÏúÑ ÌèâÍ∑† Ï†êÏàò Í≤ÄÏ¶ù Ìï®Ïàò ---\n",
        "def validate_video_level(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # ÏòÅÏÉÅÎ≥Ñ Ï†êÏàòÎ•º Î™®ÏúºÍ∏∞ ÏúÑÌïú ÎîïÏÖîÎÑàÎ¶¨\n",
        "    video_scores = defaultdict(list)\n",
        "    video_labels = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels, video_ids in tqdm(dataloader, desc=\"  Validating\", leave=False):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device).unsqueeze(1)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # ÏãúÍ∑∏Î™®Ïù¥ÎìúÎ•º ÌÜµÍ≥ºÏãúÏºú 0~1 ÏÇ¨Ïù¥ ÌôïÎ•†Í∞í Ï∂îÏ∂ú\n",
        "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "            labels_np = labels.cpu().numpy()\n",
        "\n",
        "            for i in range(len(video_ids)):\n",
        "                vid = video_ids[i]\n",
        "                video_scores[vid].append(probs[i])\n",
        "                video_labels[vid] = labels_np[i]\n",
        "\n",
        "    # üî• ÏòÅÏÉÅ Îã®ÏúÑ ÌèâÍ∑† Ï†êÏàò Í≥ÑÏÇ∞ (ÏÇ¨Ïö©ÏûêÎãòÏù¥ ÏöîÏ≤≠ÌïòÏã† Î°úÏßÅ)\n",
        "    correct = 0\n",
        "    for vid in video_scores:\n",
        "        avg_prob = np.mean(video_scores[vid]) # ÌîÑÎ†àÏûÑ Ï†êÏàò ÌèâÍ∑†\n",
        "        final_pred = 1 if avg_prob > 0.5 else 0\n",
        "        if final_pred == video_labels[vid]:\n",
        "            correct += 1\n",
        "\n",
        "    video_acc = correct / len(video_scores)\n",
        "    return running_loss / len(dataloader), video_acc"
      ],
      "metadata": {
        "id": "jtxXilo75YQ3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ïã§Ìóò ÎåÄÏÉÅ Î™®Îç∏\n",
        "model_names = ['resnet50', 'efficientnet_b0', 'vit_tiny_patch16_224', 'convnext_tiny']\n",
        "\n",
        "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞\n",
        "MAX_EPOCHS = 20  # ÏñºÎ¶¨Ïä§ÌÉëÏù¥ ÏûàÏúºÎØÄÎ°ú ÎÑâÎÑâÌûà Ïû°ÏäµÎãàÎã§.\n",
        "BATCH_SIZE = 32\n",
        "LR = 1e-4\n",
        "\n",
        "# Í≤∞Í≥ºÎ•º Ï†ÄÏû•Ìï† Î¶¨Ïä§Ìä∏\n",
        "results_summary = []\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ Î°úÎçî Ï§ÄÎπÑ\n",
        "train_dataset = DeepfakeDataset(CSV_PATH, split='train', transform=train_transform)\n",
        "val_dataset = DeepfakeDataset(CSV_PATH, split='val', transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=2, worker_init_fn=seed_worker, generator=g)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "JoNIZc-HPAL7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m_name in model_names:\n",
        "    print(f\"\\n\" + \"=\"*50)\n",
        "    print(f\"üöÄ Experiment Start: {m_name}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 1. Î™®Îç∏ Ï¥àÍ∏∞Ìôî (Binary ClassificationÏùÑ ÏúÑÌï¥ num_classes=1 ÏÑ§Ï†ï)\n",
        "    model = timm.create_model(m_name, pretrained=True, num_classes=1).to(device)\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
        "\n",
        "    # Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î∂àÎü¨Ïò§Í∏∞ (Ï§ëÎã®Îêú Í≤ΩÏö∞ ÎåÄÎπÑ)\n",
        "    start_epoch, best_acc = load_checkpoint(m_name, model, optimizer)\n",
        "\n",
        "    for epoch in range(start_epoch, MAX_EPOCHS):\n",
        "        print(f\"\\n[Epoch {epoch+1}/{MAX_EPOCHS}]\")\n",
        "\n",
        "        # ÌïôÏäµ\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "        # Í≤ÄÏ¶ù (ÏòÅÏÉÅ Îã®ÏúÑ ÌèâÍ∞Ä)\n",
        "        val_loss, video_acc = validate_video_level(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"  Val Loss:   {val_loss:.4f} | Video-level Val Acc: {video_acc:.4f}\")\n",
        "\n",
        "        # Î≤†Ïä§Ìä∏ Î™®Îç∏ Ïó¨Î∂Ä ÌôïÏù∏\n",
        "        is_best = video_acc > best_acc\n",
        "        if is_best:\n",
        "            best_acc = video_acc\n",
        "\n",
        "        # Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î∞è Î≤†Ïä§Ìä∏ Í∞ÄÏ§ëÏπò Ï†ÄÏû•\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'best_acc': best_acc,\n",
        "        }, is_best, m_name)\n",
        "\n",
        "        # ÏñºÎ¶¨Ïä§ÌÉë ÌôïÏù∏\n",
        "        early_stopping(video_acc)\n",
        "        if early_stopping.early_stop:\n",
        "            print(f\"üõë {m_name} Early Stopping!\")\n",
        "            break\n",
        "\n",
        "    results_summary.append({'Model': m_name, 'Best Video Acc': best_acc})\n",
        "\n",
        "    # Î©îÎ™®Î¶¨ Ï†ïÎ¶¨\n",
        "    del model, optimizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# ÏµúÏ¢Ö Í≤∞Í≥º Ï∂úÎ†•\n",
        "print(\"\\n\" + \"üèÜ Final Comparison Report \" + \"üèÜ\")\n",
        "df_res = pd.DataFrame(results_summary)\n",
        "print(df_res.sort_values(by='Best Video Acc', ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939,
          "referenced_widgets": [
            "8b411acfdb5247ee90a9c94a5bb83cab",
            "6889cc6c88f440009c796e42e3616581",
            "02fb38262bd64d91b95f166fd0b2bc92",
            "0c8819b10f484236ab7f2acda5d781e6",
            "efda58ba0e1843689272cb0aabe96203",
            "4dcf7ce2bd9e41c7bdaa9a2273c02785",
            "d45824721d314feea45c21520527e14e",
            "59fd11e4c59e4e3e98c7bc4760c45001",
            "7a14e8b5b30244da9b5b13af701b4b60",
            "3f908ef798cf424e839fb020a55178ac",
            "d37021cd661b44e3b6d57dcdb7412f14"
          ]
        },
        "id": "2w8rQFAu5ipV",
        "outputId": "5005f08f-96ad-494b-f796-80593de3c8e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "üöÄ Experiment Start: resnet50\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b411acfdb5247ee90a9c94a5bb83cab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üÜï Ïù¥Ï†Ñ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ ÏóÜÏùå. Ï≤òÏùåÎ∂ÄÌÑ∞ ÌïôÏäµÏùÑ ÏãúÏûëÌï©ÎãàÎã§.\n",
            "\n",
            "[Epoch 1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Train Loss: 0.5121 | Train Acc: 0.7299\n",
            "  Val Loss:   0.4062 | Video-level Val Acc: 0.8730\n",
            "‚≠ê ÏµúÍ≥† ÏÑ±Îä• Í∞±Ïã†! Î≤†Ïä§Ìä∏ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: /content/drive/MyDrive/HECTO/checkpoints/01_backbone_selection/resnet50_best.pth.tar\n",
            "\n",
            "[Epoch 2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Train Loss: 0.2976 | Train Acc: 0.8693\n",
            "  Val Loss:   0.3636 | Video-level Val Acc: 0.8836\n",
            "‚≠ê ÏµúÍ≥† ÏÑ±Îä• Í∞±Ïã†! Î≤†Ïä§Ìä∏ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: /content/drive/MyDrive/HECTO/checkpoints/01_backbone_selection/resnet50_best.pth.tar\n",
            "\n",
            "[Epoch 3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Train Loss: 0.2201 | Train Acc: 0.9067\n",
            "  Val Loss:   0.3664 | Video-level Val Acc: 0.9101\n",
            "‚≠ê ÏµúÍ≥† ÏÑ±Îä• Í∞±Ïã†! Î≤†Ïä§Ìä∏ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: /content/drive/MyDrive/HECTO/checkpoints/01_backbone_selection/resnet50_best.pth.tar\n",
            "\n",
            "[Epoch 4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3781088255.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# ÌïôÏäµ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Í≤ÄÏ¶ù (ÏòÅÏÉÅ Îã®ÏúÑ ÌèâÍ∞Ä)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3176960500.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}