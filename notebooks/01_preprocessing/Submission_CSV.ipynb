{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install insightface"
      ],
      "metadata": {
        "id": "4U4vKsAf2cPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf36b19-06b2-429b-ea63-cbcb5fc2651a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from insightface) (2.0.2)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from insightface) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from insightface) (2.32.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from insightface) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from insightface) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from insightface) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from insightface) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from insightface) (0.25.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (from insightface) (3.0.12)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (from insightface) (2.0.8)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (from insightface) (3.17.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (6.0.3)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (2.12.3)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations->insightface) (4.6.0)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations->insightface) (6.5.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (2.9.0.post0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx->insightface) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx->insightface) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx->insightface) (0.5.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable->insightface) (0.2.14)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (2026.1.4)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (3.6.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (2026.1.14)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->insightface) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->insightface) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.17.0)\n",
            "Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m131.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp312-cp312-linux_x86_64.whl size=1071491 sha256=f115af346638df3945f0dc51253cb592bf2f0f328b1262da1b487e983355e60e\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/3c/e2/6d4815e8a8b33a2006554d65ce0d1f973e768f4c7a222fa675\n",
            "Successfully built insightface\n",
            "Installing collected packages: onnx, insightface\n",
            "Successfully installed insightface-0.7.3 onnx-1.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime"
      ],
      "metadata": {
        "id": "wXC1etS_sktS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae64e1a-2460-4384-836a-edfbd1ddd6cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.12.19)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.14.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m125.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.23.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "from insightface.app import FaceAnalysis\n",
        "import zipfile\n",
        "import gc\n",
        "from google.colab import drive\n",
        "import random\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "AhXORV9MxaHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "SAMPLE_CSV_PATH = \"/content/drive/MyDrive/HECTO/Dataset/sample_submission.csv\"\n",
        "ZIP_SAVE_PATH = \"/content/drive/MyDrive/HECTO/Dataset/test_pp.zip\"\n",
        "CKPT_PATH = \"/content/drive/MyDrive/HECTO/checkpoints/01_backbone_selection/convnext_tiny_best.pth.tar\"\n",
        "CSV_SAVE_PATH = \"/content/drive/MyDrive/HECTO/Dataset/submission.csv\""
      ],
      "metadata": {
        "id": "ZoNX17muGSWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3903331e-1471-432b-d156-14a4d95ad6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "bBiIzJ72HGvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1️⃣ 파이썬에서 디렉토리 만들기 (권장)\n",
        "os.makedirs(\"/content/TEST_DIR\", exist_ok=True)\n",
        "\n",
        "# 2️⃣ 셸 명령으로 압축 풀기\n",
        "!unzip -q \"/content/drive/MyDrive/HECTO/Dataset/test_pp.zip\" -d /content/TEST_DIR\n"
      ],
      "metadata": {
        "id": "rURuwpTWsR_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "metadata": {
        "id": "dU0R6jw1G2tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_EXTS = ['jpg', 'jpeg', 'png', 'jfif']\n",
        "VID_EXTS = ['mp4', 'mov', 'avi']"
      ],
      "metadata": {
        "id": "T6cVdGZGIZZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single_image(model, image, tta=False):\n",
        "    \"\"\"\n",
        "    단일 이미지 예측\n",
        "    - tta=True이면 사진에서만 TTA 적용\n",
        "    \"\"\"\n",
        "    if tta:\n",
        "        # 사진용 TTA\n",
        "        tta_transform = A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.RandomBrightnessContrast(p=0.5),\n",
        "            A.ShiftScaleRotate(\n",
        "                shift_limit=0.02,\n",
        "                scale_limit=0.02,\n",
        "                rotate_limit=0,\n",
        "                border_mode=cv2.BORDER_CONSTANT,\n",
        "                p=0.3\n",
        "            ),\n",
        "            A.CenterCrop(height=224, width=224, p=1.0),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "        base_transform = A.Compose([\n",
        "            A.CenterCrop(height=224, width=224, p=1.0),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "        imgs = [base_transform(image=image)['image']]\n",
        "        for _ in range(9):  # 총 10장\n",
        "            imgs.append(tta_transform(image=image)['image'])\n",
        "\n",
        "        input_tensor = torch.stack(imgs).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_tensor)\n",
        "            probs = torch.sigmoid(outputs).squeeze()\n",
        "        return probs.mean().item()\n",
        "\n",
        "    else:\n",
        "        # 영상 프레임용, TTA 없이 단일 이미지\n",
        "        transform = A.Compose([\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "        img_tensor = transform(image=image)['image'].unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(img_tensor)\n",
        "            prob = torch.sigmoid(output).item()\n",
        "        return prob\n"
      ],
      "metadata": {
        "id": "8A0cQVzs1kri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = timm.create_model(\"convnext_tiny\", pretrained=False, num_classes=1)\n",
        "checkpoint = torch.load(CKPT_PATH, map_location=device)\n",
        "model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "xUobQfNX2Vu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67752bdc-1763-4552-b71d-f2e479977a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNeXt(\n",
              "  (stem): Sequential(\n",
              "    (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
              "    (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
              "  )\n",
              "  (stages): Sequential(\n",
              "    (0): ConvNeXtStage(\n",
              "      (downsample): Identity()\n",
              "      (blocks): Sequential(\n",
              "        (0): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): ConvNeXtStage(\n",
              "      (downsample): Sequential(\n",
              "        (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
              "        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "          (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): ConvNeXtStage(\n",
              "      (downsample): Sequential(\n",
              "        (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
              "        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (6): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (7): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (8): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): ConvNeXtStage(\n",
              "      (downsample): Sequential(\n",
              "        (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): ConvNeXtBlock(\n",
              "          (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU()\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (shortcut): Identity()\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (norm_pre): Identity()\n",
              "  (head): NormMlpClassifierHead(\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
              "    (norm): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "    (pre_logits): Identity()\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (fc): Linear(in_features=768, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_DIR = \"/content/TEST_DIR\""
      ],
      "metadata": {
        "id": "iBjxOHGh29cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = pd.read_csv(SAMPLE_CSV_PATH)\n",
        "final_probs = []\n",
        "\n",
        "# ---------------- 추론 (Inference) 시작 ----------------\n",
        "for filename in tqdm(sample_df['filename'], desc=\"Inference\"):\n",
        "    file_stem = Path(filename).stem  # 예: TEST_000\n",
        "    file_ext = filename.lower().split('.')[-1]\n",
        "\n",
        "    # ---------- [CASE 1] 영상 처리 (폴더 구조: TEST_000 / frame_0.jpg ...) ----------\n",
        "    if file_ext in VID_EXTS:\n",
        "        # 영상 이름과 동일한 이름을 가진 '폴더' 경로 설정\n",
        "        video_folder = os.path.join(TEST_DIR, file_stem)\n",
        "\n",
        "        if os.path.exists(video_folder):\n",
        "            # 폴더 내의 프레임 파일들을 숫자 순서대로 정렬 (frame0, frame1...)\n",
        "            matched_frames = sorted(\n",
        "                [f for f in os.listdir(video_folder) if f.lower().endswith('.jpg')],\n",
        "                key=lambda x: int(''.join(filter(str.isdigit, x))) # 파일명에서 숫자만 추출해 정렬\n",
        "            )\n",
        "\n",
        "            frame_scores = []\n",
        "            for f_name in matched_frames:\n",
        "                img_path = os.path.join(video_folder, f_name)\n",
        "                img_bgr = cv2.imread(img_path)\n",
        "                if img_bgr is None: continue\n",
        "                image = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # 영상은 이미 224로 전처리되었으므로 TTA 적용 시에도 일관성 유지\n",
        "                frame_scores.append(predict_single_image(model, image, tta=False))\n",
        "\n",
        "            # 프레임들의 평균 점수 계산\n",
        "            final_probs.append(np.mean(frame_scores) if frame_scores else 0.5)\n",
        "        else:\n",
        "            final_probs.append(0.5) # 폴더 자체가 없는 경우\n",
        "\n",
        "    # ---------- [CASE 2] 사진 처리 (파일 구조: TEST_001.jpg ...) ----------\n",
        "    elif file_ext in IMG_EXTS:\n",
        "        img_path = os.path.join(TEST_DIR, filename)\n",
        "\n",
        "        # 파일이 없을 경우를 대비해 확장자 무시하고 탐색\n",
        "        if not os.path.exists(img_path):\n",
        "            possible_files = [f for f in os.listdir(TEST_DIR) if f.startswith(file_stem)]\n",
        "            if possible_files:\n",
        "                img_path = os.path.join(TEST_DIR, possible_files[0])\n",
        "            else:\n",
        "                final_probs.append(0.5)\n",
        "                continue\n",
        "\n",
        "        img_bgr = cv2.imread(img_path)\n",
        "        if img_bgr is None:\n",
        "            final_probs.append(0.5)\n",
        "            continue\n",
        "\n",
        "        image = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "        # 사진은 256 -> 224 CenterCrop 포함된 TTA 적용\n",
        "        final_probs.append(predict_single_image(model, image, tta=True))\n",
        "\n",
        "    # ---------- [CASE 3] 기타 ----------\n",
        "    else:\n",
        "        final_probs.append(0.5)\n",
        "# ---------------- CSV 저장 ----------------\n",
        "sample_df['prob'] = final_probs\n",
        "sample_df.to_csv(CSV_SAVE_PATH, index=False)\n",
        "print(f\"✅ submission.csv 생성 완료 → {CSV_SAVE_PATH}\")"
      ],
      "metadata": {
        "id": "vnIocXNEoVBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2824c5-0be7-4e12-9fa6-940b4b55fc7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference:   0%|          | 1/500 [00:04<33:56,  4.08s/it]/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Inference: 100%|██████████| 500/500 [00:49<00:00, 10.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ submission.csv 생성 완료 → /content/drive/MyDrive/HECTO/Dataset/submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}
