{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPXwh5Sk0AhG5+br32zWK30"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJe-6Xz36_Sg",
        "outputId": "65afdaed-eb7d-42aa-f3bd-18228a177815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/439.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[32m337.9/439.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from insightface) (2.0.2)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from insightface) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from insightface) (2.32.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from insightface) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from insightface) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from insightface) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from insightface) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from insightface) (0.25.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (from insightface) (3.0.12)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (from insightface) (2.0.8)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (from insightface) (3.17.0)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (25.12.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime-gpu) (1.14.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (6.0.3)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (2.12.3)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations->insightface) (4.6.0)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations->insightface) (6.5.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (2.9.0.post0)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx->insightface) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx->insightface) (0.5.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable->insightface) (0.2.14)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (2026.1.4)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (3.6.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (2026.1.14)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->insightface) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->insightface) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.17.0)\n",
            "Downloading onnxruntime_gpu-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (300.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m300.5/300.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp312-cp312-linux_x86_64.whl size=1071492 sha256=e6466f8995525348254d145781e99caeb3edf1d3b8db5f84370bb41e1e187625\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/3c/e2/6d4815e8a8b33a2006554d65ce0d1f973e768f4c7a222fa675\n",
            "Successfully built insightface\n",
            "Installing collected packages: humanfriendly, onnx, coloredlogs, onnxruntime-gpu, insightface\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 insightface-0.7.3 onnx-1.20.1 onnxruntime-gpu-1.23.2\n"
          ]
        }
      ],
      "source": [
        "!pip install insightface onnxruntime-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import shutil\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "import tempfile\n",
        "import random\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from insightface.app import FaceAnalysis\n",
        "from google.colab import drive\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "vVJ4eARz-TiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo0Xp--l-Xu8",
        "outputId": "9084c66b-5aff-4140-e74f-46296fe1e1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "1FK34NNYApAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ZIP_PATH = \"/content/drive/MyDrive/Celeb-DF-v2.zip\"\n",
        "SAVE_BASE_PATH = \"/content/drive/MyDrive/HECTO/Dataset/Celeb_frames\"\n",
        "\n",
        "NUM_FRAMES = 15\n",
        "TARGET_SIZE = (256, 256)"
      ],
      "metadata": {
        "id": "eE3VSeP--gwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# providers=['CUDAExecutionProvider']ë¡œ GPU ê°•ì œ ì‚¬ìš©\n",
        "detector = FaceAnalysis(allowed_modules=['detection', 'landmark_2d'], providers=['CUDAExecutionProvider'])\n",
        "detector.prepare(ctx_id=0, det_size=(640, 640))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh_5E4ga_jk3",
        "outputId": "b3a259f3-1781-4ec3-a6a4-cd97f3e68436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download_path: /root/.insightface/models/buffalo_l\n",
            "Downloading /root/.insightface/models/buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281857/281857 [00:03<00:00, 81789.80KB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/genderage.onnx genderage\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "model ignore: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition\n",
            "set det-size: (640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hybrid_face(image, face_info, target_size=(256, 256)):\n",
        "    try:\n",
        "        h, w = image.shape[:2]\n",
        "        bbox = face_info.bbox.astype(int)\n",
        "        landmarks = getattr(face_info, 'kps', None)\n",
        "\n",
        "        cx = (bbox[0] + bbox[2]) // 2\n",
        "        cy = (bbox[1] + bbox[3]) // 2\n",
        "\n",
        "        # 1ï¸âƒ£ ì •ë ¬\n",
        "        if landmarks is not None and len(landmarks) >= 2:\n",
        "            left_eye, right_eye = landmarks[0], landmarks[1]\n",
        "            dy, dx = right_eye[1] - left_eye[1], right_eye[0] - left_eye[0]\n",
        "            angle = np.degrees(np.arctan2(dy, dx))\n",
        "            M = cv2.getRotationMatrix2D((float(cx), float(cy)), angle, 1.0)\n",
        "            image = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC)\n",
        "\n",
        "        # 2ï¸âƒ£ ì •ì‚¬ê° í¬ë¡­\n",
        "        side = int(max(bbox[2]-bbox[0], bbox[3]-bbox[1]) * 1.3)\n",
        "        half = side // 2\n",
        "\n",
        "        x1, y1 = cx - half, cy - half\n",
        "        x2, y2 = cx + half, cy + half\n",
        "\n",
        "        px1, py1 = max(0, -x1), max(0, -y1)\n",
        "        px2, py2 = max(0, x2 - w), max(0, y2 - h)\n",
        "\n",
        "        x1, y1 = max(0, x1), max(0, y1)\n",
        "        x2, y2 = min(w, x2), min(h, y2)\n",
        "\n",
        "        crop = image[y1:y2, x1:x2]\n",
        "\n",
        "        if px1 or py1 or px2 or py2:\n",
        "            crop = cv2.copyMakeBorder(\n",
        "                crop, py1, py2, px1, px2,\n",
        "                cv2.BORDER_CONSTANT, value=[0, 0, 0]\n",
        "            )\n",
        "\n",
        "        return cv2.resize(crop, target_size)\n",
        "\n",
        "    except:\n",
        "        return None"
      ],
      "metadata": {
        "id": "fnwyYCbYAU_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_preprocessing():\n",
        "    # ì €ì¥ ê²½ë¡œ ì´ˆê¸°í™”\n",
        "    if os.path.exists(SAVE_BASE_PATH):\n",
        "        shutil.rmtree(SAVE_BASE_PATH)\n",
        "    os.makedirs(SAVE_BASE_PATH, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as z:\n",
        "        all_videos = [\n",
        "            f for f in z.namelist()\n",
        "            if f.lower().endswith('.mp4') and not os.path.basename(f).startswith('._')\n",
        "        ]\n",
        "\n",
        "        # ===============================\n",
        "        # ğŸ”§ ë°ì´í„° í•„í„°ë§ ë° ìƒ˜í”Œë§\n",
        "        # ===============================\n",
        "\n",
        "        # 1ï¸âƒ£ Celeb-realë§Œ Realë¡œ ì‚¬ìš©\n",
        "        real_videos = [\n",
        "            f for f in all_videos\n",
        "            if 'celeb-real' in f.lower()\n",
        "        ]\n",
        "\n",
        "        # 2ï¸âƒ£ Celeb-synthesis ì „ì²´\n",
        "        fake_all = [\n",
        "            f for f in all_videos\n",
        "            if 'celeb-synthesis' in f.lower()\n",
        "        ]\n",
        "        # 3ï¸âƒ£ Celeb-synthesisë¥¼ target ID ê¸°ì¤€ìœ¼ë¡œ ë¯¸ë¦¬ ë¬¶ê¸° (ì†ë„ ê°œì„ )\n",
        "        fake_by_target = defaultdict(list)\n",
        "\n",
        "        for fake_path in fake_all:\n",
        "            fake_stem = Path(fake_path).stem   # ì˜ˆ: id0_id00_0001\n",
        "\n",
        "            # âœ… targetì€ í•­ìƒ ë’¤ìª½\n",
        "            if '_' not in fake_stem:\n",
        "                continue\n",
        "\n",
        "            target_id = fake_stem.split('_', 1)[1]  # id00_0001\n",
        "            fake_by_target[target_id].append(fake_path)\n",
        "        # 4ï¸âƒ£ Celeb-real ê¸°ì¤€ 1:1 fake ë§¤ì¹­\n",
        "        matched_real_videos = []\n",
        "        matched_fake_videos = []\n",
        "        used_fakes = set()\n",
        "\n",
        "        for real_path in real_videos:\n",
        "            target_id = Path(real_path).stem\n",
        "            candidates = [\n",
        "                f for f in fake_by_target.get(target_id, [])\n",
        "                if f not in used_fakes\n",
        "            ]\n",
        "\n",
        "            if candidates:\n",
        "                chosen = random.choice(candidates)\n",
        "                matched_real_videos.append(real_path)\n",
        "                matched_fake_videos.append(chosen)\n",
        "                used_fakes.add(chosen)\n",
        "\n",
        "        # âœ… ì—¬ê¸°ì„œ í•œ ë²ˆë§Œ ë®ì–´ì“°ê¸°\n",
        "        real_videos = matched_real_videos\n",
        "        fake_videos = matched_fake_videos\n",
        "\n",
        "        print(f\"ğŸ“Š REAL (matched): {len(real_videos)}, FAKE (matched): {len(fake_videos)}\")\n",
        "        assert len(real_videos) == len(fake_videos)\n",
        "\n",
        "        # ===============================\n",
        "        # ğŸ”½ ì´í›„ ì „ì²˜ë¦¬ ë¡œì§ (ê¸°ì¡´ ê·¸ëŒ€ë¡œ)\n",
        "        # ===============================\n",
        "\n",
        "        for video_list, label_type in [(real_videos, \"REAL\"), (fake_videos, \"FAKE\")]:\n",
        "            print(f\"\\nğŸ”¥ {label_type} ì²˜ë¦¬ ì¤‘...\")\n",
        "\n",
        "            for file_path in tqdm(video_list):\n",
        "                video_name = Path(file_path).stem\n",
        "                label_dir = 'real' if label_type == \"REAL\" else 'fake'\n",
        "                person_id = video_name.split('_')[0]\n",
        "\n",
        "                save_dir = os.path.join(SAVE_BASE_PATH, label_dir, person_id, video_name)\n",
        "                os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "                with tempfile.NamedTemporaryFile(suffix=\".mp4\") as tmp:\n",
        "                    tmp.write(z.read(file_path))\n",
        "                    tmp.flush()\n",
        "\n",
        "                    cap = cv2.VideoCapture(tmp.name)\n",
        "                    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "                    if total <= 0:\n",
        "                        cap.release()\n",
        "                        continue\n",
        "\n",
        "                    indices = np.linspace(0, total - 1, NUM_FRAMES, dtype=int)\n",
        "\n",
        "                    face_crops = []\n",
        "                    frames_cache = []\n",
        "                    last_face_info = None\n",
        "\n",
        "                    for idx in indices:\n",
        "                        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
        "                        ret, frame = cap.read()\n",
        "                        if not ret or frame is None:\n",
        "                            continue\n",
        "\n",
        "                        frames_cache.append(frame)\n",
        "                        faces = detector.get(frame)\n",
        "                        crop = None\n",
        "\n",
        "                        if faces:\n",
        "                            face = max(\n",
        "                                faces,\n",
        "                                key=lambda x: (x.bbox[2]-x.bbox[0])*(x.bbox[3]-x.bbox[1])\n",
        "                            )\n",
        "                            crop = get_hybrid_face(frame, face)\n",
        "                            if crop is not None:\n",
        "                                last_face_info = face\n",
        "                        elif last_face_info is not None:\n",
        "                            crop = get_hybrid_face(frame, last_face_info)\n",
        "\n",
        "                        if crop is not None:\n",
        "                            if len(face_crops) == 0 and len(frames_cache) > 1:\n",
        "                                for i in range(len(frames_cache) - 1):\n",
        "                                    retro = get_hybrid_face(frames_cache[i], last_face_info)\n",
        "                                    face_crops.append(retro if retro is not None else crop)\n",
        "                            face_crops.append(crop)\n",
        "\n",
        "                    cap.release()\n",
        "\n",
        "                    if len(face_crops) == 0:\n",
        "                        for i, frame in enumerate(frames_cache[:NUM_FRAMES]):\n",
        "                            resized = cv2.resize(frame, TARGET_SIZE)\n",
        "                            cv2.imwrite(os.path.join(save_dir, f\"frame_{i}.jpg\"), resized)\n",
        "                    else:\n",
        "                        while len(face_crops) < NUM_FRAMES:\n",
        "                            face_crops.append(face_crops[-1])\n",
        "                        for i in range(NUM_FRAMES):\n",
        "                            cv2.imwrite(os.path.join(save_dir, f\"frame_{i}.jpg\"), face_crops[i])\n",
        "\n",
        "                gc.collect()\n",
        "\n",
        "    print(f\"\\nâœ… ì™„ë£Œ: {SAVE_BASE_PATH}\")\n",
        "\n",
        "run_preprocessing()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mePRPcj7DIQE",
        "outputId": "32171e09-aad8-43ae-8b07-6b982c68a3d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š REAL (matched): 558, FAKE (matched): 558\n",
            "\n",
            "ğŸ”¥ REAL ì²˜ë¦¬ ì¤‘...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 558/558 [09:32<00:00,  1.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”¥ FAKE ì²˜ë¦¬ ì¤‘...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 558/558 [10:51<00:00,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… ì™„ë£Œ: /content/drive/MyDrive/HECTO/Dataset/Celeb_frames\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_DIR = \"/content/drive/MyDrive/HECTO/Dataset/Celeb_frames\"\n",
        "DST_DIR = \"/content/drive/MyDrive/HECTO/Dataset/final_files\"\n",
        "ZIP_NAME = \"Celeb_frames_pp_final.zip\"\n",
        "\n",
        "os.makedirs(DST_DIR, exist_ok=True)\n",
        "\n",
        "zip_path = os.path.join(DST_DIR, ZIP_NAME)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for root, dirs, files in os.walk(SRC_DIR):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "\n",
        "            # zip ë‚´ë¶€ ê²½ë¡œ (Celeb_frames/... êµ¬ì¡° ìœ ì§€)\n",
        "            arcname = os.path.relpath(file_path, SRC_DIR)\n",
        "\n",
        "            zipf.write(file_path, arcname)\n",
        "\n",
        "print(f\"âœ… ì••ì¶• ì™„ë£Œ: {zip_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Zjh0wK4lU5h",
        "outputId": "b2b58093-291b-47a1-be9f-3f3ccaf914ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ì••ì¶• ì™„ë£Œ: /content/drive/MyDrive/HECTO/Dataset/final_files/Celeb_frames_pp_final.zip\n"
          ]
        }
      ]
    }
  ]
}