{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install insightface"
      ],
      "metadata": {
        "id": "4U4vKsAf2cPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf757f8-85cc-42c0-8a23-9c1f288a2898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/439.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from insightface) (2.0.2)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from insightface) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from insightface) (2.32.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from insightface) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from insightface) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from insightface) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from insightface) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from insightface) (0.25.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (from insightface) (3.0.12)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (from insightface) (2.0.8)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.12/dist-packages (from insightface) (3.17.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (6.0.3)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (2.12.3)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations->insightface) (4.13.0.90)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations->insightface) (4.6.0)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations->insightface) (6.5.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->insightface) (2.9.0.post0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx->insightface) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx->insightface) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx->insightface) (0.5.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prettytable->insightface) (0.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->insightface) (2026.1.4)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (3.6.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (2026.1.14)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->insightface) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->insightface) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.17.0)\n",
            "Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp312-cp312-linux_x86_64.whl size=1071488 sha256=d43ceb993f1163932cf9a5bac0512c760e2e381ceff052107292a88c2d7566ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/3c/e2/6d4815e8a8b33a2006554d65ce0d1f973e768f4c7a222fa675\n",
            "Successfully built insightface\n",
            "Installing collected packages: onnx, insightface\n",
            "Successfully installed insightface-0.7.3 onnx-1.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime"
      ],
      "metadata": {
        "id": "wXC1etS_sktS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45aa6376-244e-4242-cace-89acc954a826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.12.19)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.14.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.23.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "from insightface.app import FaceAnalysis\n",
        "from google.colab import drive\n",
        "import random\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "AhXORV9MxaHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tunWsam6hlS",
        "outputId": "6980f353-341c-421d-d653-5eb7cf7cd6f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ëª¨ë¸ ì´ë¦„ì— ë”°ë¼ ìˆ˜ì •\n",
        "model_name = \"convnext_tiny\"\n",
        "name = \"convnext_tiny_only_ff_celeb(1-p)\"\n",
        "\n",
        "SAMPLE_CSV_PATH = \"/content/drive/MyDrive/HECTO/Dataset/sample_submission.csv\"\n",
        "ZIP_PATH = \"/content/drive/MyDrive/HECTO/Dataset/test_pp.zip\"\n",
        "CKPT_PATH = \"/content/drive/MyDrive/HECTO/checkpoints/04_convnext_different_lr_augmentation_only_ff_celeb/convnext_tiny_best.pth.tar\"\n",
        "CSV_SAVE_PATH = f\"/content/drive/MyDrive/HECTO/Dataset/{name}_submission.csv\"\n",
        "\n",
        "LOCAL_EXTRACT_BASE = Path(\"/content/Test_DIR\")"
      ],
      "metadata": {
        "id": "ZoNX17muGSWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if LOCAL_EXTRACT_BASE.exists():\n",
        "    shutil.rmtree(LOCAL_EXTRACT_BASE)\n",
        "LOCAL_EXTRACT_BASE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"ğŸ”“ ì••ì¶• í•´ì œ ì‹œì‘: {ZIP_PATH}\")\n",
        "# -q: quiet, -d: target directory\n",
        "!unzip -q \"{ZIP_PATH}\" -d \"{LOCAL_EXTRACT_BASE}\"\n",
        "print(\"âœ… ì••ì¶• í•´ì œ ì™„ë£Œ!\")\n",
        "\n",
        "data_list = []\n",
        "print(\"ğŸ” ë¡œì»¬ í´ë” ìŠ¤ìº” ì¤‘ (Real=1, Fake=0)...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvVcH8_u1VSU",
        "outputId": "6fb6bcbe-dcb7-4979-a0eb-5487f19fbaa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”“ ì••ì¶• í•´ì œ ì‹œì‘: /content/drive/MyDrive/HECTO/Dataset/test_pp.zip\n",
            "âœ… ì••ì¶• í•´ì œ ì™„ë£Œ!\n",
            "ğŸ” ë¡œì»¬ í´ë” ìŠ¤ìº” ì¤‘ (Real=1, Fake=0)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "bBiIzJ72HGvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "metadata": {
        "id": "dU0R6jw1G2tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- ëª¨ë¸ ë¡œë“œ ----------------\n",
        "model = timm.create_model(\n",
        "    model_name,          # \"convnext_tiny\"\n",
        "    pretrained=False,\n",
        "    num_classes=1        # binary classification (logit 1ê°œ)\n",
        ")\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
        "\n",
        "# ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° ëŒ€ì‘\n",
        "if 'state_dict' in ckpt:\n",
        "    state_dict = ckpt['state_dict']\n",
        "else:\n",
        "    state_dict = ckpt\n",
        "\n",
        "# multi-gpu í•™ìŠµ ì‹œ 'module.' ì œê±°\n",
        "new_state_dict = {}\n",
        "for k, v in state_dict.items():\n",
        "    if k.startswith(\"module.\"):\n",
        "        k = k[len(\"module.\"):]\n",
        "    new_state_dict[k] = v\n",
        "\n",
        "model.load_state_dict(new_state_dict, strict=True)\n",
        "\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmLLyrV5LfDx",
        "outputId": "bb739d69-d8fc-45e3-bca7-9746acf66dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_EXTS = ['jpg', 'jpeg', 'png', 'jfif']\n",
        "VID_EXTS = ['mp4', 'mov', 'avi']"
      ],
      "metadata": {
        "id": "T6cVdGZGIZZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single_image(model, image, tta=False):\n",
        "    \"\"\"\n",
        "    ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡\n",
        "    - tta=Trueì´ë©´ ì‚¬ì§„ì—ì„œë§Œ TTA ì ìš©\n",
        "    \"\"\"\n",
        "    if tta:\n",
        "        # ì‚¬ì§„ìš© TTA\n",
        "        tta_transform = A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.RandomBrightnessContrast(p=0.5),\n",
        "            A.ShiftScaleRotate(\n",
        "                shift_limit=0.02,\n",
        "                scale_limit=0.02,\n",
        "                rotate_limit=0,\n",
        "                border_mode=cv2.BORDER_CONSTANT,\n",
        "                p=0.3\n",
        "            ),\n",
        "            A.CenterCrop(height=224, width=224, p=1.0),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "        base_transform = A.Compose([\n",
        "            A.CenterCrop(height=224, width=224, p=1.0),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "        imgs = [base_transform(image=image)['image']]\n",
        "        for _ in range(9):  # ì´ 10ì¥\n",
        "            imgs.append(tta_transform(image=image)['image'])\n",
        "\n",
        "        input_tensor = torch.stack(imgs).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_tensor)\n",
        "            probs = torch.sigmoid(outputs).squeeze()\n",
        "        return probs.mean().item()\n",
        "\n",
        "    else:\n",
        "        # ì˜ìƒ í”„ë ˆì„ìš©, TTA ì—†ì´ ë‹¨ì¼ ì´ë¯¸ì§€\n",
        "        transform = A.Compose([\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "        img_tensor = transform(image=image)['image'].unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(img_tensor)\n",
        "            prob = torch.sigmoid(output).item()\n",
        "        return prob\n"
      ],
      "metadata": {
        "id": "8A0cQVzs1kri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_DIR = str(LOCAL_EXTRACT_BASE)"
      ],
      "metadata": {
        "id": "iBjxOHGh29cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = pd.read_csv(SAMPLE_CSV_PATH)\n",
        "final_probs = []\n",
        "\n",
        "# ---------------- ì¶”ë¡  (Inference) ì‹œì‘ ----------------\n",
        "for filename in tqdm(sample_df['filename'], desc=\"Inference\"):\n",
        "    file_stem = Path(filename).stem  # ì˜ˆ: TEST_000\n",
        "    file_ext = filename.lower().split('.')[-1]\n",
        "    # ---------- [CASE 1] ì˜ìƒ ì²˜ë¦¬ (í´ë” êµ¬ì¡°: TEST_000 / frame_0.jpg ...) ----------\n",
        "    if file_ext in VID_EXTS:\n",
        "        # ì˜ìƒ ì´ë¦„ê³¼ ë™ì¼í•œ ì´ë¦„ì„ ê°€ì§„ 'í´ë”' ê²½ë¡œ ì„¤ì •\n",
        "        video_folder = os.path.join(TEST_DIR, file_stem)\n",
        "\n",
        "        if os.path.exists(video_folder):\n",
        "          # ìˆ˜ì • 1 . ìˆœì„œ\n",
        "            matched_frames = sorted([f for f in os.listdir(video_folder) if f.lower().endswith('.jpg')])\n",
        "            frame_scores = []\n",
        "\n",
        "            for f_name in matched_frames:\n",
        "                img_path = os.path.join(video_folder, f_name)\n",
        "                img_bgr = cv2.imread(img_path)\n",
        "                if img_bgr is None: continue\n",
        "                image = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # ì˜ìƒì€ ì´ë¯¸ 224ë¡œ ì „ì²˜ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ TTA ì ìš© ì‹œì—ë„ ì¼ê´€ì„± ìœ ì§€\n",
        "                frame_scores.append(predict_single_image(model, image, tta=False))\n",
        "\n",
        "            # í”„ë ˆì„ë“¤ì˜ í‰ê·  ì ìˆ˜ ê³„ì‚°\n",
        "            final_probs.append(np.mean(frame_scores) if frame_scores else 0.5)\n",
        "        else:\n",
        "            final_probs.append(0.5) # í´ë” ìì²´ê°€ ì—†ëŠ” ê²½ìš°\n",
        "\n",
        "    # ---------- [CASE 2] ì‚¬ì§„ ì²˜ë¦¬ (íŒŒì¼ êµ¬ì¡°: TEST_001.jpg ...) ----------\n",
        "    elif file_ext in IMG_EXTS:\n",
        "        img_path = os.path.join(TEST_DIR, filename)\n",
        "\n",
        "        # íŒŒì¼ì´ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ í™•ì¥ì ë¬´ì‹œí•˜ê³  íƒìƒ‰\n",
        "        if not os.path.exists(img_path):\n",
        "            possible_files = [f for f in os.listdir(TEST_DIR) if f.startswith(file_stem)]\n",
        "            if possible_files:\n",
        "                img_path = os.path.join(TEST_DIR, possible_files[0])\n",
        "            else:\n",
        "                final_probs.append(0.5)\n",
        "                continue\n",
        "\n",
        "        img_bgr = cv2.imread(img_path)\n",
        "        if img_bgr is None:\n",
        "            final_probs.append(0.5)\n",
        "            continue\n",
        "\n",
        "        image = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "        # ì‚¬ì§„ì€ 256 -> 224 CenterCrop í¬í•¨ëœ TTA ì ìš©\n",
        "        final_probs.append(predict_single_image(model, image, tta=True))\n",
        "\n",
        "    # ---------- [CASE 3] ê¸°íƒ€ ----------\n",
        "    else:\n",
        "        final_probs.append(0.5)\n",
        "# ---------------- CSV ì €ì¥ ----------------\n",
        "sample_df['prob'] = 1.0 - np.array(final_probs)\n",
        "sample_df.to_csv(CSV_SAVE_PATH, index=False)\n",
        "print(f\"âœ… submission.csv ìƒì„± ì™„ë£Œ â†’ {CSV_SAVE_PATH}\")"
      ],
      "metadata": {
        "id": "vnIocXNEoVBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff280fd-d943-40d6-c5eb-d238366350b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inference:   0%|          | 1/500 [00:02<24:02,  2.89s/it]/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:49<00:00, 10.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… submission.csv ìƒì„± ì™„ë£Œ â†’ /content/drive/MyDrive/HECTO/Dataset/convnext_tiny_only_ff_celeb(1-p)_submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}