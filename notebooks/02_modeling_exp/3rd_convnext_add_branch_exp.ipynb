{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepfake-detection-model-project/Deepfake-Detection-Project/blob/jiwon-dev/notebooks/02_modeling_exp/3rd_convnext_add_branch_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install timm # í˜„ì¬ ì½”ë©ì— ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì„œ ì£¼ì„ì²˜ë¦¬ í•¨"
      ],
      "metadata": {
        "id": "2gYXWlQZPfah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import gc"
      ],
      "metadata": {
        "id": "WH3tSGvTPZkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VPw09SGCs7oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# src í´ë”ë¥¼ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ ê²½ë¡œ ì¶”ê°€ (í˜„ì¬ ê²½ë¡œê°€ /contentë¼ë©´)\n",
        "sys.path.append('/content/drive/MyDrive/HECTO')\n",
        "\n",
        "from src.utils import set_seed, log_to_csv\n",
        "from src.dataset import DeepfakeDataset, seed_worker\n",
        "from src.trainer import train_one_epoch, validate_video_level, save_checkpoint"
      ],
      "metadata": {
        "id": "3BsGABBbUFJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¡œì»¬ì—ì„œ ì••ì¶• í•´ì œ (ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì—†ìŒ)\n",
        "!unzip -q /content/drive/MyDrive/HECTO/Dataset/final_files/Celeb_frames_pp_final.zip -d /content/Celeb_Extract\n",
        "!unzip -q /content/drive/MyDrive/HECTO/Dataset/final_files/DF_Frames_Final.zip -d /content/DF_Extract\n",
        "!unzip -q /content/drive/MyDrive/HECTO/Dataset/final_files/FF_Frames_Final.zip -d /content/FF++_Extract"
      ],
      "metadata": {
        "id": "L2eAoSQr862o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ ì„¤ì • (ë³¸ì¸ì˜ ë“œë¼ì´ë¸Œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • ê°€ëŠ¥)\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/HECTO/checkpoints/05_convnext_add_branch'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# 3. ë°ì´í„°ì…‹ ê²½ë¡œ\n",
        "CSV_PATH = '/content/drive/MyDrive/HECTO/Dataset/CSV/total_final.csv'\n",
        "\n",
        "print(f\"âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ: {CHECKPOINT_DIR}\")"
      ],
      "metadata": {
        "id": "lI5k7luTO2cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‹œë“œ ì„¤ì •\n",
        "EXPERIMENT_SEED = 42\n",
        "set_seed(EXPERIMENT_SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"âœ… ì‹œë“œ {EXPERIMENT_SEED} ê³ ì • ì™„ë£Œ ë° {device} ì¤€ë¹„\")"
      ],
      "metadata": {
        "id": "mieyyaqCO47W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator()\n",
        "g.manual_seed(EXPERIMENT_SEED)\n",
        "\n",
        "# ê¸°ë³¸ ì¦ê°• ì„¤ì •\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    # 1. ê¸°í•˜í•™ì  ë³€í™˜ (256x256 ì›ë³¸ í•´ìƒë„ì—ì„œ ìˆ˜í–‰)\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "\n",
        "    # 2. í™”ì§ˆ ë° ìƒ‰ìƒ ë³€í™˜\n",
        "    transforms.RandomApply([\n",
        "        transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
        "    ], p=0.3),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "\n",
        "    # 3. ì„¼í„° í¬ë¡­ (Resize ëŒ€ì‹  ì‚¬ìš©)\n",
        "    # 256x256 ì´ë¯¸ì§€ì˜ ì¤‘ì•™ì—ì„œ 224x224ë¥¼ ì˜ë¼ë‚´ì–´ í”½ì…€ ì™œê³¡ì„ ë°©ì§€í•©ë‹ˆë‹¤.\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "\n",
        "    # 4. í…ì„œí™” ë° ì •ê·œí™”\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "    # 5. ê°€ë ¤ì§ ëŒ€ë¹„ (ToTensor ì´í›„ ì ìš©)\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    # 1. ì„¼í„° í¬ë¡­\n",
        "    # í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ ì¤‘ì•™ ì˜ì—­ì„ 224x224ë¡œ ì˜ë¼ëƒ…ë‹ˆë‹¤.\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "\n",
        "    # 2. í…ì„œí™” ë° ì •ê·œí™”\n",
        "    # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ íŒŒë¼ë¯¸í„°ì™€ ì™„ë²½íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "gHgu-5mvO6X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.delta = delta\n",
        "        self.val_acc_max = 0\n",
        "\n",
        "    def __call__(self, val_acc):\n",
        "        score = val_acc\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.val_acc_max = val_acc\n",
        "        # [ìˆ˜ì •] ì •í™•ë„ê°€ ê°œì„ ë˜ì§€ ì•Šì€ ê²½ìš° (scoreê°€ best + deltaë³´ë‹¤ ì‘ì„ ë•Œ)\n",
        "        elif score <= self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        # [ìˆ˜ì •] ì •í™•ë„ê°€ í™•ì‹¤íˆ ê°œì„ ëœ ê²½ìš°\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.val_acc_max = val_acc\n",
        "            self.counter = 0\n",
        "\n",
        "def load_checkpoint(model_name, model, optimizer, save_dir=CHECKPOINT_DIR):\n",
        "    filename = os.path.join(save_dir, f\"{model_name}_checkpoint.pth.tar\")\n",
        "    if os.path.isfile(filename):\n",
        "        print(f\"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: {filename}\")\n",
        "        # map_location ì¶”ê°€í•˜ì—¬ ì¥ì¹˜ ë¶ˆì¼ì¹˜ ë°©ì§€\n",
        "        checkpoint = torch.load(filename, map_location=device)\n",
        "\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        best_acc = checkpoint['best_acc']\n",
        "        es_state = checkpoint.get('es_state', None)\n",
        "\n",
        "        # ë§Œì•½ es_stateì— best_score ì •ë³´ê°€ ì—†ë‹¤ë©´ best_accë¡œ ê°•ì œ ë™ê¸°í™” ì¤€ë¹„\n",
        "        if es_state is not None:\n",
        "            if 'best_score' not in es_state or es_state['best_score'] is None:\n",
        "                es_state['best_score'] = best_acc\n",
        "\n",
        "        return start_epoch, best_acc, es_state\n",
        "    else:\n",
        "        print(\"ğŸ†• ì´ì „ ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ. ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
        "        return 0, 0, None"
      ],
      "metadata": {
        "id": "c-DtaIfzO9ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiScaleConvNeXt(nn.Module):\n",
        "    def __init__(self, model_name='convnext_tiny.fb_in1k', pretrained=True, checkpoint_path=None):\n",
        "        super(MultiScaleConvNeXt, self).__init__()\n",
        "        # 1. ë°±ë³¸ ìƒì„± (features_only=Trueë¡œ ì„¤ì •í•˜ì—¬ ì¤‘ê°„ íŠ¹ì§• ì¶”ì¶œ ê°€ëŠ¥í•˜ê²Œ í•¨)\n",
        "        self.backbone = timm.create_model(model_name, pretrained=pretrained, features_only=True)\n",
        "\n",
        "        # 2. ì‹¤í—˜ 1 ê°€ì¤‘ì¹˜ ë¡œë“œ (ë°±ë³¸ ë¶€ë¶„ë§Œ ì´ì‹)\n",
        "        if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "            print(f\"ğŸ“¥ ì‹¤í—˜ 1 ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤: {checkpoint_path}\")\n",
        "            ckpt = torch.load(checkpoint_path, map_location='cpu')\n",
        "            state_dict = ckpt.get('state_dict', ckpt)\n",
        "\n",
        "            # backbone ë¶€ë¶„ë§Œ í•„í„°ë§í•˜ì—¬ ë¡œë“œ\n",
        "            new_state_dict = {}\n",
        "            for k, v in state_dict.items():\n",
        "                if 'backbone' in k:\n",
        "                    # 'model.backbone.' ë˜ëŠ” 'backbone.' ë“±ì˜ ì ‘ë‘ì–´ ì œê±°\n",
        "                    key = k.split('backbone.')[-1]\n",
        "                    new_state_dict[key] = v\n",
        "\n",
        "            # strict=Falseë¡œ í•˜ì—¬ ìƒˆë¡œ ìƒê¸´ adapter/head ê°€ì¤‘ì¹˜ëŠ” ì œì™¸í•˜ê³  ë¡œë“œ\n",
        "            msg = self.backbone.load_state_dict(new_state_dict, strict=False)\n",
        "            print(f\"âœ… ë°±ë³¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ê²°ê³¼: {msg}\")\n",
        "\n",
        "        # ê° ìŠ¤í…Œì´ì§€ì˜ ì±„ë„ ìˆ˜: Stage 2(192), Stage 3(384), Stage 4(768)\n",
        "        # 3. ë¸Œëœì¹˜ìš© í•©ì„±ê³± ë ˆì´ì–´ (Adapter)\n",
        "        self.adapter2 = nn.Sequential(\n",
        "            nn.Conv2d(192, 192, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.adapter3 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.adapter4 = nn.Sequential(\n",
        "            nn.Conv2d(768, 768, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(768),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # 4. ìµœì¢… ë¶„ë¥˜ê¸° (3ê°œ ìŠ¤í…Œì´ì§€ì˜ íŠ¹ì„±ì„ í•©ì¹¨: 192 + 384 + 768 = 1344)\n",
        "        self.head = nn.Linear(192 + 384 + 768, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x) # [s1, s2, s3, s4]\n",
        "\n",
        "        # ê° ìŠ¤í…Œì´ì§€ë³„ ë¸Œëœì¹˜ í†µê³¼ ë° Global Average Pooling\n",
        "        f2 = self.gap(self.adapter2(features[1])).flatten(1) # Stage 2\n",
        "        f3 = self.gap(self.adapter3(features[2])).flatten(1) # Stage 3\n",
        "        f4 = self.gap(self.adapter4(features[3])).flatten(1) # Stage 4\n",
        "\n",
        "        # íŠ¹ì„± ê²°í•© ë° ìµœì¢… ë¶„ë¥˜\n",
        "        combined = torch.cat([f2, f3, f4], dim=1)\n",
        "        return self.head(combined)"
      ],
      "metadata": {
        "id": "lV4amqkqYFIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‹¤í—˜ ëŒ€ìƒ ëª¨ë¸\n",
        "model_names = ['convnext_tiny']\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "MAX_EPOCHS = 20  # ì–¼ë¦¬ìŠ¤íƒ‘ì´ ìˆìœ¼ë¯€ë¡œ ë„‰ë„‰íˆ ì¡ìŠµë‹ˆë‹¤.\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# ë°ì´í„° ë¡œë” ì¤€ë¹„\n",
        "train_dataset = DeepfakeDataset(CSV_PATH, split='train', transform=train_transform)\n",
        "val_dataset = DeepfakeDataset(CSV_PATH, split='val', transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=2, worker_init_fn=seed_worker, generator=g)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "JoNIZc-HPAL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
        "results_summary = []\n",
        "\n",
        "for m_name in model_names:\n",
        "    print(f\"\\nğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘: {m_name} (Branch Structure + Differential LR)\")\n",
        "\n",
        "    # [ì„¤ì •] ì‹¤í—˜ 1ì—ì„œ í•™ìŠµ ì™„ë£Œëœ ë² ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ê²½ë¡œ (ë³¸ì¸ì˜ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •)\n",
        "    EXP1_BEST_PATH = \"/content/drive/MyDrive/HECTO/checkpoints/03_convnext_different_lr/convnext_tiny_best.pth.tar\"\n",
        "\n",
        "    # 2. ëª¨ë¸ ë° ì†ì‹¤í•¨ìˆ˜ ì´ˆê¸°í™”\n",
        "    model = MultiScaleConvNeXt(model_name=m_name, checkpoint_path=EXP1_BEST_PATH).to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # 3. [í•µì‹¬] AdamW ë° ì°¨ë“± í•™ìŠµë¥  ì ìš©\n",
        "    # ë°±ë³¸(ì´ë¯¸ í•™ìŠµë¨)ì€ 1e-6, ìƒˆë¡œìš´ ë ˆì´ì–´ë“¤ì€ 1e-4ë¡œ ì„¤ì •\n",
        "    optimizer = optim.AdamW([\n",
        "        {'params': model.backbone.parameters(), 'lr': 1e-6},\n",
        "        {'params': model.adapter2.parameters(), 'lr': 1e-4},\n",
        "        {'params': model.adapter3.parameters(), 'lr': 1e-4},\n",
        "        {'params': model.adapter4.parameters(), 'lr': 1e-4},\n",
        "        {'params': model.head.parameters(), 'lr': 1e-4}\n",
        "    ], weight_decay=0.05)\n",
        "\n",
        "    # 4. í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ (ì „ì²´ì ì¸ ìˆ˜ë ´ ìœ ë„)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=MAX_EPOCHS)\n",
        "\n",
        "    # 5. ì–¼ë¦¬ìŠ¤íƒ‘ ë° ê°€ì¤‘ì¹˜ ë¡œë“œ ë¡œì§ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)\n",
        "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
        "    # ì¸ì ìˆœì„œë¥¼ ì •ì˜ëœ (model_name, model, optimizer, save_dir)ì— ë§ì¶¤\n",
        "    # early_stoppingì€ í•¨ìˆ˜ ì •ì˜ì— ì¸ìë¡œ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šìœ¼ë¯€ë¡œ ë‚´ë¶€ ìƒíƒœë§Œ ë”°ë¡œ ì—…ë°ì´íŠ¸í•´ì•¼ í•¨\n",
        "    start_epoch, best_acc, es_state = load_checkpoint(m_name, model, optimizer, CHECKPOINT_DIR)\n",
        "\n",
        "    if es_state:\n",
        "        early_stopping.__dict__.update(es_state)\n",
        "\n",
        "    # --- ì—í¬í¬ ë°˜ë³µ ì‹œì‘ ---\n",
        "    for epoch in range(start_epoch, MAX_EPOCHS):\n",
        "        print(f\"\\n[Epoch {epoch+1}/{MAX_EPOCHS}]\")\n",
        "\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, video_acc = validate_video_level(model, val_loader, criterion, device)\n",
        "\n",
        "        scheduler.step() # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸\n",
        "\n",
        "        is_best = video_acc > best_acc\n",
        "        if is_best:\n",
        "            best_acc = video_acc\n",
        "            print(f\"âœ¨ Best Model Updated! (Acc: {best_acc:.4f})\")\n",
        "\n",
        "        early_stopping(video_acc)\n",
        "\n",
        "        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'best_acc': best_acc,\n",
        "            'es_state': early_stopping.__dict__,\n",
        "        }, is_best, m_name, CHECKPOINT_DIR)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(f\"ğŸ›‘ Early Stopping triggered at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    results_summary.append({'Model': m_name, 'Best Video Acc': best_acc})\n",
        "\n",
        "    del model, optimizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "print(\"\\nâœ… ëª¨ë“  ëª¨ë¸ ì‹¤í—˜ ì™„ë£Œ!\")\n",
        "\n",
        "# 18 ì—í¬í¬ì—ì„œ ìµœê³ ì„±ëŠ¥ 0.9722 ë‹¬ì„±í•¨"
      ],
      "metadata": {
        "id": "ar_Y9W4ssZA6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}