{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c4b3522715e4401f810c7bb3184c5107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c417f2bc079d47a483932588ad4e82fc",
              "IPY_MODEL_e217492d7e5a4258b5a61976ae811c35",
              "IPY_MODEL_bcf9cc7132164757b2f13a841d9c07bb"
            ],
            "layout": "IPY_MODEL_17113aa13afc4a02a1fb718e20791534"
          }
        },
        "c417f2bc079d47a483932588ad4e82fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0740dc9a30746e0a0cdd5c73ba1ffab",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3a23476963994d27b36e8cc8d9e0a7fa",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "e217492d7e5a4258b5a61976ae811c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80604aff66744184916089a87a4f3cac",
            "max": 114374272,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fe4500001b14beba2cef25babd66798",
            "value": 114374272
          }
        },
        "bcf9cc7132164757b2f13a841d9c07bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6d880a96a0d47349ddfc49557e8001c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c87796f010ae404983f2fa400a1b136f",
            "value": "‚Äá114M/114M‚Äá[00:01&lt;00:00,‚Äá142MB/s]"
          }
        },
        "17113aa13afc4a02a1fb718e20791534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0740dc9a30746e0a0cdd5c73ba1ffab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a23476963994d27b36e8cc8d9e0a7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80604aff66744184916089a87a4f3cac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fe4500001b14beba2cef25babd66798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6d880a96a0d47349ddfc49557e8001c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c87796f010ae404983f2fa400a1b136f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepfake-detection-model-project/Deepfake-Detection-Project/blob/jiwon-dev/notebooks/02_modeling_exp/3rd_convnext_add_branch_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install timm # ÌòÑÏû¨ ÏΩîÎû©Ïóê Ïù¥ÎØ∏ ÏÑ§ÏπòÎêòÏñ¥ ÏûàÏñ¥ÏÑú Ï£ºÏÑùÏ≤òÎ¶¨ Ìï®"
      ],
      "metadata": {
        "id": "2gYXWlQZPfah"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import gc"
      ],
      "metadata": {
        "id": "WH3tSGvTPZkd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏å ÎßàÏö¥Ìä∏\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VPw09SGCs7oB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "243efdaf-3bd4-434d-95c4-6b1e80857148"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# src Ìè¥ÎçîÎ•º Ïù∏ÏãùÌï† Ïàò ÏûàÎèÑÎ°ù Í≤ΩÎ°ú Ï∂îÍ∞Ä (ÌòÑÏû¨ Í≤ΩÎ°úÍ∞Ä /contentÎùºÎ©¥)\n",
        "sys.path.append('/content/drive/MyDrive/HECTO')\n",
        "\n",
        "from src.utils import set_seed, log_to_csv\n",
        "from src.dataset import DeepfakeDataset, seed_worker\n",
        "from src.trainer import train_one_epoch, validate_video_level, save_checkpoint"
      ],
      "metadata": {
        "id": "3BsGABBbUFJA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Î°úÏª¨ÏóêÏÑú ÏïïÏ∂ï Ìï¥Ï†ú (ÎÑ§Ìä∏ÏõåÌÅ¨ ÏßÄÏó∞ ÏóÜÏùå)\n",
        "!unzip -q /content/drive/MyDrive/HECTO/Dataset/final_files/Celeb_frames_pp_final.zip -d /content/Celeb_Extract\n",
        "!unzip -q /content/drive/MyDrive/HECTO/Dataset/final_files/DF_Frames_Final.zip -d /content/DF_Extract\n",
        "!unzip -q /content/drive/MyDrive/HECTO/Dataset/final_files/FF_Frames_Final.zip -d /content/FF++_Extract"
      ],
      "metadata": {
        "id": "L2eAoSQr862o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû• Í≤ΩÎ°ú ÏÑ§Ï†ï (Î≥∏Ïù∏Ïùò ÎìúÎùºÏù¥Î∏å Í≤ΩÎ°úÏóê ÎßûÍ≤å ÏàòÏ†ï Í∞ÄÎä•)\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/HECTO/checkpoints/05_convnext_add_branch'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# 3. Îç∞Ïù¥ÌÑ∞ÏÖã Í≤ΩÎ°ú\n",
        "CSV_PATH = '/content/drive/MyDrive/HECTO/Dataset/CSV/total_final.csv'\n",
        "\n",
        "print(f\"‚úÖ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû• Í≤ΩÎ°ú: {CHECKPOINT_DIR}\")"
      ],
      "metadata": {
        "id": "lI5k7luTO2cn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71217242-4fa6-4d94-dc47-b596bf079fc3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû• Í≤ΩÎ°ú: /content/drive/MyDrive/HECTO/checkpoints/05_convnext_add_branch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÏãúÎìú ÏÑ§Ï†ï\n",
        "EXPERIMENT_SEED = 42\n",
        "set_seed(EXPERIMENT_SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"‚úÖ ÏãúÎìú {EXPERIMENT_SEED} Í≥†Ï†ï ÏôÑÎ£å Î∞è {device} Ï§ÄÎπÑ\")"
      ],
      "metadata": {
        "id": "mieyyaqCO47W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5784a59b-578a-46ce-f31f-488a4d6f7846"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ÏãúÎìú 42 Í≥†Ï†ï ÏôÑÎ£å Î∞è cuda Ï§ÄÎπÑ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator()\n",
        "g.manual_seed(EXPERIMENT_SEED)\n",
        "\n",
        "# Í∏∞Î≥∏ Ï¶ùÍ∞ï ÏÑ§Ï†ï\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    # 1. Í∏∞ÌïòÌïôÏ†Å Î≥ÄÌôò (256x256 ÏõêÎ≥∏ Ìï¥ÏÉÅÎèÑÏóêÏÑú ÏàòÌñâ)\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "\n",
        "    # 2. ÌôîÏßà Î∞è ÏÉâÏÉÅ Î≥ÄÌôò\n",
        "    transforms.RandomApply([\n",
        "        transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
        "    ], p=0.3),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "\n",
        "    # 3. ÏÑºÌÑ∞ ÌÅ¨Î°≠ (Resize ÎåÄÏã† ÏÇ¨Ïö©)\n",
        "    # 256x256 Ïù¥ÎØ∏ÏßÄÏùò Ï§ëÏïôÏóêÏÑú 224x224Î•º ÏûòÎùºÎÇ¥Ïñ¥ ÌîΩÏÖÄ ÏôúÍ≥°ÏùÑ Î∞©ÏßÄÌï©ÎãàÎã§.\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "\n",
        "    # 4. ÌÖêÏÑúÌôî Î∞è Ï†ïÍ∑úÌôî\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "    # 5. Í∞ÄÎ†§Ïßê ÎåÄÎπÑ (ToTensor Ïù¥ÌõÑ Ï†ÅÏö©)\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    # 1. ÏÑºÌÑ∞ ÌÅ¨Î°≠\n",
        "    # ÌïôÏäµ ÏãúÏôÄ ÎèôÏùºÌïòÍ≤å Ï§ëÏïô ÏòÅÏó≠ÏùÑ 224x224Î°ú ÏûòÎùºÎÉÖÎãàÎã§.\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "\n",
        "    # 2. ÌÖêÏÑúÌôî Î∞è Ï†ïÍ∑úÌôî\n",
        "    # ÌïôÏäµ Ïãú ÏÇ¨Ïö©Ìïú ÌååÎùºÎØ∏ÌÑ∞ÏôÄ ÏôÑÎ≤ΩÌûà ÏùºÏπòÌï¥Ïïº Ìï©ÎãàÎã§.\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "gHgu-5mvO6X6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.delta = delta\n",
        "        self.val_acc_max = 0\n",
        "\n",
        "    def __call__(self, val_acc):\n",
        "        score = val_acc\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.val_acc_max = val_acc\n",
        "        # [ÏàòÏ†ï] Ï†ïÌôïÎèÑÍ∞Ä Í∞úÏÑ†ÎêòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞ (scoreÍ∞Ä best + deltaÎ≥¥Îã§ ÏûëÏùÑ Îïå)\n",
        "        elif score <= self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        # [ÏàòÏ†ï] Ï†ïÌôïÎèÑÍ∞Ä ÌôïÏã§Ìûà Í∞úÏÑ†Îêú Í≤ΩÏö∞\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.val_acc_max = val_acc\n",
        "            self.counter = 0\n",
        "\n",
        "def load_checkpoint(model_name, model, optimizer, save_dir=CHECKPOINT_DIR):\n",
        "    filename = os.path.join(save_dir, f\"{model_name}_checkpoint.pth.tar\")\n",
        "    if os.path.isfile(filename):\n",
        "        print(f\"üîÑ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î∂àÎü¨Ïò§Îäî Ï§ë: {filename}\")\n",
        "        # map_location Ï∂îÍ∞ÄÌïòÏó¨ Ïû•Ïπò Î∂àÏùºÏπò Î∞©ÏßÄ\n",
        "        checkpoint = torch.load(filename, map_location=device)\n",
        "\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        best_acc = checkpoint['best_acc']\n",
        "        es_state = checkpoint.get('es_state', None)\n",
        "\n",
        "        # ÎßåÏïΩ es_stateÏóê best_score Ï†ïÎ≥¥Í∞Ä ÏóÜÎã§Î©¥ best_accÎ°ú Í∞ïÏ†ú ÎèôÍ∏∞Ìôî Ï§ÄÎπÑ\n",
        "        if es_state is not None:\n",
        "            if 'best_score' not in es_state or es_state['best_score'] is None:\n",
        "                es_state['best_score'] = best_acc\n",
        "\n",
        "        return start_epoch, best_acc, es_state\n",
        "    else:\n",
        "        print(\"üÜï Ïù¥Ï†Ñ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ ÏóÜÏùå. Ï≤òÏùåÎ∂ÄÌÑ∞ ÌïôÏäµÏùÑ ÏãúÏûëÌï©ÎãàÎã§.\")\n",
        "        return 0, 0, None"
      ],
      "metadata": {
        "id": "c-DtaIfzO9ge"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiScaleConvNeXt(nn.Module):\n",
        "    def __init__(self, model_name='convnext_tiny.fb_in1k', pretrained=True, checkpoint_path=None):\n",
        "        super(MultiScaleConvNeXt, self).__init__()\n",
        "        # 1. Î∞±Î≥∏ ÏÉùÏÑ± (features_only=TrueÎ°ú ÏÑ§Ï†ïÌïòÏó¨ Ï§ëÍ∞Ñ ÌäπÏßï Ï∂îÏ∂ú Í∞ÄÎä•ÌïòÍ≤å Ìï®)\n",
        "        self.backbone = timm.create_model(model_name, pretrained=pretrained, features_only=True)\n",
        "\n",
        "        # 2. Ïã§Ìóò 1 Í∞ÄÏ§ëÏπò Î°úÎìú (Î∞±Î≥∏ Î∂ÄÎ∂ÑÎßå Ïù¥Ïãù)\n",
        "        if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "            print(f\"üì• Ïã§Ìóò 1 Í∞ÄÏ§ëÏπòÎ•º Î°úÎìúÌï©ÎãàÎã§: {checkpoint_path}\")\n",
        "            ckpt = torch.load(checkpoint_path, map_location='cpu')\n",
        "            state_dict = ckpt.get('state_dict', ckpt)\n",
        "\n",
        "            # backbone Î∂ÄÎ∂ÑÎßå ÌïÑÌÑ∞ÎßÅÌïòÏó¨ Î°úÎìú\n",
        "            new_state_dict = {}\n",
        "            for k, v in state_dict.items():\n",
        "                if 'backbone' in k:\n",
        "                    # 'model.backbone.' ÎòêÎäî 'backbone.' Îì±Ïùò Ï†ëÎëêÏñ¥ Ï†úÍ±∞\n",
        "                    key = k.split('backbone.')[-1]\n",
        "                    new_state_dict[key] = v\n",
        "\n",
        "            # strict=FalseÎ°ú ÌïòÏó¨ ÏÉàÎ°ú ÏÉùÍ∏¥ adapter/head Í∞ÄÏ§ëÏπòÎäî Ï†úÏô∏ÌïòÍ≥† Î°úÎìú\n",
        "            msg = self.backbone.load_state_dict(new_state_dict, strict=False)\n",
        "            print(f\"‚úÖ Î∞±Î≥∏ Í∞ÄÏ§ëÏπò Î°úÎìú Í≤∞Í≥º: {msg}\")\n",
        "\n",
        "        # Í∞Å Ïä§ÌÖåÏù¥ÏßÄÏùò Ï±ÑÎÑê Ïàò: Stage 2(192), Stage 3(384), Stage 4(768)\n",
        "        # 3. Î∏åÎûúÏπòÏö© Ìï©ÏÑ±Í≥± Î†àÏù¥Ïñ¥ (Adapter)\n",
        "        self.adapter2 = nn.Sequential(\n",
        "            nn.Conv2d(192, 192, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.adapter3 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.adapter4 = nn.Sequential(\n",
        "            nn.Conv2d(768, 768, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(768),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        # 4. ÏµúÏ¢Ö Î∂ÑÎ•òÍ∏∞ (3Í∞ú Ïä§ÌÖåÏù¥ÏßÄÏùò ÌäπÏÑ±ÏùÑ Ìï©Ïπ®: 192 + 384 + 768 = 1344)\n",
        "        self.head = nn.Linear(192 + 384 + 768, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x) # [s1, s2, s3, s4]\n",
        "\n",
        "        # Í∞Å Ïä§ÌÖåÏù¥ÏßÄÎ≥Ñ Î∏åÎûúÏπò ÌÜµÍ≥º Î∞è Global Average Pooling\n",
        "        f2 = self.gap(self.adapter2(features[1])).flatten(1) # Stage 2\n",
        "        f3 = self.gap(self.adapter3(features[2])).flatten(1) # Stage 3\n",
        "        f4 = self.gap(self.adapter4(features[3])).flatten(1) # Stage 4\n",
        "\n",
        "        # ÌäπÏÑ± Í≤∞Ìï© Î∞è ÏµúÏ¢Ö Î∂ÑÎ•ò\n",
        "        combined = torch.cat([f2, f3, f4], dim=1)\n",
        "        return self.head(combined)"
      ],
      "metadata": {
        "id": "lV4amqkqYFIs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ïã§Ìóò ÎåÄÏÉÅ Î™®Îç∏\n",
        "model_names = ['convnext_tiny']\n",
        "\n",
        "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞\n",
        "MAX_EPOCHS = 20  # ÏñºÎ¶¨Ïä§ÌÉëÏù¥ ÏûàÏúºÎØÄÎ°ú ÎÑâÎÑâÌûà Ïû°ÏäµÎãàÎã§.\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ Î°úÎçî Ï§ÄÎπÑ\n",
        "train_dataset = DeepfakeDataset(CSV_PATH, split='train', transform=train_transform)\n",
        "val_dataset = DeepfakeDataset(CSV_PATH, split='val', transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=2, worker_init_fn=seed_worker, generator=g)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "JoNIZc-HPAL7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Í≤∞Í≥º Ï†ÄÏû•Ïö© Î¶¨Ïä§Ìä∏\n",
        "results_summary = []\n",
        "\n",
        "for m_name in model_names:\n",
        "    print(f\"\\nüöÄ Î™®Îç∏ ÌïôÏäµ ÏãúÏûë: {m_name} (Branch Structure + Differential LR)\")\n",
        "\n",
        "    # [ÏÑ§Ï†ï] Ïã§Ìóò 1ÏóêÏÑú ÌïôÏäµ ÏôÑÎ£åÎêú Î≤†Ïä§Ìä∏ Í∞ÄÏ§ëÏπò Í≤ΩÎ°ú (Î≥∏Ïù∏Ïùò Í≤ΩÎ°úÏóê ÎßûÍ≤å ÏàòÏ†ï)\n",
        "    EXP1_BEST_PATH = \"/content/drive/MyDrive/HECTO/checkpoints/03_convnext_different_lr/convnext_tiny_best.pth.tar\"\n",
        "\n",
        "    # 2. Î™®Îç∏ Î∞è ÏÜêÏã§Ìï®Ïàò Ï¥àÍ∏∞Ìôî\n",
        "    model = MultiScaleConvNeXt(model_name=m_name, checkpoint_path=EXP1_BEST_PATH).to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # 3. [ÌïµÏã¨] AdamW Î∞è Ï∞®Îì± ÌïôÏäµÎ•† Ï†ÅÏö©\n",
        "    # Î∞±Î≥∏(Ïù¥ÎØ∏ ÌïôÏäµÎê®)ÏùÄ 1e-6, ÏÉàÎ°úÏö¥ Î†àÏù¥Ïñ¥Îì§ÏùÄ 1e-4Î°ú ÏÑ§Ï†ï\n",
        "    optimizer = optim.AdamW([\n",
        "        {'params': model.backbone.parameters(), 'lr': 1e-6},\n",
        "        {'params': model.adapter2.parameters(), 'lr': 1e-4},\n",
        "        {'params': model.adapter3.parameters(), 'lr': 1e-4},\n",
        "        {'params': model.adapter4.parameters(), 'lr': 1e-4},\n",
        "        {'params': model.head.parameters(), 'lr': 1e-4}\n",
        "    ], weight_decay=0.05)\n",
        "\n",
        "    # 4. ÌïôÏäµÎ•† Ïä§ÏºÄÏ§ÑÎü¨ (Ï†ÑÏ≤¥Ï†ÅÏù∏ ÏàòÎ†¥ Ïú†ÎèÑ)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=MAX_EPOCHS)\n",
        "\n",
        "    # 5. ÏñºÎ¶¨Ïä§ÌÉë Î∞è Í∞ÄÏ§ëÏπò Î°úÎìú Î°úÏßÅ (Í∏∞Ï°¥ ÏΩîÎìú Ïú†ÏßÄ)\n",
        "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
        "    # Ïù∏Ïûê ÏàúÏÑúÎ•º Ï†ïÏùòÎêú (model_name, model, optimizer, save_dir)Ïóê ÎßûÏ∂§\n",
        "    # early_stoppingÏùÄ Ìï®Ïàò Ï†ïÏùòÏóê Ïù∏ÏûêÎ°ú Ìè¨Ìï®ÎêòÏñ¥ ÏûàÏßÄ ÏïäÏúºÎØÄÎ°ú ÎÇ¥Î∂Ä ÏÉÅÌÉúÎßå Îî∞Î°ú ÏóÖÎç∞Ïù¥Ìä∏Ìï¥Ïïº Ìï®\n",
        "    start_epoch, best_acc, es_state = load_checkpoint(m_name, model, optimizer, CHECKPOINT_DIR)\n",
        "\n",
        "    if es_state:\n",
        "        early_stopping.__dict__.update(es_state)\n",
        "\n",
        "    # --- ÏóêÌè¨ÌÅ¨ Î∞òÎ≥µ ÏãúÏûë ---\n",
        "    for epoch in range(start_epoch, MAX_EPOCHS):\n",
        "        print(f\"\\n[Epoch {epoch+1}/{MAX_EPOCHS}]\")\n",
        "\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, video_acc = validate_video_level(model, val_loader, criterion, device)\n",
        "\n",
        "        scheduler.step() # Ïä§ÏºÄÏ§ÑÎü¨ ÏóÖÎç∞Ïù¥Ìä∏\n",
        "\n",
        "        is_best = video_acc > best_acc\n",
        "        if is_best:\n",
        "            best_acc = video_acc\n",
        "            print(f\"‚ú® Best Model Updated! (Acc: {best_acc:.4f})\")\n",
        "\n",
        "        early_stopping(video_acc)\n",
        "\n",
        "        # Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû•\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'best_acc': best_acc,\n",
        "            'es_state': early_stopping.__dict__,\n",
        "        }, is_best, m_name, CHECKPOINT_DIR)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(f\"üõë Early Stopping triggered at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    results_summary.append({'Model': m_name, 'Best Video Acc': best_acc})\n",
        "\n",
        "    del model, optimizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "print(\"\\n‚úÖ Î™®Îì† Î™®Îç∏ Ïã§Ìóò ÏôÑÎ£å!\")"
      ],
      "metadata": {
        "id": "ar_Y9W4ssZA6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657,
          "referenced_widgets": [
            "c4b3522715e4401f810c7bb3184c5107",
            "c417f2bc079d47a483932588ad4e82fc",
            "e217492d7e5a4258b5a61976ae811c35",
            "bcf9cc7132164757b2f13a841d9c07bb",
            "17113aa13afc4a02a1fb718e20791534",
            "d0740dc9a30746e0a0cdd5c73ba1ffab",
            "3a23476963994d27b36e8cc8d9e0a7fa",
            "80604aff66744184916089a87a4f3cac",
            "7fe4500001b14beba2cef25babd66798",
            "b6d880a96a0d47349ddfc49557e8001c",
            "c87796f010ae404983f2fa400a1b136f"
          ]
        },
        "outputId": "7fe5b1e0-4099-4b22-ead5-2ad44b990b80"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Î™®Îç∏ ÌïôÏäµ ÏãúÏûë: convnext_tiny (Branch Structure + Differential LR)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4b3522715e4401f810c7bb3184c5107"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Ïã§Ìóò 1 Í∞ÄÏ§ëÏπòÎ•º Î°úÎìúÌï©ÎãàÎã§: /content/drive/MyDrive/HECTO/checkpoints/03_convnext_different_lr/convnext_tiny_best.pth.tar\n",
            "‚úÖ Î∞±Î≥∏ Í∞ÄÏ§ëÏπò Î°úÎìú Í≤∞Í≥º: _IncompatibleKeys(missing_keys=['stem_0.weight', 'stem_0.bias', 'stem_1.weight', 'stem_1.bias', 'stages_0.blocks.0.gamma', 'stages_0.blocks.0.conv_dw.weight', 'stages_0.blocks.0.conv_dw.bias', 'stages_0.blocks.0.norm.weight', 'stages_0.blocks.0.norm.bias', 'stages_0.blocks.0.mlp.fc1.weight', 'stages_0.blocks.0.mlp.fc1.bias', 'stages_0.blocks.0.mlp.fc2.weight', 'stages_0.blocks.0.mlp.fc2.bias', 'stages_0.blocks.1.gamma', 'stages_0.blocks.1.conv_dw.weight', 'stages_0.blocks.1.conv_dw.bias', 'stages_0.blocks.1.norm.weight', 'stages_0.blocks.1.norm.bias', 'stages_0.blocks.1.mlp.fc1.weight', 'stages_0.blocks.1.mlp.fc1.bias', 'stages_0.blocks.1.mlp.fc2.weight', 'stages_0.blocks.1.mlp.fc2.bias', 'stages_0.blocks.2.gamma', 'stages_0.blocks.2.conv_dw.weight', 'stages_0.blocks.2.conv_dw.bias', 'stages_0.blocks.2.norm.weight', 'stages_0.blocks.2.norm.bias', 'stages_0.blocks.2.mlp.fc1.weight', 'stages_0.blocks.2.mlp.fc1.bias', 'stages_0.blocks.2.mlp.fc2.weight', 'stages_0.blocks.2.mlp.fc2.bias', 'stages_1.downsample.0.weight', 'stages_1.downsample.0.bias', 'stages_1.downsample.1.weight', 'stages_1.downsample.1.bias', 'stages_1.blocks.0.gamma', 'stages_1.blocks.0.conv_dw.weight', 'stages_1.blocks.0.conv_dw.bias', 'stages_1.blocks.0.norm.weight', 'stages_1.blocks.0.norm.bias', 'stages_1.blocks.0.mlp.fc1.weight', 'stages_1.blocks.0.mlp.fc1.bias', 'stages_1.blocks.0.mlp.fc2.weight', 'stages_1.blocks.0.mlp.fc2.bias', 'stages_1.blocks.1.gamma', 'stages_1.blocks.1.conv_dw.weight', 'stages_1.blocks.1.conv_dw.bias', 'stages_1.blocks.1.norm.weight', 'stages_1.blocks.1.norm.bias', 'stages_1.blocks.1.mlp.fc1.weight', 'stages_1.blocks.1.mlp.fc1.bias', 'stages_1.blocks.1.mlp.fc2.weight', 'stages_1.blocks.1.mlp.fc2.bias', 'stages_1.blocks.2.gamma', 'stages_1.blocks.2.conv_dw.weight', 'stages_1.blocks.2.conv_dw.bias', 'stages_1.blocks.2.norm.weight', 'stages_1.blocks.2.norm.bias', 'stages_1.blocks.2.mlp.fc1.weight', 'stages_1.blocks.2.mlp.fc1.bias', 'stages_1.blocks.2.mlp.fc2.weight', 'stages_1.blocks.2.mlp.fc2.bias', 'stages_2.downsample.0.weight', 'stages_2.downsample.0.bias', 'stages_2.downsample.1.weight', 'stages_2.downsample.1.bias', 'stages_2.blocks.0.gamma', 'stages_2.blocks.0.conv_dw.weight', 'stages_2.blocks.0.conv_dw.bias', 'stages_2.blocks.0.norm.weight', 'stages_2.blocks.0.norm.bias', 'stages_2.blocks.0.mlp.fc1.weight', 'stages_2.blocks.0.mlp.fc1.bias', 'stages_2.blocks.0.mlp.fc2.weight', 'stages_2.blocks.0.mlp.fc2.bias', 'stages_2.blocks.1.gamma', 'stages_2.blocks.1.conv_dw.weight', 'stages_2.blocks.1.conv_dw.bias', 'stages_2.blocks.1.norm.weight', 'stages_2.blocks.1.norm.bias', 'stages_2.blocks.1.mlp.fc1.weight', 'stages_2.blocks.1.mlp.fc1.bias', 'stages_2.blocks.1.mlp.fc2.weight', 'stages_2.blocks.1.mlp.fc2.bias', 'stages_2.blocks.2.gamma', 'stages_2.blocks.2.conv_dw.weight', 'stages_2.blocks.2.conv_dw.bias', 'stages_2.blocks.2.norm.weight', 'stages_2.blocks.2.norm.bias', 'stages_2.blocks.2.mlp.fc1.weight', 'stages_2.blocks.2.mlp.fc1.bias', 'stages_2.blocks.2.mlp.fc2.weight', 'stages_2.blocks.2.mlp.fc2.bias', 'stages_2.blocks.3.gamma', 'stages_2.blocks.3.conv_dw.weight', 'stages_2.blocks.3.conv_dw.bias', 'stages_2.blocks.3.norm.weight', 'stages_2.blocks.3.norm.bias', 'stages_2.blocks.3.mlp.fc1.weight', 'stages_2.blocks.3.mlp.fc1.bias', 'stages_2.blocks.3.mlp.fc2.weight', 'stages_2.blocks.3.mlp.fc2.bias', 'stages_2.blocks.4.gamma', 'stages_2.blocks.4.conv_dw.weight', 'stages_2.blocks.4.conv_dw.bias', 'stages_2.blocks.4.norm.weight', 'stages_2.blocks.4.norm.bias', 'stages_2.blocks.4.mlp.fc1.weight', 'stages_2.blocks.4.mlp.fc1.bias', 'stages_2.blocks.4.mlp.fc2.weight', 'stages_2.blocks.4.mlp.fc2.bias', 'stages_2.blocks.5.gamma', 'stages_2.blocks.5.conv_dw.weight', 'stages_2.blocks.5.conv_dw.bias', 'stages_2.blocks.5.norm.weight', 'stages_2.blocks.5.norm.bias', 'stages_2.blocks.5.mlp.fc1.weight', 'stages_2.blocks.5.mlp.fc1.bias', 'stages_2.blocks.5.mlp.fc2.weight', 'stages_2.blocks.5.mlp.fc2.bias', 'stages_2.blocks.6.gamma', 'stages_2.blocks.6.conv_dw.weight', 'stages_2.blocks.6.conv_dw.bias', 'stages_2.blocks.6.norm.weight', 'stages_2.blocks.6.norm.bias', 'stages_2.blocks.6.mlp.fc1.weight', 'stages_2.blocks.6.mlp.fc1.bias', 'stages_2.blocks.6.mlp.fc2.weight', 'stages_2.blocks.6.mlp.fc2.bias', 'stages_2.blocks.7.gamma', 'stages_2.blocks.7.conv_dw.weight', 'stages_2.blocks.7.conv_dw.bias', 'stages_2.blocks.7.norm.weight', 'stages_2.blocks.7.norm.bias', 'stages_2.blocks.7.mlp.fc1.weight', 'stages_2.blocks.7.mlp.fc1.bias', 'stages_2.blocks.7.mlp.fc2.weight', 'stages_2.blocks.7.mlp.fc2.bias', 'stages_2.blocks.8.gamma', 'stages_2.blocks.8.conv_dw.weight', 'stages_2.blocks.8.conv_dw.bias', 'stages_2.blocks.8.norm.weight', 'stages_2.blocks.8.norm.bias', 'stages_2.blocks.8.mlp.fc1.weight', 'stages_2.blocks.8.mlp.fc1.bias', 'stages_2.blocks.8.mlp.fc2.weight', 'stages_2.blocks.8.mlp.fc2.bias', 'stages_3.downsample.0.weight', 'stages_3.downsample.0.bias', 'stages_3.downsample.1.weight', 'stages_3.downsample.1.bias', 'stages_3.blocks.0.gamma', 'stages_3.blocks.0.conv_dw.weight', 'stages_3.blocks.0.conv_dw.bias', 'stages_3.blocks.0.norm.weight', 'stages_3.blocks.0.norm.bias', 'stages_3.blocks.0.mlp.fc1.weight', 'stages_3.blocks.0.mlp.fc1.bias', 'stages_3.blocks.0.mlp.fc2.weight', 'stages_3.blocks.0.mlp.fc2.bias', 'stages_3.blocks.1.gamma', 'stages_3.blocks.1.conv_dw.weight', 'stages_3.blocks.1.conv_dw.bias', 'stages_3.blocks.1.norm.weight', 'stages_3.blocks.1.norm.bias', 'stages_3.blocks.1.mlp.fc1.weight', 'stages_3.blocks.1.mlp.fc1.bias', 'stages_3.blocks.1.mlp.fc2.weight', 'stages_3.blocks.1.mlp.fc2.bias', 'stages_3.blocks.2.gamma', 'stages_3.blocks.2.conv_dw.weight', 'stages_3.blocks.2.conv_dw.bias', 'stages_3.blocks.2.norm.weight', 'stages_3.blocks.2.norm.bias', 'stages_3.blocks.2.mlp.fc1.weight', 'stages_3.blocks.2.mlp.fc1.bias', 'stages_3.blocks.2.mlp.fc2.weight', 'stages_3.blocks.2.mlp.fc2.bias'], unexpected_keys=[])\n",
            "üîÑ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Î∂àÎü¨Ïò§Îäî Ï§ë: /content/drive/MyDrive/HECTO/checkpoints/05_convnext_add_branch/convnext_tiny_checkpoint.pth.tar\n",
            "\n",
            "[Epoch 15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 1 out of 5\n",
            "\n",
            "[Epoch 16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 2 out of 5\n",
            "\n",
            "[Epoch 17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 3 out of 5\n",
            "\n",
            "[Epoch 18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú® Best Model Updated! (Acc: 0.9722)\n",
            "‚≠ê [Best Updated] convnext_tiny - Best Acc: 0.9722 Ï†ÄÏû• ÏôÑÎ£å\n",
            "\n",
            "[Epoch 19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 1 out of 5\n",
            "\n",
            "[Epoch 20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 2 out of 5\n",
            "\n",
            "‚úÖ Î™®Îì† Î™®Îç∏ Ïã§Ìóò ÏôÑÎ£å!\n"
          ]
        }
      ]
    }
  ]
}