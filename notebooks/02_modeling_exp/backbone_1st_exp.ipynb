{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepfake-detection-model-project/Deepfake-Detection-Project/blob/jiwon-dev/notebooks/02_modeling_exp/backbone_1st_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install timm # í˜„ì¬ ì½”ë©ì— ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì„œ ì£¼ì„ì²˜ë¦¬ í•¨"
      ],
      "metadata": {
        "id": "2gYXWlQZPfah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import gc"
      ],
      "metadata": {
        "id": "WH3tSGvTPZkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VPw09SGCs7oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# src í´ë”ë¥¼ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ ê²½ë¡œ ì¶”ê°€ (í˜„ì¬ ê²½ë¡œê°€ /contentë¼ë©´)\n",
        "sys.path.append('/content/drive/MyDrive/HECTO')\n",
        "\n",
        "from src.utils import set_seed\n",
        "from src.dataset import DeepfakeDataset, seed_worker\n",
        "from src.trainer import train_one_epoch, validate_video_level, save_checkpoint"
      ],
      "metadata": {
        "id": "3BsGABBbUFJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¡œì»¬ì—ì„œ ì••ì¶• í•´ì œ (ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì—†ìŒ)\n",
        "!unzip -q /content/drive/MyDrive/HECTO/Dataset/images_data.zip -d /content/data_local"
      ],
      "metadata": {
        "id": "L2eAoSQr862o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ ì„¤ì • (ë³¸ì¸ì˜ ë“œë¼ì´ë¸Œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • ê°€ëŠ¥)\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/HECTO/checkpoints/01_backbone_selection'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# 3. ë°ì´í„°ì…‹ ê²½ë¡œ\n",
        "CSV_PATH = '/content/drive/MyDrive/HECTO/Dataset/CSV/total_local_path.csv'\n",
        "\n",
        "print(f\"âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ: {CHECKPOINT_DIR}\")"
      ],
      "metadata": {
        "id": "lI5k7luTO2cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‹œë“œ ì„¤ì •\n",
        "EXPERIMENT_SEED = 42\n",
        "set_seed(EXPERIMENT_SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"âœ… ì‹œë“œ {EXPERIMENT_SEED} ê³ ì • ì™„ë£Œ ë° {device} ì¤€ë¹„\")"
      ],
      "metadata": {
        "id": "mieyyaqCO47W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator()\n",
        "g.manual_seed(EXPERIMENT_SEED)\n",
        "\n",
        "# ê¸°ë³¸ ì¦ê°• ì„¤ì •\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    # 1. ê¸°í•˜í•™ì  ë³€í™˜ (256x256 ì›ë³¸ í•´ìƒë„ì—ì„œ ìˆ˜í–‰)\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "\n",
        "    # 2. í™”ì§ˆ ë° ìƒ‰ìƒ ë³€í™˜\n",
        "    transforms.RandomApply([\n",
        "        transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
        "    ], p=0.3),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "\n",
        "    # 3. ì„¼í„° í¬ë¡­ (Resize ëŒ€ì‹  ì‚¬ìš©)\n",
        "    # 256x256 ì´ë¯¸ì§€ì˜ ì¤‘ì•™ì—ì„œ 224x224ë¥¼ ì˜ë¼ë‚´ì–´ í”½ì…€ ì™œê³¡ì„ ë°©ì§€í•©ë‹ˆë‹¤.\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "\n",
        "    # 4. í…ì„œí™” ë° ì •ê·œí™”\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "    # 5. ê°€ë ¤ì§ ëŒ€ë¹„ (ToTensor ì´í›„ ì ìš©)\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    # 1. ì„¼í„° í¬ë¡­\n",
        "    # í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ ì¤‘ì•™ ì˜ì—­ì„ 224x224ë¡œ ì˜ë¼ëƒ…ë‹ˆë‹¤.\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "\n",
        "    # 2. í…ì„œí™” ë° ì •ê·œí™”\n",
        "    # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ íŒŒë¼ë¯¸í„°ì™€ ì™„ë²½íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "gHgu-5mvO6X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_acc_max = 0\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_acc):\n",
        "        score = val_acc\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "\n",
        "def load_checkpoint(model_name, model, optimizer):\n",
        "    filename = os.path.join(CHECKPOINT_DIR, f\"{model_name}_checkpoint.pth.tar\")\n",
        "    if os.path.isfile(filename):\n",
        "        print(f\"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: {filename}\")\n",
        "        checkpoint = torch.load(filename)\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        best_acc = checkpoint['best_acc']\n",
        "        return start_epoch, best_acc\n",
        "    else:\n",
        "        print(\"ğŸ†• ì´ì „ ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ. ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
        "        return 0, 0"
      ],
      "metadata": {
        "id": "c-DtaIfzO9ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‹¤í—˜ ëŒ€ìƒ ëª¨ë¸\n",
        "model_names = ['resnet50', 'efficientnet_b0', 'vit_tiny_patch16_224', 'convnext_tiny']\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "MAX_EPOCHS = 20  # ì–¼ë¦¬ìŠ¤íƒ‘ì´ ìˆìœ¼ë¯€ë¡œ ë„‰ë„‰íˆ ì¡ìŠµë‹ˆë‹¤.\n",
        "BATCH_SIZE = 32\n",
        "LR = 1e-4\n",
        "\n",
        "# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "results_summary = []\n",
        "\n",
        "# ë°ì´í„° ë¡œë” ì¤€ë¹„\n",
        "train_dataset = DeepfakeDataset(CSV_PATH, split='train', transform=train_transform)\n",
        "val_dataset = DeepfakeDataset(CSV_PATH, split='val', transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=2, worker_init_fn=seed_worker, generator=g)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "JoNIZc-HPAL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m_name in model_names:\n",
        "    print(f\"\\n\" + \"=\"*50)\n",
        "    print(f\"ğŸš€ Experiment Start: {m_name}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    set_seed(EXPERIMENT_SEED) # ì‹œë“œ ë‹¤ì‹œ í•œë²ˆ ê³ ì •\n",
        "\n",
        "    # 1. ëª¨ë¸ ì´ˆê¸°í™” (Binary Classificationì„ ìœ„í•´ num_classes=1 ì„¤ì •)\n",
        "    model = timm.create_model(m_name, pretrained=True, num_classes=1).to(device)\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
        "\n",
        "    # ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸° (ì¤‘ë‹¨ëœ ê²½ìš° ëŒ€ë¹„)\n",
        "    start_epoch, best_acc = load_checkpoint(m_name, model, optimizer)\n",
        "\n",
        "    for epoch in range(start_epoch, MAX_EPOCHS):\n",
        "        print(f\"\\n[Epoch {epoch+1}/{MAX_EPOCHS}]\")\n",
        "\n",
        "        # í•™ìŠµ\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "        # ê²€ì¦ (ì˜ìƒ ë‹¨ìœ„ í‰ê°€)\n",
        "        val_loss, video_acc = validate_video_level(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"  Val Loss:   {val_loss:.4f} | Video-level Val Acc: {video_acc:.4f}\")\n",
        "\n",
        "        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì—¬ë¶€ í™•ì¸\n",
        "        is_best = video_acc > best_acc\n",
        "        if is_best:\n",
        "            best_acc = video_acc\n",
        "\n",
        "        # ì²´í¬í¬ì¸íŠ¸ ë° ë² ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ì €ì¥\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'best_acc': best_acc,\n",
        "        }, is_best, m_name, CHECKPOINT_DIR)\n",
        "\n",
        "        # ì–¼ë¦¬ìŠ¤íƒ‘ í™•ì¸\n",
        "        early_stopping(video_acc)\n",
        "        if early_stopping.early_stop:\n",
        "            print(f\"ğŸ›‘ {m_name} Early Stopping!\")\n",
        "            break\n",
        "\n",
        "    results_summary.append({'Model': m_name, 'Best Video Acc': best_acc})\n",
        "\n",
        "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    del model, optimizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
        "print(\"\\n\" + \"ğŸ† Final Comparison Report \" + \"ğŸ†\")\n",
        "df_res = pd.DataFrame(results_summary)\n",
        "print(df_res.sort_values(by='Best Video Acc', ascending=False))"
      ],
      "metadata": {
        "id": "2w8rQFAu5ipV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}