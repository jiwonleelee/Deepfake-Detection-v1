{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepfake-detection-model-project/Deepfake-Detection-Project/blob/jiwon-dev/notebooks/02_modeling_exp/backbone_1st_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install timm # í˜„ì¬ ì½”ë©ì— ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì„œ ì£¼ì„ì²˜ë¦¬ í•¨"
      ],
      "metadata": {
        "id": "2gYXWlQZPfah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import gc"
      ],
      "metadata": {
        "id": "WH3tSGvTPZkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VPw09SGCs7oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "# src í´ë”ë¥¼ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ ê²½ë¡œ ì¶”ê°€ (í˜„ì¬ ê²½ë¡œê°€ /contentë¼ë©´)\n",
        "sys.path.append('/content/drive/MyDrive/HECTO')\n",
        "\n",
        "from src.utils import set_seed, log_to_csv\n",
        "from src.dataset import DeepfakeDataset, seed_worker\n",
        "from src.trainer import train_one_epoch, validate_video_level, save_checkpoint"
      ],
      "metadata": {
        "id": "3BsGABBbUFJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¡œì»¬ì—ì„œ ì••ì¶• í•´ì œ (ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì—†ìŒ)\n",
        "!unzip -q /content/drive/MyDrive/HECTO/Dataset/images_data.zip -d /content/data_local"
      ],
      "metadata": {
        "id": "L2eAoSQr862o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ ì„¤ì • (ë³¸ì¸ì˜ ë“œë¼ì´ë¸Œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • ê°€ëŠ¥)\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/HECTO/checkpoints/01_backbone_selection'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# 3. ë°ì´í„°ì…‹ ê²½ë¡œ\n",
        "CSV_PATH = '/content/drive/MyDrive/HECTO/Dataset/CSV/total_local_path.csv'\n",
        "\n",
        "print(f\"âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ: {CHECKPOINT_DIR}\")"
      ],
      "metadata": {
        "id": "lI5k7luTO2cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‹œë“œ ì„¤ì •\n",
        "EXPERIMENT_SEED = 42\n",
        "set_seed(EXPERIMENT_SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"âœ… ì‹œë“œ {EXPERIMENT_SEED} ê³ ì • ì™„ë£Œ ë° {device} ì¤€ë¹„\")"
      ],
      "metadata": {
        "id": "mieyyaqCO47W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator()\n",
        "g.manual_seed(EXPERIMENT_SEED)\n",
        "\n",
        "# ê¸°ë³¸ ì¦ê°• ì„¤ì •\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    # 1. ê¸°í•˜í•™ì  ë³€í™˜ (256x256 ì›ë³¸ í•´ìƒë„ì—ì„œ ìˆ˜í–‰)\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "\n",
        "    # 2. í™”ì§ˆ ë° ìƒ‰ìƒ ë³€í™˜\n",
        "    transforms.RandomApply([\n",
        "        transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
        "    ], p=0.3),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "\n",
        "    # 3. ì„¼í„° í¬ë¡­ (Resize ëŒ€ì‹  ì‚¬ìš©)\n",
        "    # 256x256 ì´ë¯¸ì§€ì˜ ì¤‘ì•™ì—ì„œ 224x224ë¥¼ ì˜ë¼ë‚´ì–´ í”½ì…€ ì™œê³¡ì„ ë°©ì§€í•©ë‹ˆë‹¤.\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "\n",
        "    # 4. í…ì„œí™” ë° ì •ê·œí™”\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "    # 5. ê°€ë ¤ì§ ëŒ€ë¹„ (ToTensor ì´í›„ ì ìš©)\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    # 1. ì„¼í„° í¬ë¡­\n",
        "    # í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ ì¤‘ì•™ ì˜ì—­ì„ 224x224ë¡œ ì˜ë¼ëƒ…ë‹ˆë‹¤.\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "\n",
        "    # 2. í…ì„œí™” ë° ì •ê·œí™”\n",
        "    # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ íŒŒë¼ë¯¸í„°ì™€ ì™„ë²½íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "gHgu-5mvO6X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.delta = delta\n",
        "        self.val_acc_max = 0\n",
        "\n",
        "    def __call__(self, val_acc):\n",
        "        score = val_acc\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.val_acc_max = val_acc\n",
        "        # [ìˆ˜ì •] ì •í™•ë„ê°€ ê°œì„ ë˜ì§€ ì•Šì€ ê²½ìš° (scoreê°€ best + deltaë³´ë‹¤ ì‘ì„ ë•Œ)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        # [ìˆ˜ì •] ì •í™•ë„ê°€ í™•ì‹¤íˆ ê°œì„ ëœ ê²½ìš°\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.val_acc_max = val_acc\n",
        "            self.counter = 0\n",
        "\n",
        "def load_checkpoint(model_name, model, optimizer, save_dir=CHECKPOINT_DIR):\n",
        "    filename = os.path.join(save_dir, f\"{model_name}_checkpoint.pth.tar\")\n",
        "    if os.path.isfile(filename):\n",
        "        print(f\"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: {filename}\")\n",
        "        # map_location ì¶”ê°€í•˜ì—¬ ì¥ì¹˜ ë¶ˆì¼ì¹˜ ë°©ì§€\n",
        "        checkpoint = torch.load(filename, map_location=device)\n",
        "\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        best_acc = checkpoint['best_acc']\n",
        "        es_state = checkpoint.get('es_state', None)\n",
        "\n",
        "        # ë§Œì•½ es_stateì— best_score ì •ë³´ê°€ ì—†ë‹¤ë©´ best_accë¡œ ê°•ì œ ë™ê¸°í™” ì¤€ë¹„\n",
        "        if es_state is not None:\n",
        "            if 'best_score' not in es_state or es_state['best_score'] is None:\n",
        "                es_state['best_score'] = best_acc\n",
        "\n",
        "        return start_epoch, best_acc, es_state\n",
        "    else:\n",
        "        print(\"ğŸ†• ì´ì „ ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ. ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
        "        return 0, 0, None"
      ],
      "metadata": {
        "id": "c-DtaIfzO9ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‹¤í—˜ ëŒ€ìƒ ëª¨ë¸\n",
        "model_names = ['resnet50', 'efficientnet_b0', 'vit_tiny_patch16_224', 'convnext_tiny']\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "MAX_EPOCHS = 20  # ì–¼ë¦¬ìŠ¤íƒ‘ì´ ìˆìœ¼ë¯€ë¡œ ë„‰ë„‰íˆ ì¡ìŠµë‹ˆë‹¤.\n",
        "BATCH_SIZE = 32\n",
        "LR = 1e-4\n",
        "\n",
        "# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "results_summary = []\n",
        "\n",
        "# ë°ì´í„° ë¡œë” ì¤€ë¹„\n",
        "train_dataset = DeepfakeDataset(CSV_PATH, split='train', transform=train_transform)\n",
        "val_dataset = DeepfakeDataset(CSV_PATH, split='val', transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=2, worker_init_fn=seed_worker, generator=g)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "JoNIZc-HPAL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import timm\n",
        "import gc\n",
        "from torch import nn, optim\n",
        "\n",
        "# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
        "results_summary = []\n",
        "\n",
        "for m_name in model_names:\n",
        "    print(f\"\\n\" + \"=\"*50)\n",
        "    print(f\"ğŸš€ Experiment Target: {m_name}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 1. ì‹œë“œ ê³ ì • (ì¬í˜„ì„± í™•ë³´)\n",
        "    set_seed(EXPERIMENT_SEED)\n",
        "\n",
        "    # 2. ëª¨ë¸ ë° ê¸°ë³¸ ê°ì²´ ì´ˆê¸°í™”\n",
        "    model = timm.create_model(m_name, pretrained=True, num_classes=1).to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    # ì–¼ë¦¬ìŠ¤íƒ‘ ê°ì²´ ìƒì„± (ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹œì‘)\n",
        "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
        "\n",
        "    # 3. [í•µì‹¬ ìˆ˜ì •] ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (í•™ìŠµ ì¬ê°œ ì—¬ë¶€ íŒë‹¨ì˜ ê·¼ê±°)\n",
        "    start_epoch, best_acc, es_state = load_checkpoint(m_name, model, optimizer, CHECKPOINT_DIR)\n",
        "\n",
        "    if es_state is not None:\n",
        "        # 1. ì €ì¥ëœ ìƒíƒœ ì „ì²´ ë³µêµ¬ (counter, early_stop ë“±)\n",
        "        early_stopping.__dict__.update(es_state)\n",
        "\n",
        "        # 2. [í•µì‹¬] ë§Œì•½ best_scoreê°€ ë¹„ì–´ìˆë‹¤ë©´ ë¶ˆëŸ¬ì˜¨ best_accë¡œ ì±„ì›Œì¤Œ\n",
        "        if early_stopping.best_score is None:\n",
        "            early_stopping.best_score = best_acc\n",
        "\n",
        "        print(f\"ğŸ”„ {m_name} ìƒíƒœ ë³µêµ¬: Epoch {start_epoch}, Best Acc {best_acc:.4f}, Counter {early_stopping.counter}\")\n",
        "\n",
        "    # 5. [í•µì‹¬ ìˆ˜ì •] í•™ìŠµ ì™„ë£Œ ì—¬ë¶€ íŒë³„ ë¡œì§\n",
        "    # ì¡°ê±´ A: ì´ë¯¸ ì–¼ë¦¬ìŠ¤íƒ‘ì´ ë°œìƒí–ˆëŠ”ê°€?\n",
        "    # ì¡°ê±´ B: ì´ë¯¸ ì„¤ì •í•œ ìµœëŒ€ ì—í¬í¬(MAX_EPOCHS)ê¹Œì§€ ì™„ì£¼í–ˆëŠ”ê°€?\n",
        "    if early_stopping.early_stop or start_epoch >= MAX_EPOCHS:\n",
        "        reason = \"Early Stopping ì™„ë£Œ\" if early_stopping.early_stop else \"ìµœëŒ€ ì—í¬í¬ ì™„ì£¼\"\n",
        "        print(f\"âœ… {m_name}ì€(ëŠ”) ì´ë¯¸ í•™ìŠµì´ ì¢…ë£Œëœ ìƒíƒœì…ë‹ˆë‹¤. ({reason})\")\n",
        "        results_summary.append({'Model': m_name, 'Best Video Acc': best_acc})\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ë‹¤ìŒ ëª¨ë¸ë¡œ ìŠ¤í‚µ\n",
        "        del model, optimizer\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        continue\n",
        "\n",
        "    # 6. í•™ìŠµ ë£¨í”„ (start_epochë¶€í„° ì¬ê°œ)\n",
        "    print(f\"â–¶ï¸ {m_name} í•™ìŠµì„ {start_epoch+1} ì—í¬í¬ë¶€í„° ì¬ê°œí•©ë‹ˆë‹¤.\")\n",
        "\n",
        "    for epoch in range(start_epoch, MAX_EPOCHS):\n",
        "        print(f\"\\n[Epoch {epoch+1}/{MAX_EPOCHS}]\")\n",
        "\n",
        "        # í•™ìŠµ ë° ê²€ì¦\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, video_acc = validate_video_level(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"   Val Loss:   {val_loss:.4f} | Video-level Val Acc: {video_acc:.4f}\")\n",
        "\n",
        "        # ì—í¬í¬ë³„ ë¡œê·¸ ê¸°ë¡\n",
        "        log_to_csv(m_name, epoch+1, train_loss, train_acc, val_loss, video_acc, f\"{CHECKPOINT_DIR}/{m_name}_history.csv\")\n",
        "\n",
        "        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ê°±ì‹  í™•ì¸\n",
        "        is_best = video_acc > best_acc\n",
        "        if is_best:\n",
        "            best_acc = video_acc\n",
        "            print(f\"âœ¨ Best Model Updated! (Acc: {best_acc:.4f})\")\n",
        "\n",
        "        # ì–¼ë¦¬ìŠ¤íƒ‘ íŒì • (ì¹´ìš´í„° ì—…ë°ì´íŠ¸)\n",
        "        early_stopping(video_acc)\n",
        "\n",
        "        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ê°±ì‹ ëœ es_state í¬í•¨)\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'best_acc': best_acc,\n",
        "            'es_state': early_stopping.__dict__,  # ê°±ì‹ ëœ ì–¼ë¦¬ìŠ¤íƒ‘ ìƒíƒœ ì €ì¥\n",
        "        }, is_best, m_name, CHECKPOINT_DIR)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(f\"ğŸ›‘ {m_name} Early Stopping triggered at epoch {epoch+1}!\")\n",
        "            break\n",
        "\n",
        "    results_summary.append({'Model': m_name, 'Best Video Acc': best_acc})\n",
        "\n",
        "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    del model, optimizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# 7. ìµœì¢… ê²°ê³¼ ë³´ê³ ì„œ\n",
        "print(\"\\n\" + \"ğŸ†\" * 5 + \" Final Comparison Report \" + \"ğŸ†\" * 5)\n",
        "if results_summary:\n",
        "    df_res = pd.DataFrame(results_summary)\n",
        "    # ì¤‘ë³µ ëª¨ë¸ëª…ì´ ìˆì„ ê²½ìš° ìµœê³  ì ìˆ˜ë§Œ ë‚¨ê¹€ (ì¬ê°œ ë¡œì§ ëŒ€ë¹„)\n",
        "    df_res = df_res.sort_values(by=['Model', 'Best Video Acc'], ascending=[True, False])\n",
        "    df_res = df_res.drop_duplicates('Model').sort_values(by='Best Video Acc', ascending=False).reset_index(drop=True)\n",
        "    print(df_res)\n",
        "    print(f\"\\nğŸ¥‡ ìµœì ì˜ ë°±ë³¸ ëª¨ë¸: {df_res.iloc[0]['Model']} ({df_res.iloc[0]['Best Video Acc']:.4f})\")\n",
        "else:\n",
        "    print(\"ê¸°ë¡ëœ ì‹¤í—˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "id": "ar_Y9W4ssZA6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}