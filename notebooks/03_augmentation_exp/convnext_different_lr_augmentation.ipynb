{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepfake-detection-model-project/Deepfake-Detection-Project/blob/jiwon-dev/notebooks/03_augmentation_exp/convnext_different_lr_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gYXWlQZPfah"
      },
      "outputs": [],
      "source": [
        "# !pip install timm # í˜„ì¬ ì½”ë©ì— ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì„œ ì£¼ì„ì²˜ë¦¬ í•¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WH3tSGvTPZkd"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import gc\n",
        "import albumentations as A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPw09SGCs7oB"
      },
      "outputs": [],
      "source": [
        "# 1. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BsGABBbUFJA"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "# src í´ë”ë¥¼ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ ê²½ë¡œ ì¶”ê°€ (í˜„ì¬ ê²½ë¡œê°€ /contentë¼ë©´)\n",
        "sys.path.append('/content/drive/MyDrive/HECTO')\n",
        "\n",
        "from src.utils import set_seed, log_to_csv\n",
        "from src.dataset import DeepfakeDataset, seed_worker\n",
        "from src.trainer import train_one_epoch, validate_video_level, save_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2eAoSQr862o"
      },
      "outputs": [],
      "source": [
        "# ë¡œì»¬ì—ì„œ ì••ì¶• í•´ì œ (ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì—†ìŒ)\n",
        "!unzip -q /content/drive/MyDrive/HECTO/Dataset/final_files/Celeb_frames_pp_final.zip -d /content/Celeb_Extract\n",
        "!unzip -q /content/drive/MyDrive/HECTO/Dataset/final_files/DF_Frames_Final.zip -d /content/DF_Extract\n",
        "!unzip -q /content/drive/MyDrive/HECTO/Dataset/final_files/FF_Frames_Final.zip -d /content/FF++_Extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI5k7luTO2cn"
      },
      "outputs": [],
      "source": [
        "# 2. ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ ì„¤ì • (ë³¸ì¸ì˜ ë“œë¼ì´ë¸Œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì • ê°€ëŠ¥)\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/HECTO/checkpoints/04_convnext_different_lr_augmentation_only_ff_celeb'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# 3. ë°ì´í„°ì…‹ ê²½ë¡œ\n",
        "CSV_PATH = '/content/drive/MyDrive/HECTO/Dataset/CSV/total_final.csv'\n",
        "\n",
        "print(f\"âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ: {CHECKPOINT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mieyyaqCO47W"
      },
      "outputs": [],
      "source": [
        "# ì‹œë“œ ì„¤ì •\n",
        "EXPERIMENT_SEED = 42\n",
        "set_seed(EXPERIMENT_SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"âœ… ì‹œë“œ {EXPERIMENT_SEED} ê³ ì • ì™„ë£Œ ë° {device} ì¤€ë¹„\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHgu-5mvO6X6"
      },
      "outputs": [],
      "source": [
        "g = torch.Generator()\n",
        "g.manual_seed(EXPERIMENT_SEED)\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# Albumentationsì™€ Torchvisionì„ ì—°ê²°í•˜ê¸° ìœ„í•œ ë˜í¼ í´ë˜ìŠ¤\n",
        "class AlbumentationsWrapper:\n",
        "    def __init__(self, transform):\n",
        "        self.transform = transform\n",
        "    def __call__(self, img):\n",
        "        img_np = np.array(img)\n",
        "        augmented = self.transform(image=img_np)\n",
        "        return Image.fromarray(augmented['image'])\n",
        "\n",
        "# --- 1. DFìš© (ì•½í•œ ì¦ê°•) ---\n",
        "alb_aug_df_settings = A.Compose([\n",
        "    A.ImageCompression(quality_lower=70, quality_upper=95, p=0.15),\n",
        "    A.GaussNoise(var_limit=(5.0, 20.0), p=0.1),\n",
        "])\n",
        "\n",
        "train_transform_df = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    AlbumentationsWrapper(alb_aug_df_settings),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 1.2))], p=0.2), # ê°•ë„ ë‚®ì¶¤\n",
        "    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.05), # ê°•ë„ ë‚®ì¶¤\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
        "])\n",
        "\n",
        "# --- 2. Celeb/FF++ìš© (ê¸°ë³¸ ì¦ê°•) ---\n",
        "alb_aug_celeb_ff_settings = A.Compose([\n",
        "    A.ImageCompression(quality_lower=50, quality_upper=90, p=0.3),\n",
        "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
        "    A.ISONoise(p=0.1)\n",
        "])\n",
        "\n",
        "train_transform_others = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    AlbumentationsWrapper(alb_aug_celeb_ff_settings),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))], p=0.3),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
        "])\n",
        "\n",
        "# ê²€ì¦ìš©ì€ ë™ì¼í•˜ê²Œ ìœ ì§€\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.CenterCrop((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlF3sfUpxxxZ"
      },
      "outputs": [],
      "source": [
        "class DeepfakeDataset(Dataset):\n",
        "    def __init__(self, csv_path, split='train', transform_df=None, transform_others=None):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        self.data = df[df['split'] == split].reset_index(drop=True)\n",
        "        # í•™ìŠµ ì‹œì—ëŠ” ë‘ ì¢…ë¥˜ì˜ transformì„ ì‚¬ìš©, ê²€ì¦ ì‹œì—ëŠ” í•˜ë‚˜ë§Œ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •\n",
        "        self.transform_df = transform_df\n",
        "        self.transform_others = transform_others\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data.loc[idx, 'frame_path']\n",
        "        label = self.data.loc[idx, 'label']\n",
        "        video_id = self.data.loc[idx, 'video_id']\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # ê²½ë¡œì— 'DF_Extract'ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì—¬ ì¦ê°• ì„ íƒ\n",
        "        if 'DF_Extract' in img_path:\n",
        "            if self.transform_df:\n",
        "                image = self.transform_df(image)\n",
        "        else:\n",
        "            if self.transform_others:\n",
        "                image = self.transform_others(image)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.float32), video_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-DtaIfzO9ge"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.delta = delta\n",
        "        self.val_acc_max = 0\n",
        "\n",
        "    def __call__(self, val_acc):\n",
        "        score = val_acc\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.val_acc_max = val_acc\n",
        "        # [ìˆ˜ì •] ì •í™•ë„ê°€ ê°œì„ ë˜ì§€ ì•Šì€ ê²½ìš° (scoreê°€ best + deltaë³´ë‹¤ ì‘ì„ ë•Œ)\n",
        "        elif score <= self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        # [ìˆ˜ì •] ì •í™•ë„ê°€ í™•ì‹¤íˆ ê°œì„ ëœ ê²½ìš°\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.val_acc_max = val_acc\n",
        "            self.counter = 0\n",
        "\n",
        "def load_checkpoint(model_name, model, optimizer, save_dir=CHECKPOINT_DIR):\n",
        "    filename = os.path.join(save_dir, f\"{model_name}_checkpoint.pth.tar\")\n",
        "    if os.path.isfile(filename):\n",
        "        print(f\"ğŸ”„ ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: {filename}\")\n",
        "        # map_location ì¶”ê°€í•˜ì—¬ ì¥ì¹˜ ë¶ˆì¼ì¹˜ ë°©ì§€\n",
        "        checkpoint = torch.load(filename, map_location=device)\n",
        "\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        best_acc = checkpoint['best_acc']\n",
        "        es_state = checkpoint.get('es_state', None)\n",
        "\n",
        "        # ë§Œì•½ es_stateì— best_score ì •ë³´ê°€ ì—†ë‹¤ë©´ best_accë¡œ ê°•ì œ ë™ê¸°í™” ì¤€ë¹„\n",
        "        if es_state is not None:\n",
        "            if 'best_score' not in es_state or es_state['best_score'] is None:\n",
        "                es_state['best_score'] = best_acc\n",
        "\n",
        "        return start_epoch, best_acc, es_state\n",
        "    else:\n",
        "        print(\"ğŸ†• ì´ì „ ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ. ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
        "        return 0, 0, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIMoYcZ0hhTQ"
      },
      "outputs": [],
      "source": [
        "# 1. ì›ë³¸ CSV ë¡œë“œ\n",
        "df_orig = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# 2. í•„í„°ë§ ë¡œì§ ì ìš©\n",
        "# 'level_4', 'level_5', 'mix_2'ê°€ ê²½ë¡œì— í¬í•¨ëœ í–‰ì€ ì œì™¸í•©ë‹ˆë‹¤.\n",
        "# (ë§Œì•½ DFì˜ level_1, level_2ë„ ìˆë‹¤ë©´, 'level_3'ë§Œ ëª…ì‹œì ìœ¼ë¡œ ë‚¨ê¸°ëŠ” ë°©ì‹ì´ ë” ì•ˆì „í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)\n",
        "exclude_list = ['level_3', 'level_4', 'level_5', 'mix_2']\n",
        "\n",
        "# ë¬¸ìì—´ì„ í¬í•¨í•˜ì§€ ì•ŠëŠ”(~) í–‰ë“¤ë§Œ ì„ íƒ\n",
        "df_filtered = df_orig[~df_orig['frame_path'].str.contains('|'.join(exclude_list))]\n",
        "\n",
        "# (ì¶”ê°€ ê¶Œì¥) ë§Œì•½ DF ë°ì´í„°ì…‹ ì¤‘ level_3ë§Œ ë”± ë‚¨ê¸°ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”.\n",
        "# df_filtered = df_orig[~(df_orig['frame_path'].str.contains('DF_Extract') &\n",
        "#                        ~df_orig['frame_path'].str.contains('level_3'))]\n",
        "\n",
        "# 3. í•„í„°ë§ëœ ê²°ê³¼ ì €ì¥\n",
        "FILTERED_CSV_PATH = CSV_PATH.replace('.csv', '_filtered.csv')\n",
        "df_filtered.to_csv(FILTERED_CSV_PATH, index=False)\n",
        "\n",
        "# 4. ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ í•„í„°ë§ëœ CSVë¡œ êµì²´\n",
        "CSV_PATH = FILTERED_CSV_PATH\n",
        "\n",
        "print(f\"âœ… í•„í„°ë§ ì™„ë£Œ!\")\n",
        "print(f\"ì „ì²´ ë°ì´í„°: {len(df_orig)} -> í•„í„°ë§ í›„: {len(df_filtered)}\")\n",
        "print(f\"ì œì™¸ëœ ë°ì´í„° ìˆ˜: {len(df_orig) - len(df_filtered)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoNIZc-HPAL7"
      },
      "outputs": [],
      "source": [
        "# ì‹¤í—˜ ëŒ€ìƒ ëª¨ë¸\n",
        "model_names = ['convnext_tiny']\n",
        "\n",
        "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "MAX_EPOCHS = 20  # ì–¼ë¦¬ìŠ¤íƒ‘ì´ ìˆìœ¼ë¯€ë¡œ ë„‰ë„‰íˆ ì¡ìŠµë‹ˆë‹¤.\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# ì°¨ë“± í•™ìŠµë¥  ì„¤ì •\n",
        "BACKBONE_LR = 1e-5  # ê¸°ì¡´ ì§€ì‹ì„ ë³´ì¡´í•˜ê¸° ìœ„í•´ ë‚®ê²Œ ì„¤ì •\n",
        "HEAD_LR = 1e-4      # ìƒˆë¡œìš´ íƒœìŠ¤í¬ì— ì ì‘í•˜ê¸° ìœ„í•´ 10ë°° ë†’ê²Œ ì„¤ì •\n",
        "\n",
        "# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "results_summary = []\n",
        "\n",
        "# ë°ì´í„° ë¡œë” ì¤€ë¹„\n",
        "# í•™ìŠµ ë°ì´í„°ì…‹ì—ëŠ” DFìš©ê³¼ ê¸°íƒ€ìš© ì¦ê°•ì„ ê°ê° ì „ë‹¬\n",
        "train_dataset = DeepfakeDataset(CSV_PATH, split='train',\n",
        "                                transform_df=train_transform_df,\n",
        "                                transform_others=train_transform_others)\n",
        "\n",
        "# ê²€ì¦ ë°ì´í„°ì…‹ì€ êµ¬ë¶„í•  í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ ë‘˜ ë‹¤ ë™ì¼í•œ val_transform ì „ë‹¬\n",
        "val_dataset = DeepfakeDataset(CSV_PATH, split='val',\n",
        "                              transform_df=val_transform,\n",
        "                              transform_others=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=2, worker_init_fn=seed_worker, generator=g)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ar_Y9W4ssZA6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import timm\n",
        "import gc\n",
        "from torch import nn, optim\n",
        "\n",
        "# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
        "results_summary = []\n",
        "\n",
        "for m_name in model_names:\n",
        "    print(f\"\\n\" + \"=\"*50)\n",
        "    print(f\"ğŸš€ Experiment Target: {m_name}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 1. ì‹œë“œ ê³ ì • (ì¬í˜„ì„± í™•ë³´)\n",
        "    set_seed(EXPERIMENT_SEED)\n",
        "\n",
        "    # 2. ëª¨ë¸ ë° ê¸°ë³¸ ê°ì²´ ì´ˆê¸°í™”\n",
        "    model = timm.create_model(m_name, pretrained=True, num_classes=1).to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    optimizer = optim.AdamW([\n",
        "        {'params': model.stem.parameters(), 'lr': BACKBONE_LR},\n",
        "        {'params': model.stages.parameters(), 'lr': BACKBONE_LR},\n",
        "        {'params': model.head.parameters(), 'lr': HEAD_LR}\n",
        "    ], weight_decay=0.05)\n",
        "\n",
        "    # ì–¼ë¦¬ìŠ¤íƒ‘ ê°ì²´ ìƒì„± (ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹œì‘)\n",
        "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
        "\n",
        "    # 3. [í•µì‹¬ ìˆ˜ì •] ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (í•™ìŠµ ì¬ê°œ ì—¬ë¶€ íŒë‹¨ì˜ ê·¼ê±°)\n",
        "    start_epoch, best_acc, es_state = load_checkpoint(m_name, model, optimizer, CHECKPOINT_DIR)\n",
        "\n",
        "    if es_state is not None:\n",
        "        # 1. ì €ì¥ëœ ìƒíƒœ ì „ì²´ ë³µêµ¬ (counter, early_stop ë“±)\n",
        "        early_stopping.__dict__.update(es_state)\n",
        "\n",
        "        # 2. [í•µì‹¬] ë§Œì•½ best_scoreê°€ ë¹„ì–´ìˆë‹¤ë©´ ë¶ˆëŸ¬ì˜¨ best_accë¡œ ì±„ì›Œì¤Œ\n",
        "        if early_stopping.best_score is None:\n",
        "            early_stopping.best_score = best_acc\n",
        "\n",
        "        print(f\"ğŸ”„ {m_name} ìƒíƒœ ë³µêµ¬: Epoch {start_epoch}, Best Acc {best_acc:.4f}, Counter {early_stopping.counter}\")\n",
        "\n",
        "    # 5. [í•µì‹¬ ìˆ˜ì •] í•™ìŠµ ì™„ë£Œ ì—¬ë¶€ íŒë³„ ë¡œì§\n",
        "    # ì¡°ê±´ A: ì´ë¯¸ ì–¼ë¦¬ìŠ¤íƒ‘ì´ ë°œìƒí–ˆëŠ”ê°€?\n",
        "    # ì¡°ê±´ B: ì´ë¯¸ ì„¤ì •í•œ ìµœëŒ€ ì—í¬í¬(MAX_EPOCHS)ê¹Œì§€ ì™„ì£¼í–ˆëŠ”ê°€?\n",
        "    if early_stopping.early_stop or start_epoch >= MAX_EPOCHS:\n",
        "        reason = \"Early Stopping ì™„ë£Œ\" if early_stopping.early_stop else \"ìµœëŒ€ ì—í¬í¬ ì™„ì£¼\"\n",
        "        print(f\"âœ… {m_name}ì€(ëŠ”) ì´ë¯¸ í•™ìŠµì´ ì¢…ë£Œëœ ìƒíƒœì…ë‹ˆë‹¤. ({reason})\")\n",
        "        results_summary.append({'Model': m_name, 'Best Video Acc': best_acc})\n",
        "\n",
        "        # ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ ë‹¤ìŒ ëª¨ë¸ë¡œ ìŠ¤í‚µ\n",
        "        del model, optimizer\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        continue\n",
        "\n",
        "    # 6. í•™ìŠµ ë£¨í”„ (start_epochë¶€í„° ì¬ê°œ)\n",
        "    print(f\"â–¶ï¸ {m_name} í•™ìŠµì„ {start_epoch+1} ì—í¬í¬ë¶€í„° ì¬ê°œí•©ë‹ˆë‹¤.\")\n",
        "\n",
        "    for epoch in range(start_epoch, MAX_EPOCHS):\n",
        "        print(f\"\\n[Epoch {epoch+1}/{MAX_EPOCHS}]\")\n",
        "\n",
        "        # í•™ìŠµ ë° ê²€ì¦\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, video_acc = validate_video_level(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"   Val Loss:   {val_loss:.4f} | Video-level Val Acc: {video_acc:.4f}\")\n",
        "\n",
        "        # ì—í¬í¬ë³„ ë¡œê·¸ ê¸°ë¡\n",
        "        log_to_csv(m_name, epoch+1, train_loss, train_acc, val_loss, video_acc, f\"{CHECKPOINT_DIR}/{m_name}_history.csv\")\n",
        "\n",
        "        # ë² ìŠ¤íŠ¸ ëª¨ë¸ ê°±ì‹  í™•ì¸\n",
        "        is_best = video_acc > best_acc\n",
        "        if is_best:\n",
        "            best_acc = video_acc\n",
        "            print(f\"âœ¨ Best Model Updated! (Acc: {best_acc:.4f})\")\n",
        "\n",
        "        # ì–¼ë¦¬ìŠ¤íƒ‘ íŒì • (ì¹´ìš´í„° ì—…ë°ì´íŠ¸)\n",
        "        early_stopping(video_acc)\n",
        "\n",
        "        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ê°±ì‹ ëœ es_state í¬í•¨)\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'best_acc': best_acc,\n",
        "            'es_state': early_stopping.__dict__,  # ê°±ì‹ ëœ ì–¼ë¦¬ìŠ¤íƒ‘ ìƒíƒœ ì €ì¥\n",
        "        }, is_best, m_name, CHECKPOINT_DIR)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            print(f\"ğŸ›‘ {m_name} Early Stopping triggered at epoch {epoch+1}!\")\n",
        "            break\n",
        "\n",
        "    results_summary.append({'Model': m_name, 'Best Video Acc': best_acc})\n",
        "\n",
        "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "    del model, optimizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# 7. ìµœì¢… ê²°ê³¼ ë³´ê³ ì„œ\n",
        "print(\"\\n\" + \"ğŸ†\" * 5 + \" Final Comparison Report \" + \"ğŸ†\" * 5)\n",
        "if results_summary:\n",
        "    df_res = pd.DataFrame(results_summary)\n",
        "    # ì¤‘ë³µ ëª¨ë¸ëª…ì´ ìˆì„ ê²½ìš° ìµœê³  ì ìˆ˜ë§Œ ë‚¨ê¹€ (ì¬ê°œ ë¡œì§ ëŒ€ë¹„)\n",
        "    df_res = df_res.sort_values(by=['Model', 'Best Video Acc'], ascending=[True, False])\n",
        "    df_res = df_res.drop_duplicates('Model').sort_values(by='Best Video Acc', ascending=False).reset_index(drop=True)\n",
        "    print(df_res)\n",
        "    print(f\"\\nğŸ¥‡ ìµœì ì˜ ë°±ë³¸ ëª¨ë¸: {df_res.iloc[0]['Model']} ({df_res.iloc[0]['Best Video Acc']:.4f})\")\n",
        "else:\n",
        "    print(\"ê¸°ë¡ëœ ì‹¤í—˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaKp6zH0KFpF"
      },
      "outputs": [],
      "source": [
        "# --- ë§ˆì§€ë§‰ ì…€: í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ì˜ Video-level AUC ì¸¡ì • ---\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_video_level_auc(model, val_loader, device):\n",
        "    \"\"\"\n",
        "    í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ ë ˆë²¨ì˜ AUCë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "    ë°ì´í„°ë¡œë”ê°€ ë¦¬ìŠ¤íŠ¸ [image, label, video_id]ë¥¼ ë°˜í™˜í•˜ëŠ” êµ¬ì¡°ì— ë§ì¶° ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    video_scores = defaultdict(list)\n",
        "    video_labels = {}\n",
        "\n",
        "    print(\"ğŸ” AUC ê³„ì‚°ì„ ìœ„í•œ ê²€ì¦ ë°ì´í„° ì¶”ë¡  ì¤‘...\")\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader):\n",
        "            # ì—ëŸ¬ í•´ê²°: ë¦¬ìŠ¤íŠ¸ ì¸ë±ì‹±ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ\n",
        "            # batch[0]: ì´ë¯¸ì§€, batch[1]: ë¼ë²¨, batch[2]: ë¹„ë””ì˜¤ ID\n",
        "            images = batch[0].to(device)\n",
        "            labels = batch[1].to(device)\n",
        "            video_ids = batch[2]\n",
        "\n",
        "            outputs = model(images).squeeze()\n",
        "\n",
        "            # Sigmoidë¥¼ ì ìš©í•˜ì—¬ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜\n",
        "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "\n",
        "            # ë‹¨ì¼ ê°’(Batch Size 1)ì¸ ê²½ìš° ë°°ì—´ë¡œ í˜•íƒœ ìœ ì§€\n",
        "            if probs.ndim == 0:\n",
        "                probs = np.array([probs])\n",
        "\n",
        "            labels = labels.cpu().numpy()\n",
        "\n",
        "            for i, v_id in enumerate(video_ids):\n",
        "                video_scores[v_id].append(probs[i])\n",
        "                if v_id not in video_labels:\n",
        "                    video_labels[v_id] = labels[i]\n",
        "\n",
        "    # ë¹„ë””ì˜¤ë³„ í”„ë ˆì„ í™•ë¥ ê°’ì˜ í‰ê·  ê³„ì‚°\n",
        "    all_video_probs = []\n",
        "    all_video_labels = []\n",
        "\n",
        "    for v_id in video_scores.keys():\n",
        "        avg_prob = np.mean(video_scores[v_id])\n",
        "        all_video_probs.append(avg_prob)\n",
        "        all_video_labels.append(video_labels[v_id])\n",
        "\n",
        "    # ìµœì¢… AUC ê³„ì‚°\n",
        "    auc_score = roc_auc_score(all_video_labels, all_video_probs)\n",
        "    return auc_score\n",
        "\n",
        "# --- ì‹¤í–‰ë¶€: ì €ì¥ëœ ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¡œë“œ ë° í‰ê°€ ---\n",
        "for m_name in model_names:\n",
        "    print(f\"\\n\" + \"=\"*50)\n",
        "    print(f\"ğŸ“Š [{m_name}] ìµœì¢… ì„±ëŠ¥ í‰ê°€ (Video-level AUC)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 1. ë² ìŠ¤íŠ¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì„¤ì •\n",
        "    # CHECKPOINT_DIRê°€ ì •ì˜ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´ ì•ì„  ì…€ì˜ ê²½ë¡œì™€ ì¼ì¹˜ì‹œì¼œì£¼ì„¸ìš”.\n",
        "    best_model_path = os.path.join(CHECKPOINT_DIR, f\"{m_name}_best.pth.tar\")\n",
        "\n",
        "    if os.path.exists(best_model_path):\n",
        "        # 2. ëª¨ë¸ êµ¬ì¡° ì´ˆê¸°í™” ë° ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
        "        model = timm.create_model(m_name, pretrained=False, num_classes=1).to(device)\n",
        "        checkpoint = torch.load(best_model_path, map_location=device)\n",
        "\n",
        "        # 'state_dict' í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸ í›„ ë¡œë“œ\n",
        "        if 'state_dict' in checkpoint:\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "        else:\n",
        "            model.load_state_dict(checkpoint)\n",
        "\n",
        "        print(f\"âœ… ë² ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ: {best_model_path}\")\n",
        "        if 'epoch' in checkpoint:\n",
        "            print(f\"ğŸ“… í•´ë‹¹ ëª¨ë¸ì€ Epoch {checkpoint['epoch']}ì—ì„œ ì €ì¥ëœ ëª¨ë¸ì…ë‹ˆë‹¤.\")\n",
        "\n",
        "        # 3. AUC ì¸¡ì • ì‹¤í–‰\n",
        "        final_auc = get_video_level_auc(model, val_loader, device)\n",
        "        print(f\"\\nğŸ† [{m_name}] Final Video-level AUC: {final_auc:.4f}\")\n",
        "\n",
        "        # 4. ê²°ê³¼ ìš”ì•½ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸\n",
        "        for res in results_summary:\n",
        "            if res.get('Model') == m_name:\n",
        "                res['Final_AUC'] = final_auc\n",
        "    else:\n",
        "        print(f\"âŒ ë² ìŠ¤íŠ¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {best_model_path}\")\n",
        "\n",
        "# ì „ì²´ ê²°ê³¼ ì¶œë ¥\n",
        "if results_summary:\n",
        "    print(\"\\n\" + \"âœ¨\" * 5 + \" Final Experiment Summary \" + \"âœ¨\" * 5)\n",
        "    print(pd.DataFrame(results_summary))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}